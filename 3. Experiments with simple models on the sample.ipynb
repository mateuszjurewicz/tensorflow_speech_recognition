{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with simple models on the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebooks we have separated a small subset of our data, called \"sample\", on which we can now experiment with simple models to assess the effectiveness of our preprocessing & data augmentation techniques.\n",
    "\n",
    "We do it this way to avoid spending too much time on training on the entire set, the assumption is that the methods which are effective on the sample will work well on a larger scale too. \n",
    "\n",
    "We will start by testing a couple of simple models on untouched sample data (as numpy arrays) and then proceed towards data augmentation and finally spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/mateusz/Documents/Mateusz/Career/Machine Learning & AI/tensorflow_speech_recognition/tensorflow_speech_recognition\n"
     ]
    }
   ],
   "source": [
    "# first make sure we're in the parent dictory of our data/sample folders.\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "We'll need a couple of additional libraries so let's import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'C:\\\\Users\\\\mateusz\\\\Documents\\\\Mateusz\\\\Career\\\\Machine Learning & AI\\\\tensorflow_speech_recognition\\\\tensorflow_speech_recognition\\\\utils.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# utils\n",
    "from importlib import reload\n",
    "import utils; reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "The easiest way to work with data is by turning it into a list of numbers, in our case a numpy array. We can use one of the functions from utils to load the raw data or use the librosa.load() function. The difference lies in the fact that the former returns int16s whereas librosa returns float32s and uses its default sampling rate of 22050Hz, unless we explicitly tell it to use the file's original sampling rate of 16000Hz.\n",
    "\n",
    "We should also consider normalizing our data (so that it all falls within the same scale) and extracting a 1D mel-frequency cepstrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sample = \"data\\\\sample\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll have to go through each of the folders in our sample/train, cv and test sets, one-hot encode their label and load the 16K long array of raw data. The y data will be of shape (m, 12), where m is the number of examples, and the X data will be of shape (m, 16000).\n",
    "\n",
    "Let's calculate **m** first. We will do that by using a function that create a list of all the .wav files within a directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of paths\n",
    "We will use the glob module that we learned about in the very first notebook and a function from util.py which can, given a directory, return a list of paths to .wav files within it. We will repeat the process for all 3 sets within sample, and every category subdirectory within those too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\sample\\\\train\\\\stop\\\\01bcfc0c_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\17cc40ee_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\2da58b32_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\2da58b32_nohash_4.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\311fde72_nohash_2.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example we can grab all .wav files from sample/train/stop\n",
    "path_to_sample_train_stop = os.path.join(path_to_sample, \"train\", \"stop\")\n",
    "utils.grab_wavs(path_to_sample_train_stop)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll need a list of all category folder names\n",
    "categories_to_predict = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"silence\", \"unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\sample\\\\train\\\\yes\\\\023a61ad_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\0f3f64d5_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\190821dc_nohash_4.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\28ed6bc9_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\324210dd_nohash_5.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\32561e9e_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\3fdafe25_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\48e8b82a_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\493392c6_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\589bce2c_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\5c237956_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\65c73b55_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\89f680f3_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\953fe1ad_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\b43de700_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\b7669804_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\e48a80ed_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\f5c3de1b_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\f839238a_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\yes\\\\f953e1af_nohash_4.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\0362539c_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\0362539c_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\0bd689d7_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\190821dc_nohash_3.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\1bb574f9_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\53fd1780_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\87728a88_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\9637f43f_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\a902ce9b_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\b80d6c5e_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\be7fa0a3_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\bf8d5617_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\c1d39ce8_nohash_6.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\cf8d91cf_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\d0426d63_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\d7559b2d_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\d78858d9_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\e41e41f7_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\e4a2cf79_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\no\\\\ee07dcb9_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\21307344_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\32561e9e_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\39999a0f_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\39ec87ac_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\3b8406c0_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\4a294341_nohash_3.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\5677ec77_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\569455ff_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\611d2b50_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\61d3e51e_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\7211390b_nohash_3.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\763188c4_nohash_3.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\7f74626f_nohash_4.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\8281a2a8_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\982babaf_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\b3bdded5_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\c0fb6812_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\f06190c1_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\f92e49f3_nohash_3.wav',\n",
       " 'data\\\\sample\\\\train\\\\up\\\\ffbb695d_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\10ace7eb_nohash_3.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\1626bc5a_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\29fb33da_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\3411cf4b_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\3c257192_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\3ea77ede_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\4954abe8_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\617de221_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\87014d40_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\a97017df_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\cb8f8307_nohash_5.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\d2f4f431_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\db7c95b0_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\e3e49931_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\eb6dab4a_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\ec201020_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\f19c1390_nohash_3.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\f59d0771_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\f839238a_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\down\\\\fad7a69a_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\1cec8d71_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\24694eb6_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\2df590cd_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\338dacf5_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\531a5b8a_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\686d030b_nohash_4.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\6ef76186_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\743edf9d_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\80c17118_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\88120683_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\b2fbe484_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\bbbf4fbd_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\c79159aa_nohash_4.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\cd8b1781_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\dbb7723a_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\e102119e_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\e41e41f7_nohash_3.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\e57d35bc_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\ec201020_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\left\\\\fb9d6d23_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\06a79a03_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\0c5027de_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\0d2bcf9d_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\3c257192_nohash_3.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\4beff0c5_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\62581901_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\6e74c582_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\784e281a_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\92a9c5e6_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\97e0c576_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\a4baac4e_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\aeb99b1c_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\b4aa9fef_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\c68cf200_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\cb8f8307_nohash_6.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\d2f4f431_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\d9b50b8b_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\dbb7723a_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\dea820ce_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\right\\\\f810e799_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\21e8c417_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\2bd2cad5_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\34e8c726_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\3fb8c268_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\408de0a4_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\48a9f771_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\51055bda_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\617de221_nohash_3.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\8931f494_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\89ed36ab_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\8c3c4715_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\8eb4a1bf_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\96c66ab7_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\c9b653a0_nohash_3.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\cae62f38_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\cb8f8307_nohash_3.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\d33df435_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\e0344f60_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\f19d1738_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\on\\\\f618568f_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\300384f0_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\305776dd_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\35d1b6ee_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\51eefcc6_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\5e033479_nohash_3.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\6727b579_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\7096522d_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\78884794_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\89f3ab7d_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\918a2473_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\96ab6565_nohash_4.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\9f6fbdb4_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\a16b3102_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\b8897f1c_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\cb8f8307_nohash_6.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\d7ca14ef_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\dcc012ec_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\dd6c6806_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\edd8bfe3_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\off\\\\fe5c4a7a_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\01bcfc0c_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\17cc40ee_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\2da58b32_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\2da58b32_nohash_4.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\311fde72_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\36050ef3_nohash_3.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\5184ed3e_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\59fe87e6_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\686d030b_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\7014b07e_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\723efc4c_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\888a0c49_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\888a0c49_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\88a487ce_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\ac4b3fc3_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\d486fb84_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\e7117d00_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\ec201020_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\f06190c1_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\stop\\\\f8f60f59_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\012c8314_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\02746d24_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\10467b06_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\1bb574f9_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\36050ef3_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\364f979f_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\37e8db82_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\4fe01997_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\5628d7b7_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\57b68383_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\6fca237d_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\9a43b64b_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\c1e0e8e3_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\ceaadb24_nohash_0.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\e7ea8b76_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\eb3f7d82_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\f5733968_nohash_1.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\f5733968_nohash_3.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\f864cd4a_nohash_2.wav',\n",
       " 'data\\\\sample\\\\train\\\\go\\\\f92e49f3_nohash_4.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\doing_the_dishes_43.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\doing_the_dishes_46.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\doing_the_dishes_84.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\doing_the_dishes_94.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\exercise_bike_27.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\exercise_bike_35.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\exercise_bike_47.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\exercise_bike_50.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\exercise_bike_57.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\exercise_bike_60.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\pink_noise_45.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\pink_noise_8.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\running_tap_24.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\running_tap_35.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\running_tap_41.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\running_tap_57.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\running_tap_61.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\white_noise_26.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\white_noise_39.wav',\n",
       " 'data\\\\sample\\\\train\\\\silence\\\\white_noise_49.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\0137b3f4_nohash_1_eight.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\1365dd89_nohash_1_bird.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\18a1aab9_nohash_2_house.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\1e9b215e_nohash_0_sheila.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\2ad772d6_nohash_0_sheila.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\3ab9ba07_nohash_0_eight.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\3e31dffe_nohash_2_four.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\637c702a_nohash_1_two.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\64da5281_nohash_0_zero.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\7303215d_nohash_0_six.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\99e6cab8_nohash_0_seven.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\9aa21fa9_nohash_3_nine.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\b59fe16d_nohash_0_six.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\b959cd0c_nohash_2_four.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\c2aeb59d_nohash_0_wow.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\c2df23b2_nohash_0_sheila.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\cdbd6969_nohash_0_five.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\d430b3cc_nohash_1_eight.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\dfb6450b_nohash_0_two.wav',\n",
       " 'data\\\\sample\\\\train\\\\unknown\\\\eb0676ec_nohash_2_nine.wav']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first grab the training set\n",
    "path_to_train = os.path.join(path_to_sample, \"train\")\n",
    "sample_train_wavs = []\n",
    "\n",
    "for category in categories_to_predict:\n",
    "    path_to_category = os.path.join(path_to_train, category)\n",
    "    category_files = utils.grab_wavs(path_to_category)\n",
    "    \n",
    "    # we use extend instead of append to add all elements from the iterable\n",
    "    sample_train_wavs.extend(category_files)\n",
    "    \n",
    "sample_train_wavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for cv\n",
    "path_to_cv = os.path.join(path_to_sample, \"cv\")\n",
    "sample_cv_wavs = []\n",
    "\n",
    "for category in categories_to_predict:\n",
    "    path_to_category = os.path.join(path_to_cv, category)\n",
    "    category_files = utils.grab_wavs(path_to_category)\n",
    "    sample_cv_wavs.extend(category_files)\n",
    "\n",
    "# repeat for test\n",
    "path_to_test = os.path.join(path_to_sample, \"test\")\n",
    "sample_test_wavs = []\n",
    "\n",
    "for category in categories_to_predict:\n",
    "    path_to_category = os.path.join(path_to_test, category)\n",
    "    category_files = utils.grab_wavs(path_to_category)\n",
    "    sample_test_wavs.extend(category_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode the y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the 3 lists of files from each set (train, cv and test) we can construct our train_y, cv_y and test_y numpy arrays. These will be matrices of size (m, 12), one-hot encoded. E.g. if a row belongs to the category \"up\" it will take the form of an array of zeros, where the entry at index 2 (the third from the left) will become a 1.\n",
    "\n",
    "We will use a function from the utils that takes a path to a .wav, the index at which the category name starts within it (we want to control this because we will eventually use this for the main set, not just the sample) and a list of categories to predict. For our current example, the category name in the paths belonging to \"train\" starts at the 18th index (separators count as one char)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's grab a single path (this one is an \"up\")\n",
    "a_wav = sample_train_wavs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see if the 1 is correctly placed\n",
    "utils.one_hot_encode_path(a_wav, 18, categories_to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path belonged to the first category (\"up\") and the one-hot encoding correctly placed the 1 at index 0.\n",
    "\n",
    "We want to repeat this for all examples in each of the 3 subsets, adding each new one-hot encoded numpy array as a new row of the y matrix, in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# figure out the dimensions of train_y\n",
    "rows = len(sample_train_wavs)\n",
    "columns = len(categories_to_predict)\n",
    "dimensions = (rows, columns)\n",
    "dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current shape: 2880\n",
      "New shape: (240, 12)\n"
     ]
    }
   ],
   "source": [
    "# create train_y as empty array\n",
    "train_y = np.array([])\n",
    "\n",
    "# append each row to train_y\n",
    "for path_to_wav in sample_train_wavs:\n",
    "    row = utils.one_hot_encode_path(path_to_wav, 18, categories_to_predict)\n",
    "    \n",
    "    # append the new row\n",
    "    train_y = np.append(train_y, row)\n",
    "    \n",
    "# we currently have a flattened vector\n",
    "print(\"Current shape: {}\".format(*train_y.shape))\n",
    "\n",
    "# let's reshape it\n",
    "train_y = np.reshape(train_y, dimensions)\n",
    "print(\"New shape: {}\".format(train_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the train_y matrix to confirm\n",
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first 3 entries have the 1 at 0th index, which means they belong to category \"up\" and the last three have the 1 at the last index, which is also correct given the fact that our list of paths was also ordered.\n",
    "\n",
    "We should bear in mind that by default the np.array contains float64s and our functions for loading a .wav return int16s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for **CV set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target dimensions: (60, 12)\n",
      "Current shape: 720\n",
      "New shape: (60, 12)\n"
     ]
    }
   ],
   "source": [
    "# figure out the dimensions\n",
    "rows = len(sample_cv_wavs)\n",
    "columns = len(categories_to_predict)\n",
    "dimensions = (rows, columns)\n",
    "print(\"Target dimensions: {}\".format(dimensions))\n",
    "\n",
    "# empy array\n",
    "cv_y = np.array([])\n",
    "\n",
    "for path_to_wav in sample_cv_wavs:\n",
    "    row = utils.one_hot_encode_path(path_to_wav, 15, categories_to_predict)\n",
    "    \n",
    "    # append the new row\n",
    "    cv_y = np.append(cv_y, row)\n",
    "    \n",
    "# we currently have a flattened vector\n",
    "print(\"Current shape: {}\".format(*cv_y.shape))\n",
    "\n",
    "# let's reshape it\n",
    "cv_y = np.reshape(cv_y, dimensions)\n",
    "print(\"New shape: {}\".format(cv_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for **Test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target dimensions: (60, 12)\n",
      "Current shape: 720\n",
      "New shape: (60, 12)\n"
     ]
    }
   ],
   "source": [
    "# figure out the dimensions\n",
    "rows = len(sample_test_wavs)\n",
    "columns = len(categories_to_predict)\n",
    "dimensions = (rows, columns)\n",
    "print(\"Target dimensions: {}\".format(dimensions))\n",
    "\n",
    "# empy array\n",
    "test_y = np.array([])\n",
    "\n",
    "for path_to_wav in sample_test_wavs:\n",
    "    row = utils.one_hot_encode_path(path_to_wav, 17, categories_to_predict)\n",
    "    \n",
    "    # append the new row\n",
    "    test_y = np.append(test_y, row)\n",
    "    \n",
    "# we currently have a flattened vector\n",
    "print(\"Current shape: {}\".format(*test_y.shape))\n",
    "\n",
    "# let's reshape it\n",
    "test_y = np.reshape(test_y, dimensions)\n",
    "print(\"New shape: {}\".format(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action plan\n",
    "1) turn the sample data into numpy arrays with X and y normally <br>\n",
    "1b) turn sample data into numpy arrays with X and y via mfccs<br>\n",
    "2) Use random forest?<br>\n",
    "3) Use linear model? (towards first benchmark)<br>\n",
    "4) Use various keras CNNs?<br>\n",
    "5) Add preprocessing and test a couple of the best models<br>\n",
    "6) Experiments on images without data augmentation<br>\n",
    "7) Experiments on images with data augmentation<br>\n",
    "8) Decide on e.g. 3 most promising methods<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can start by trying a simple model on the 1D mfccs -> even a linear model,then maybe 1D convolutions on keras, then move on to actual 2D stuff.\n",
    "\n",
    "**If we work on 1D data (like mfccs/waveforms) we can use the data augmentation done by the guy here:https://www.kaggle.com/CVxTz/audio-data-augmentation when passing our files into the Keras DataGenerator, but if we decide to work with the MEL images we can just use the same image augmentation as in fastai**\n",
    "\n",
    "se very simple linear model / keras network to see how we do on current sample, then experiment with different preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_mfccs(wav_file):\n",
    "    \"\"\"\n",
    "    Take a file and return the mel-frequency cepstrum.\n",
    "    \"\"\"\n",
    "    X, sample_rate = librosa.load(wav_file, res_type='kaiser_fast', sr=None)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sample = \"data\\\\sample\"\n",
    "path_to_a_wav = os.path.join(path_to_sample, \"cv\\\\unknown\\\\9db2bfe9_nohash_4_five.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.06296364e+02,  6.31600698e+01, -2.38641127e+01, -4.86630969e+00,\n",
       "       -3.53521586e+01, -3.80595467e+00, -1.06260360e+01, -5.45357225e+00,\n",
       "       -5.38032267e-01, -3.13763738e+00, -1.61412864e+00, -3.92968492e+00,\n",
       "       -5.57078467e+00, -4.21382641e+00, -8.39318905e+00,  2.59598676e+00,\n",
       "       -1.21718174e+01,  6.58169994e+00, -6.52752377e+00,  2.20022835e+00,\n",
       "       -4.70370097e+00, -7.75634867e-01, -2.45838166e+00, -1.27684907e+00,\n",
       "       -9.24384769e-01, -2.84166555e+00, -2.06350172e+00, -8.51055474e-01,\n",
       "       -6.62192168e-01, -1.39785145e+00, -1.65039538e+00,  3.35274945e-03,\n",
       "        1.09041363e+00, -5.96439092e-01,  5.99651357e-01, -2.19326520e+00,\n",
       "        7.19763870e-01,  1.33843908e+00,  1.59644506e-01, -9.80777004e-01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_mfccs(path_to_a_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "        -3.0517578e-05, -3.0517578e-05, -3.0517578e-05], dtype=float32), 16000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and that's what the waveform uses, I think\n",
    "librosa.core.load(path_to_a_wav, sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mateusz\\docume~1\\mateusz\\career\\machin~1\\tensor~2\\trf_venv\\lib\\site-packages\\pydub\\utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from utils import get_wav_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_wav_info(path_to_a_wav)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22050"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(librosa.core.load(path_to_a_wav)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
