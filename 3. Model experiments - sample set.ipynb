{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model experiments - sample set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebooks we have separated a small subset of our data, called \"sample\", on which we can now experiment with simple models to assess the effectiveness of our preprocessing & data augmentation techniques.\n",
    "\n",
    "We do it this way to avoid spending too much time on training on the entire set, the assumption is that the methods which are effective on the sample will work well on a larger scale too. \n",
    "\n",
    "We will start by testing a couple of simple models on untouched sample data (as numpy arrays) and then proceed towards data augmentation and finally spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# first make sure we're in the parent dictory of our data/sample folders.\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "We'll need a couple of additional libraries so let's import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcolz\n",
    "import glob\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow\n",
    "\n",
    "# utils\n",
    "from importlib import reload\n",
    "import utils; reload(utils)\n",
    "\n",
    "# keras as tensorflow backend\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, BatchNormalization, Dropout, Convolution1D, Conv1D, Conv2D, Input\n",
    "from tensorflow.python.keras.layers import MaxPooling1D, MaxPooling2D, Flatten, SimpleRNN, GRU, ConvLSTM2D\n",
    "from tensorflow.python.keras.layers import LSTM, Activation, GlobalMaxPool1D\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "\n",
    "# F1 and accuracy score metric\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "The easiest way to work with data is by turning it into a list of numbers, in our case a numpy array. We can use one of the functions from utils to load the raw data or use the librosa.load() function. The difference lies in the fact that the former returns int16s whereas librosa returns float32s and uses its default sampling rate of 22050Hz, unless we explicitly tell it to use the file's original sampling rate of 16000Hz.\n",
    "\n",
    "We should also consider normalizing our data (so that it all falls within the same scale) and using the preprocessing methods explored in the previous notebook (MFCCs, Mel spectrogram, fast fourier transform and tempogram). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sample = \"data/sample\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll have to go through each of the folders in our sample/train, cv and test sets, one-hot encode their label and load the 16K long array of raw data. The y data will be of shape (m, 12), where m is the number of examples, and the X data will be of shape (m, 16000) - at least for the raw .wav input.\n",
    "\n",
    "Let's calculate **m** first. We will do that by using a function that create a list of all the .wav files within a directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of paths\n",
    "We will use the glob module that we learned about in the very first notebook and a function from util.py which can, given a directory, return a list of paths to .wav files within it. We will repeat the process for all 3 sets within sample, and every category subdirectory within those too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/sample\\\\train\\\\stop\\\\0137b3f4_nohash_4.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\11b1df78_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\29fb33da_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\2f666bb2_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\46a153d8_nohash_2.wav']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example we can grab all .wav files from sample/train/stop\n",
    "path_to_sample_train_stop = os.path.join(path_to_sample, \"train\", \"stop\")\n",
    "utils.grab_wavs(path_to_sample_train_stop)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll need a list of all category folder names\n",
    "categories_to_predict = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"silence\", \"unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/sample\\\\train\\\\yes\\\\01bb6a2a_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\0f3f64d5_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\2da58b32_nohash_4.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\3c8836dc_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\3e31dffe_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\5af0ca83_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\67fcdb05_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\8a28231e_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\918a2473_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\96a48d28_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\9886d8bf_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\a84dee7b_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\ccb1266b_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\dea820ce_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\e0315cf6_nohash_3.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\eb3f7d82_nohash_3.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\f33660af_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\f5c3de1b_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\f953e1af_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\yes\\\\ffd2ba2f_nohash_3.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\152491bc_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\1daa5ada_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\1ecfb537_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\1eddce1d_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\2df590cd_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\3402e488_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\37d38e44_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\3824c00e_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\3bfd30e6_nohash_3.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\3d53244b_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\408de0a4_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\6727b579_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\6b7d5101_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\888a0c49_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\a583c5b0_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\b19f7f5f_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\d90b4138_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\e0315cf6_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\e900b652_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\no\\\\ec201020_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\037c445a_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\13d7b8c9_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\187af8be_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\1dce06e8_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\30065f33_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\3ec05c3d_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\40115b19_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\493392c6_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\66041c69_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\80fe1dc7_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\8e884ec4_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\8f4c551f_nohash_3.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\918a2473_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\a243fcc2_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\b5552931_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\d9b8fab2_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\dedc7fab_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\e72aa705_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\f92e49f3_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\up\\\\fe291fa9_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\016e2c6d_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\05b2db80_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\069ab0d5_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\0a7c2a8d_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\0b77ee66_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\13d7b8c9_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\3bfd30e6_nohash_3.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\5a3712c9_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\7846fd85_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\815f0f03_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\87014d40_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\8eb4a1bf_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\9e6bb505_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\b43de700_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\bbd0bbd0_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\c1d39ce8_nohash_7.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\d7559b2d_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\e2362167_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\f4386675_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\down\\\\f92e49f3_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\0474c92a_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\11321027_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\173e6bbf_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\1c3f50ad_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\324210dd_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\4a1e736b_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\53fd1780_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\70a00e98_nohash_3.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\8134f43f_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\87eff300_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\918a2473_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\a5d485dc_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\afb9e62e_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\b7a0754f_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\b9f46737_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\bfdb9801_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\c634a189_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\c948d727_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\ec201020_nohash_3.wav',\n",
       " 'data/sample\\\\train\\\\left\\\\fafe8101_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\0137b3f4_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\0c2ca723_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\2bd2cad5_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\380abbad_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\3bc21161_nohash_3.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\4a1e736b_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\53fd1780_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\651d108f_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\8134f43f_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\8c4854bc_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\92a9c5e6_nohash_3.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\9aa21fa9_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\b9f46737_nohash_3.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\c37a72d3_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\d84829e0_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\d90b4138_nohash_3.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\dd2a9deb_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\e7ea8b76_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\edd8bfe3_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\right\\\\fb7c9b3b_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\0135f3f2_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\042ea76c_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\190821dc_nohash_3.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\1bb574f9_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\29fb33da_nohash_3.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\35c8fa78_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\39999a0f_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\39a12648_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\3bc21161_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\40b60ae9_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\56cd307a_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\85b877b5_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\b16f2d0d_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\b87bdb22_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\c1e0e8e3_nohash_4.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\c9b653a0_nohash_4.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\d0f7bef5_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\d312f481_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\d31d8dd7_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\on\\\\ffd2ba2f_nohash_4.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\187af8be_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\1b459024_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\24ed94ab_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\2579e514_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\28ed6bc9_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\36050ef3_nohash_4.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\3d53244b_nohash_4.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\3ffa3457_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\42c6fff1_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\51eefcc6_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\71f9bba8_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\834f03fe_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\84bf12ff_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\a84dee7b_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\c0445658_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\c33682f0_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\d0426d63_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\f7b43563_nohash_5.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\fb7cfe0e_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\off\\\\fda46b78_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\0137b3f4_nohash_4.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\11b1df78_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\29fb33da_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\2f666bb2_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\46a153d8_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\48e8b82a_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\57376a4c_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\7c75a504_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\83f9c4ab_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\918a2473_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\96a48d28_nohash_2.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\96d5276f_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\9886d8bf_nohash_4.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\c1d39ce8_nohash_4.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\c93d5e22_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\cb2929ce_nohash_3.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\d0f7bef5_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\da584bc0_nohash_4.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\e20be42a_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\stop\\\\f4504600_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\0397ecda_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\07363607_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\12c206ea_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\38c30a4a_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\39a12648_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\39a12648_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\3cfc6b3a_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\5195f0ec_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\57376a4c_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\686d030b_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\708b8d51_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\8c3c4715_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\9f63152b_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\b06c19b0_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\c0445658_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\c120e80e_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\c1e0e8e3_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\cd911ace_nohash_1.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\e6be0830_nohash_0.wav',\n",
       " 'data/sample\\\\train\\\\go\\\\ec201020_nohash_5.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\doing_the_dishes_39.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\doing_the_dishes_68.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\doing_the_dishes_8.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\doing_the_dishes_86.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\dude_miaowing_30.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\dude_miaowing_39.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\dude_miaowing_57.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\exercise_bike_45.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\exercise_bike_5.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\pink_noise_25.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\pink_noise_31.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\pink_noise_35.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\pink_noise_41.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\pink_noise_47.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\pink_noise_56.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\pink_noise_57.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\running_tap_4.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\white_noise_35.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\white_noise_48.wav',\n",
       " 'data/sample\\\\train\\\\silence\\\\white_noise_57.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\0137b3f4_nohash_4_one.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\187af8be_nohash_0_two.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\2bdbe5f7_nohash_0_cat.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\3411cf4b_nohash_0_eight.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\4c13fe25_nohash_0_nine.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\5be23def_nohash_1_seven.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\5db0e146_nohash_0_dog.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\6d2d3b0d_nohash_0_happy.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\837f7378_nohash_0_bed.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\8c4854bc_nohash_1_bird.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\937b433e_nohash_0_marvin.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\9aa21fa9_nohash_2_two.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\a9b574b3_nohash_1_four.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\b31ad508_nohash_1_seven.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\b3bb4dd6_nohash_0_cat.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\bc065a17_nohash_1_house.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\c0c0d87d_nohash_0_eight.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\cf8d91cf_nohash_0_cat.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\e1aa22e4_nohash_0_four.wav',\n",
       " 'data/sample\\\\train\\\\unknown\\\\fb24c826_nohash_1_tree.wav']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first grab the training set\n",
    "path_to_train = os.path.join(path_to_sample, \"train\")\n",
    "sample_train_wavs = []\n",
    "\n",
    "for category in categories_to_predict:\n",
    "    path_to_category = os.path.join(path_to_train, category)\n",
    "    category_files = utils.grab_wavs(path_to_category)\n",
    "    \n",
    "    # we use extend instead of append to add all elements from the iterable\n",
    "    sample_train_wavs.extend(category_files)\n",
    "    \n",
    "sample_train_wavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for cv\n",
    "path_to_cv = os.path.join(path_to_sample, \"cv\")\n",
    "sample_cv_wavs = []\n",
    "\n",
    "for category in categories_to_predict:\n",
    "    path_to_category = os.path.join(path_to_cv, category)\n",
    "    category_files = utils.grab_wavs(path_to_category)\n",
    "    sample_cv_wavs.extend(category_files)\n",
    "\n",
    "# repeat for test\n",
    "path_to_test = os.path.join(path_to_sample, \"test\")\n",
    "sample_test_wavs = []\n",
    "\n",
    "for category in categories_to_predict:\n",
    "    path_to_category = os.path.join(path_to_test, category)\n",
    "    category_files = utils.grab_wavs(path_to_category)\n",
    "    sample_test_wavs.extend(category_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode the y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the 3 lists of files from each set (train, cv and test) we can construct our train_y, cv_y and test_y numpy arrays. These will be matrices of size (m, 12), one-hot encoded. E.g. if a row belongs to the category \"up\" it will take the form of an array of zeros, where the entry at index 2 (the third from the left) will become a 1.\n",
    "\n",
    "We will use a function from the utils that takes a path to a .wav, the index at which the category name starts within it (we want to control this because we will eventually use this for the main set, not just the sample) and a list of categories to predict. For our current example, the category name in the paths belonging to \"train\" starts at the 18th index (separators count as one char)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/sample\\\\train\\\\left\\\\0474c92a_nohash_1.wav'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's grab a single path (this one is an \"left\")\n",
    "a_wav = sample_train_wavs[80]\n",
    "a_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see if the 1 is correctly placed\n",
    "utils.one_hot_encode_path(a_wav, 18, categories_to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path belonged to the fifth category (\"left\") and the one-hot encoding correctly placed the 1 at index 4 (zero-indexed).\n",
    "\n",
    "We want to repeat this for all examples in each of the 3 subsets, adding each new one-hot encoded numpy array as a new row of the y matrix, in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# figure out the dimensions of train_y\n",
    "rows = len(sample_train_wavs)\n",
    "columns = len(categories_to_predict)\n",
    "dimensions = (rows, columns)\n",
    "dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current shape: 2880\n",
      "New shape: (240, 12)\n"
     ]
    }
   ],
   "source": [
    "# create train_y as empty array\n",
    "train_y = np.array([])\n",
    "\n",
    "# append each row to train_y\n",
    "for path_to_wav in sample_train_wavs:\n",
    "    row = utils.one_hot_encode_path(path_to_wav, 18, categories_to_predict)\n",
    "    \n",
    "    # append the new row\n",
    "    train_y = np.append(train_y, row)\n",
    "    \n",
    "# we currently have a flattened vector\n",
    "print(\"Current shape: {}\".format(*train_y.shape))\n",
    "\n",
    "# let's reshape it\n",
    "train_y = np.reshape(train_y, dimensions)\n",
    "print(\"New shape: {}\".format(train_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the train_y matrix to confirm\n",
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first 3 entries have the 1 at 0th index, which means they belong to category \"up\" and the last three have the 1 at the last index, which is also correct given the fact that our list of paths was also ordered.\n",
    "\n",
    "We should bear in mind that by default the np.array contains float64s and our functions for loading a .wav return int16s.\n",
    "\n",
    "Since this is a highly-repetitive task we'll want to use the utils function for obtaining the y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for **CV set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_cv_wavs' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c1538ba1ab16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# figure out the dimensions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_cv_wavs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories_to_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdimensions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Target dimensions: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_cv_wavs' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# figure out the dimensions\n",
    "rows = len(sample_cv_wavs)\n",
    "columns = len(categories_to_predict)\n",
    "dimensions = (rows, columns)\n",
    "print(\"Target dimensions: {}\".format(dimensions))\n",
    "\n",
    "# get the y\n",
    "cv_y = utils.get_y(sample_cv_wavs, 15, categories_to_predict)\n",
    "print(\"Received shape: {}\".format(cv_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for **Test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target dimensions: (60, 12)\n",
      "Received shape: (60, 12)\n"
     ]
    }
   ],
   "source": [
    "# figure out the dimensions\n",
    "rows = len(sample_test_wavs)\n",
    "columns = len(categories_to_predict)\n",
    "dimensions = (rows, columns)\n",
    "print(\"Target dimensions: {}\".format(dimensions))\n",
    "\n",
    "# get the y\n",
    "test_y = utils.get_y(sample_test_wavs, 17, categories_to_predict)\n",
    "print(\"Received shape: {}\".format(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the X\n",
    "We have the y - the one-hot encoded vectors representing the category for each training, cv and test example in the sample set. We need the feature vectors, conventionally referred to as X. We will use both the simplest way of extracting the .wav data and the preprocessing techniques - MFCCs, Mel spectrogram, FFT and tempogram.\n",
    "\n",
    "Let's start by defining a simple helper function for just the raw .wav data. Since our samples are of slightly differing lengths but each row of our X always has to have the same length, we will **add padding by default.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the desired number of columns (n)\n",
    "n = len(utils.get_wav_info(path_to_wav)[1])\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw .wav data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple helper function\n",
    "def get_X_with_padding(list_of_paths, columns=16000):\n",
    "    \n",
    "    # get shape data\n",
    "    rows = len(list_of_paths)\n",
    "    dimensions = (rows, columns)\n",
    "    \n",
    "    # create placeholder\n",
    "    X = np.array([])\n",
    "    \n",
    "    # go through every file path in the list\n",
    "    for path_to_wav in list_of_paths:\n",
    "\n",
    "        # get raw array of signed ints\n",
    "        row = utils.get_wav_info(path_to_wav)[1]\n",
    "        \n",
    "        # some of our sample have less (or slightly more) than 16000 values, so let's adjust them\n",
    "        # trim to fixed length\n",
    "        row = row[:columns]\n",
    "        \n",
    "        # pad with zeros, calculating amount of padding needed\n",
    "        padding = columns - len(row)\n",
    "        row = np.pad(row, (0, padding), mode='constant', constant_values=0)\n",
    "\n",
    "        # append the new row\n",
    "        X = np.append(X, row)\n",
    "    \n",
    "    # reshape (unroll)\n",
    "    X = np.reshape(X, dimensions)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (240, 16000)\n",
      "CV:  (60, 16000)\n",
      "Test:  (60, 16000)\n"
     ]
    }
   ],
   "source": [
    "# get the X for each set\n",
    "train_X = utils.get_X(sample_train_wavs, n)\n",
    "cv_X = utils.get_X(sample_cv_wavs, n)\n",
    "test_X = utils.get_X(sample_test_wavs, n)\n",
    "\n",
    "print(\"Train: \", train_X.shape)\n",
    "print(\"CV: \", cv_X.shape)\n",
    "print(\"Test: \",test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MFCCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do the same for the MFCCs. We have a choice of whether or not we want to get returned only the mean value (1D) for the MFCCs. For now let's obtain both the 1D (mean) and 2D version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start with a reasonable number of mfccs to return\n",
    "n_mfcc = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mfccs:  (240, 100)\n",
      "CV mfccs:  (60, 100)\n",
      "Test mfccs:  (60, 100)\n"
     ]
    }
   ],
   "source": [
    "train_X_mfccs_1D = utils.get_X_mfccs(sample_train_wavs, shape=(n_mfcc, 32), mean=True)\n",
    "cv_X_mfccs_1D = utils.get_X_mfccs(sample_cv_wavs, shape=(n_mfcc, 32), mean=True)\n",
    "test_X_mfccs_1D = utils.get_X_mfccs(sample_test_wavs, shape=(n_mfcc, 32), mean=True)\n",
    "\n",
    "print(\"Train mfccs: \", train_X_mfccs_1D.shape)\n",
    "print(\"CV mfccs: \", cv_X_mfccs_1D.shape)\n",
    "print(\"Test mfccs: \",test_X_mfccs_1D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-572.50470616,  -11.80156799,   36.27707263,   12.83271811,\n",
       "         -5.44036651])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_mfccs_1D[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for the 2-dim output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mfccs:  (240, 100, 32)\n",
      "CV mfccs:  (60, 100, 32)\n",
      "Test mfccs:  (60, 100, 32)\n"
     ]
    }
   ],
   "source": [
    "train_X_mfccs_2D = utils.get_X_mfccs(sample_train_wavs, shape=(n_mfcc, 32), mean=False)\n",
    "cv_X_mfccs_2D = utils.get_X_mfccs(sample_cv_wavs, shape=(n_mfcc, 32), mean=False)\n",
    "test_X_mfccs_2D = utils.get_X_mfccs(sample_test_wavs, shape=(n_mfcc, 32), mean=False)\n",
    "\n",
    "print(\"Train mfccs: \", train_X_mfccs_2D.shape)\n",
    "print(\"CV mfccs: \", cv_X_mfccs_2D.shape)\n",
    "print(\"Test mfccs: \",test_X_mfccs_2D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-735.47325507, -735.47325507, -735.47325507, -735.47325507,\n",
       "       -735.47325507])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_mfccs_2D[0][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mel spectrogam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of Mel spectrograms we expect to get a matrix from a vector, therefore our final X will be 3 dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data shape: (16000,)\n",
      "Mel spectrogram shape: (128, 32)\n"
     ]
    }
   ],
   "source": [
    "# let's see the difference in dimensions\n",
    "sr, raw_data = utils.get_wav_info(path_to_wav)\n",
    "print(\"Raw data shape: {}\".format(raw_data.shape))\n",
    "x = librosa.feature.melspectrogram(raw_data, sr)\n",
    "print(\"Mel spectrogram shape: {}\".format(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's the function we'll use (via utils.py)\n",
    "def get_X_mel_spectrogram(list_of_paths, shape=(128, 32)):\n",
    "\n",
    "    # get shape data\n",
    "    rows = len(list_of_paths)\n",
    "\n",
    "    # create placeholder\n",
    "    result = np.array([])\n",
    "\n",
    "    # go through every file path in the list\n",
    "    for path_to_wav in list_of_paths:\n",
    "        \n",
    "        # get raw array of signed ints\n",
    "        sr, raw_data = utils.get_wav_info(path_to_wav)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(raw_data, sr)\n",
    "\n",
    "        # some of our samples have less (or slightly more) than the expected amount of values,\n",
    "        # so let's adjust them\n",
    "        placeholder = np.array([])\n",
    "        for row in mel_spectrogram:\n",
    "            \n",
    "            # trim to fixed length\n",
    "            row = row[:shape[1]]\n",
    "\n",
    "            # pad with zeros, calculating amount of padding needed\n",
    "            padding = shape[1] - len(row)\n",
    "            row = np.pad(row, (0, padding), mode='constant', constant_values=0)\n",
    "\n",
    "            # append the new row\n",
    "            placeholder = np.append(placeholder, row)\n",
    "        \n",
    "        # append the new unrolled matrix to the final result array\n",
    "        result = np.append(result, placeholder)\n",
    "    \n",
    "    # reshape into a 3-dim matrix\n",
    "    result = np.reshape(result, (len(list_of_paths), shape[0], shape[1]))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's obtain the Mel spectrograms for all sample sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mel spectrogram:  (240, 128, 32)\n",
      "CV mel spectrogram:  (60, 128, 32)\n",
      "Test mel spectrogram:  (60, 128, 32)\n"
     ]
    }
   ],
   "source": [
    "train_X_mel_spectrogram = utils.get_X_mel_spectrogram(sample_train_wavs)\n",
    "cv_X_mel_spectrogram = utils.get_X_mel_spectrogram(sample_cv_wavs)\n",
    "test_X_mel_spectrogram = utils.get_X_mel_spectrogram(sample_test_wavs)\n",
    "\n",
    "print(\"Train mel spectrogram: \", train_X_mel_spectrogram.shape)\n",
    "print(\"CV mel spectrogram: \", cv_X_mel_spectrogram.shape)\n",
    "print(\"Test mel spectrogram: \",test_X_mel_spectrogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.94466729e-06, 9.75222757e+02, 1.23508695e+04,\n",
       "       1.24593193e+04, 6.12230943e+03, 1.02706996e+03, 3.55268923e+03,\n",
       "       3.17763402e+04, 4.54406250e+05, 6.08294899e+05, 7.22910299e+05,\n",
       "       1.92773820e+05, 1.63454636e+06, 3.26517280e+06, 4.86702091e+05,\n",
       "       7.95720134e+04, 3.83460330e+04, 6.43597135e+03, 9.39225075e+03,\n",
       "       6.04833381e+03, 2.24258679e+03, 8.12460657e+02, 3.27471155e+02,\n",
       "       9.25234895e+02, 7.34524897e+03, 9.47712779e+03, 5.80768652e+03])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each row is a 2D matrix (hence double-indexing)\n",
    "train_X_mel_spectrogram[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFT (Fast Fourier Transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's obtain the FFT of our raw data too. For simplicity the utils.get_X_fft() function casts the complex numbers to the numpy float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here the shapes are the same\n",
    "x = utils.extract_fft(path_to_wav)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train fft:  (240, 16000)\n",
      "CV fft:  (60, 16000)\n",
      "Test fft:  (60, 16000)\n"
     ]
    }
   ],
   "source": [
    "train_X_fft = utils.get_X_fft(sample_train_wavs)\n",
    "cv_X_fft = utils.get_X_fft(sample_cv_wavs)\n",
    "test_X_fft = utils.get_X_fft(sample_test_wavs)\n",
    "\n",
    "print(\"Train fft: \", train_X_fft.shape)\n",
    "print(\"CV fft: \", cv_X_fft.shape)\n",
    "print(\"Test fft: \",test_X_fft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-24956.        ,   -626.89244346,    133.50596235,   -170.42685838,\n",
       "         3458.66063391])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no longer complex numbers\n",
    "print(type(test_X_fft[0][0]))\n",
    "test_X_fft[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tempogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With tempogram we have to do some reshaping to get a 3D matrix, just like with Mel spectrograms. We will also have to do a little bit of padding and trimming, to account for small differences in the length of the original sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempogram: (384, 32)\n"
     ]
    }
   ],
   "source": [
    "# let's see the difference in dimensions\n",
    "x = utils.extract_tempogram(path_to_wav)\n",
    "print(\"Tempogram: {}\".format(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tempogram:  (240, 384, 32)\n",
      "CV tempogram:  (60, 384, 32)\n",
      "Test tempogram:  (60, 384, 32)\n"
     ]
    }
   ],
   "source": [
    "train_X_tempogram = utils.get_X_tempogram(sample_train_wavs)\n",
    "cv_X_tempogram = utils.get_X_tempogram(sample_cv_wavs)\n",
    "test_X_tempogram = utils.get_X_tempogram(sample_test_wavs)\n",
    "\n",
    "print(\"Train tempogram: \", train_X_tempogram.shape)\n",
    "print(\"CV tempogram: \", cv_X_tempogram.shape)\n",
    "print(\"Test tempogram: \",test_X_tempogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23420628, 0.2343953 , 0.23458453, 0.23477399, 0.23496373,\n",
       "       0.23515377, 0.23534414, 0.23553488, 0.235726  , 0.23591756,\n",
       "       0.23610957, 0.23630207, 0.23649509, 0.23668866, 0.23688283,\n",
       "       0.23707761, 0.23727305, 0.23746918, 0.23766602, 0.23786363,\n",
       "       0.23806203, 0.23826126, 0.23846136, 0.23866236, 0.2388643 ,\n",
       "       0.23906723, 0.23927117, 0.23947617, 0.23968227, 0.23988951,\n",
       "       0.24009793, 0.24030758])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each row is a 2D matrix (hence double-indexing)\n",
    "train_X_tempogram[0][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist the preprocessed X and y\n",
    "It's good practice to persist your preprocessed datasets so that we don't have to recalculate all of the preprocessing (which in large datasets can be time-consuming). \n",
    "\n",
    "A great library for this purpose is the bcolz library (for binary columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the bcolz array saving functions\n",
    "def bcolz_save(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def bcolz_load(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sample = \"data\\\\sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data\\\\sample\\\\preprocessed'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_sample_preprocessed = os.path.join(path_to_sample, \"preprocessed\")\n",
    "path_to_sample_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the directory if it's not there already\n",
    "!mkdir $path_to_sample_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persist the y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the y\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"train_y\" + \".bc\", train_y)\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"cv_y\" + \".bc\", cv_y)\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"test_y\" + \".bc\", test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persist the X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the X\n",
    "# raw data\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"train_X\" + \".bc\", train_X)\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"cv_X\" + \".bc\", cv_X)\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"test_X\" + \".bc\", test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCCs (1dim and 2dim)\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"train_X_mfccs_1D\" + \".bc\", train_X_mfccs_1D)\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"cv_X_mfccs_1D\" + \".bc\", cv_X_mfccs_1D)\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"test_X_mfccs_1D\" + \".bc\", test_X_mfccs_1D)\n",
    "\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"train_X_mfccs_2D\" + \".bc\", train_X_mfccs_2D)\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"cv_X_mfccs_2D\" + \".bc\", cv_X_mfccs_2D)\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"test_X_mfccs_2D\" + \".bc\", test_X_mfccs_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mel spectrogram\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"train_X_mel_spectrogram\" + \".bc\", train_X_mel_spectrogram)\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"cv_X_mel_spectrogram\" + \".bc\", cv_X_mel_spectrogram)\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"test_X_mel_spectrogram\" + \".bc\", test_X_mel_spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"train_X_fft\" + \".bc\", train_X_fft)\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"cv_X_fft\" + \".bc\", cv_X_fft)\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"test_X_fft\" + \".bc\", test_X_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tempogram\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"train_X_tempogram\" + \".bc\", train_X_tempogram)\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"cv_X_tempogram\" + \".bc\", cv_X_tempogram)\n",
    "bcolz_save(path_to_sample_preprocessed + os.path.sep + \"test_X_tempogram\" + \".bc\", test_X_tempogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the preprocessed X and y\n",
    "In order not to have to re-run the entire notebook to obtain the preprocessed X and the corresponding y matrices, let's reload them and then proceed to train simple models.\n",
    "\n",
    "If you're reloading the X & y after restarting the notebook you will also have to run the cells that define the bcolz functions and the path names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload the y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the y\n",
    "train_y = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"train_y\" + \".bc\")\n",
    "cv_y = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"cv_y\" + \".bc\")\n",
    "test_y = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"test_y\" + \".bc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload the X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 16000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the X\n",
    "# raw data\n",
    "train_X = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"train_X\" + \".bc\")\n",
    "cv_X = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"cv_X\" + \".bc\")\n",
    "test_X = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"test_X\" + \".bc\")\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 100)\n",
      "(240, 100, 32)\n"
     ]
    }
   ],
   "source": [
    "# MFCCs (1D and 2D)\n",
    "train_X_mfccs_1D = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"train_X_mfccs_1D\" + \".bc\")\n",
    "cv_X_mfccs_1D = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"cv_X_mfccs_1D\" + \".bc\")\n",
    "test_X_mfccs_1D = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"test_X_mfccs_1D\" + \".bc\")\n",
    "print(train_X_mfccs_1D.shape)\n",
    "\n",
    "train_X_mfccs_2D = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"train_X_mfccs_2D\" + \".bc\")\n",
    "cv_X_mfccs_2D = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"cv_X_mfccs_2D\" + \".bc\")\n",
    "test_X_mfccs_2D = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"test_X_mfccs_2D\" + \".bc\")\n",
    "print(train_X_mfccs_2D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 128, 32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mel spectrogram\n",
    "train_X_mel_spectrogram = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"train_X_mel_spectrogram\" + \".bc\")\n",
    "cv_X_mel_spectrogram = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"cv_X_mel_spectrogram\" + \".bc\")\n",
    "test_X_mel_spectrogram = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"test_X_mel_spectrogram\" + \".bc\")\n",
    "train_X_mel_spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 16000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FFT\n",
    "train_X_fft = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"train_X_fft\" + \".bc\")\n",
    "cv_X_fft = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"cv_X_fft\" + \".bc\")\n",
    "test_X_fft = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"test_X_fft\" + \".bc\")\n",
    "train_X_fft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 384, 32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tempogram\n",
    "train_X_tempogram = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"train_X_tempogram\" + \".bc\")\n",
    "cv_X_tempogram = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"cv_X_tempogram\" + \".bc\")\n",
    "test_X_tempogram = bcolz_load(path_to_sample_preprocessed + os.path.sep + \"test_X_tempogram\" + \".bc\")\n",
    "train_X_tempogram.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train simple models\n",
    "We will start by training the simplest models and then try out more and more complex architectures, aiming for the highest possible accuracy and F1 score.\n",
    "\n",
    "The simplest model we can try is a linear model, which we can obtain by using the Keras Dense layer followed by an activation function such as softmax (as in our case categories are mutually exclusive).\n",
    "\n",
    "Since we have 12 mutually exclusive categories, we need to get an **accuracy of more than 0.833%** to beat random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Model\n",
    "We'll need to keep track of the dimensions that we pass into our models, so lets assign their values to separate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: 16000\n",
      "Categories to predict: 12\n"
     ]
    }
   ],
   "source": [
    "# we'll need the number of parameters and the output categories\n",
    "num_features = train_X.shape[1]\n",
    "num_categories = train_y.shape[1]\n",
    "print(\"Input features: {}\\nCategories to predict: {}\".format(num_features, num_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design & compile the model\n",
    "linear_model = Sequential([\n",
    "    Dense(input_shape=(num_features,), units = num_categories, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# we choose the Adam optimizer with a specific learning rate\n",
    "linear_model.compile(Adam(lr=0.001),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on random weights initialization (values will change everytime you compile the model)\n",
      "Categorical crossentropy (loss): 14.7749\n",
      "Accuracy: 0.08\n"
     ]
    }
   ],
   "source": [
    "# let's evaluate our loss before fitting the model\n",
    "initial_score = linear_model.evaluate(test_X, test_y, verbose=0)\n",
    "categorical_crossentropy = initial_score[0]\n",
    "accuracy = initial_score[1]\n",
    "\n",
    "print(\"Based on random weights initialization (values will change everytime you compile the model)\\nCategorical crossentropy (loss): {:.4f}\\nAccuracy: {:.2f}\".format(categorical_crossentropy, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit our simple linear model for a couple of epochs and see the **F1 score** and **accuracy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/5\n",
      "240/240 [==============================] - 0s - loss: 14.8369 - acc: 0.0792 - val_loss: 15.0436 - val_acc: 0.0667\n",
      "Epoch 2/5\n",
      "240/240 [==============================] - 0s - loss: 14.9092 - acc: 0.0750 - val_loss: 15.0436 - val_acc: 0.0667\n",
      "Epoch 3/5\n",
      "240/240 [==============================] - 0s - loss: 14.8421 - acc: 0.0792 - val_loss: 15.0436 - val_acc: 0.0667\n",
      "Epoch 4/5\n",
      "240/240 [==============================] - 0s - loss: 14.7749 - acc: 0.0833 - val_loss: 15.0436 - val_acc: 0.0667\n",
      "Epoch 5/5\n",
      "240/240 [==============================] - 0s - loss: 14.7749 - acc: 0.0833 - val_loss: 15.0436 - val_acc: 0.0667\n"
     ]
    }
   ],
   "source": [
    "# we pass our training data and our cross-validation data to see if we're not overfitting\n",
    "history = linear_model.fit(train_X, train_y, batch_size=32, epochs=5, validation_data=(cv_X, cv_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-185872964630>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# show latest results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbest_training_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mbest_validation_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best scores\\nTrain acc: {:.4f}\\nCV acc: {:.4f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_training_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_validation_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# show latest results\n",
    "best_training_accuracy = max(history.history[\"acc\"])\n",
    "best_validation_accuracy = max(history.history[\"val_acc\"])\n",
    "print(\"Best scores\\nTrain acc: {:.4f}\\nCV acc: {:.4f}\".format(best_training_accuracy, best_validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the random initialization of weights we should have an **accuracy** score within 0.05 and 0.15 on both the training and cross-validation set. Let's also calculate the **F1 score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first use the model to predict the labels\n",
    "pred_cv_y = linear_model.predict(cv_X, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 12)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cv_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 12)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if shape matches expectation (number of examples, number of categories to predict)\n",
    "pred_cv_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [1.0453914e-06, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        9.9999893e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use softmax to get a result towards one-hot encoding, but not all rows will necessarily be just zeroes and one 1\n",
    "pred_cv_y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So before we pass our predictions to the sklearn's f1 score function we need to make sure that all of our rows are actually one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cv_y = utils.one_hot_encode(pred_cv_y)\n",
    "pred_cv_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final linear model CV accuracy via sklearn: 0.0500\n"
     ]
    }
   ],
   "source": [
    "# we can also use sklearn directly to get accuracy\n",
    "sk_cv_accuracy = accuracy_score(cv_y, pred_cv_y)\n",
    "print(\"Final linear model CV accuracy via sklearn: {:.4f}\".format(sk_cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model f1 score (CV): 0.0470\n"
     ]
    }
   ],
   "source": [
    "# because we're dealing with a mutliclass classification challenge, we need to change the default value of average\n",
    "# (which is binary)\n",
    "cv_f1_score = f1_score(cv_y, pred_cv_y, average=\"weighted\")\n",
    "print(\"Linear model f1 score (CV): {:.4f}\".format(cv_f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, our accuracy and F1 score for the simplest possible model fall within 0.05 - 0.15. This is our earliest benchmark to beat, and it's **not much better than random guessing**, which given 12 categories would give us an accuracy of 0.08333."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "It is also useful to try other ML methods before jumping into neural networks and deep learning. Random Forests are a simple but very often quite effective (and computationally inexpensive) method of obtaining a good benchmark.\n",
    "\n",
    "For the sklearn implementation of Random Forest we actually do not want our target to be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse the one-hot encoding\n",
    "rf_train_y = utils.reverse_one_hot_encoding(train_y)\n",
    "rf_cv_y = utils.reverse_one_hot_encoding(cv_y)\n",
    "rf_test_y = utils.reverse_one_hot_encoding(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "rand_forest.fit(train_X, rf_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.,  2.,  8.,  7.,  8.,  1., 11., 12.,  9.,  1.,  5.,  4.,  6.,\n",
       "        7., 10.,  4.,  8.,  1.,  5.,  8.,  9.,  1., 11.,  8.,  1.,  7.,\n",
       "        4.,  6.,  2.,  8.,  5.,  3.,  9.,  3.,  1.,  7.,  3.,  3.,  3.,\n",
       "        1.,  4.,  5., 12.,  1.,  2.,  4., 10., 12., 11.,  1.,  8.,  7.,\n",
       "       11.,  7., 11.,  2.,  3.,  3.,  2.,  9.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_predicted_cv_y = rand_forest.predict(cv_X)\n",
    "rf_predicted_cv_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest f1 score (CV): 0.095\n",
      "Random forest accuracy (CV): 0.083\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy and F1 for Random Forest\n",
    "rf_cv_f1_score = f1_score(rf_cv_y, rf_predicted_cv_y, average=\"weighted\")\n",
    "rf_cv_accuracy = accuracy_score(rf_cv_y, rf_predicted_cv_y)\n",
    "\n",
    "print(\"Random forest f1 score (CV): {:.3f}\".format(rf_cv_f1_score))\n",
    "print(\"Random forest accuracy (CV): {:.3f}\".format(rf_cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Random Forest method, using only default parameters (except for max depth), we are getting an **F1 score and accuracy around 0.10 - 0.15**.<br/> Slightly better than random, nowhere near good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set benchmark\n",
    "best_cv_acc = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Neural Networks\n",
    "Now that we have a benchmark obtained via simple linear and Random Forest models we can proceed towards trying to outdo it with MLPs and deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP - multi-layer perceptron\n",
    "Let's start with the simplest possible neural network of just 2 dense layers. We'll be working only on the mfccs data from now on, as it tends to produce better results. We will also add **batch normalization** and **dropout** to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design & compile the model\n",
    "num_nodes = 2000\n",
    "mlp = Sequential([\n",
    "    Dense(input_shape=(num_features,), units = num_nodes, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.96),\n",
    "    Dense(num_categories, activation='softmax')\n",
    "])\n",
    "\n",
    "# we choose the Adam optimizer with a specific learning rate\n",
    "mlp.compile(Adam(lr=0.001),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 3s - loss: 8.2435 - acc: 0.0958 - val_loss: 6.3584 - val_acc: 0.0833\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 2s - loss: 7.8047 - acc: 0.1000 - val_loss: 3.9879 - val_acc: 0.0667\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 2s - loss: 6.5026 - acc: 0.1292 - val_loss: 3.5573 - val_acc: 0.1000\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 2s - loss: 6.4385 - acc: 0.1167 - val_loss: 3.2334 - val_acc: 0.0833\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 2s - loss: 6.0878 - acc: 0.1583 - val_loss: 2.9742 - val_acc: 0.1333\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 2s - loss: 5.5775 - acc: 0.2042 - val_loss: 2.9128 - val_acc: 0.1500\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 2s - loss: 6.0301 - acc: 0.1750 - val_loss: 2.8771 - val_acc: 0.1500\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 2s - loss: 5.5120 - acc: 0.1917 - val_loss: 2.8346 - val_acc: 0.1500\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 2s - loss: 5.1921 - acc: 0.2375 - val_loss: 2.8122 - val_acc: 0.1333\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 2s - loss: 4.7076 - acc: 0.3000 - val_loss: 2.7891 - val_acc: 0.1500\n"
     ]
    }
   ],
   "source": [
    "mlp_results = mlp.fit(train_X, train_y, batch_size=32, epochs=10, validation_data=(cv_X, cv_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MLP scores\n",
      "Train acc: 0.3000\n",
      "CV acc: 0.1500\n"
     ]
    }
   ],
   "source": [
    "# show latest results\n",
    "best_training_accuracy = max(mlp_results.history[\"acc\"])\n",
    "best_validation_accuracy = max(mlp_results.history[\"val_acc\"])\n",
    "print(\"Best MLP scores\\nTrain acc: {:.4f}\\nCV acc: {:.4f}\".format(best_training_accuracy, best_validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 12)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict and one-hot encode\n",
    "mlp_pred_cv_y = mlp.predict(cv_X, batch_size=32)\n",
    "mlp_pred_cv_y = utils.one_hot_encode(mlp_pred_cv_y)\n",
    "mlp_pred_cv_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP accuracy via sklearn (CV): 0.1500\n",
      "MLP f1 score (CV): 0.1499\n"
     ]
    }
   ],
   "source": [
    "# we can also use sklearn directly to get accuracy\n",
    "mlp_cv_accuracy = accuracy_score(cv_y, mlp_pred_cv_y)\n",
    "mlp_cv_f1_score = f1_score(cv_y, mlp_pred_cv_y, average=\"weighted\")\n",
    "print(\"MLP accuracy via sklearn (CV): {:.4f}\".format(mlp_cv_accuracy))\n",
    "print(\"MLP f1 score (CV): {:.4f}\".format(mlp_cv_f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a simple MLP model reaches a very similar accuracy score to our previous benchmark of 0.15. Both this one and the previous ones can be tuned to reach approximately 0.25 but let's save fine-tuning for when we have a more promising approach - we are also already overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Neural Networks\n",
    "Let's try adding more layers to capture more complex interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = Sequential([\n",
    "    Dense(input_shape=(num_features,), units = 4000, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.8),\n",
    "    Dense(3000, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.85),\n",
    "    Dense(2000, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.9),\n",
    "    Dense(num_categories, activation='softmax')\n",
    "])\n",
    "\n",
    "# we choose the Adam optimizer with a specific learning rate\n",
    "dnn.compile(Adam(lr=0.001),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s - loss: 6.7286 - acc: 0.0958 - val_loss: 7.9826 - val_acc: 0.0833\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 3s - loss: 6.5261 - acc: 0.0917 - val_loss: 4.9535 - val_acc: 0.1000\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 3s - loss: 6.0344 - acc: 0.1333 - val_loss: 4.2601 - val_acc: 0.0833\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 3s - loss: 5.7909 - acc: 0.0875 - val_loss: 3.7598 - val_acc: 0.0500\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 3s - loss: 6.0803 - acc: 0.1000 - val_loss: 3.2002 - val_acc: 0.0500\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 3s - loss: 5.9077 - acc: 0.0958 - val_loss: 3.0013 - val_acc: 0.0667\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 3s - loss: 5.6614 - acc: 0.0792 - val_loss: 2.9356 - val_acc: 0.1167\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 3s - loss: 5.8123 - acc: 0.0958 - val_loss: 2.8923 - val_acc: 0.1500\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 3s - loss: 5.5146 - acc: 0.1375 - val_loss: 2.9007 - val_acc: 0.1500\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 3s - loss: 5.2759 - acc: 0.1500 - val_loss: 2.9153 - val_acc: 0.1500\n"
     ]
    }
   ],
   "source": [
    "dnn_results = dnn.fit(train_X, train_y, batch_size=64, epochs=10, validation_data=(cv_X, cv_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best DNN scores\n",
      "Train acc: 0.1500\n",
      "CV acc: 0.1500\n"
     ]
    }
   ],
   "source": [
    "# show latest results\n",
    "best_training_accuracy = max(dnn_results.history[\"acc\"])\n",
    "best_validation_accuracy = max(dnn_results.history[\"val_acc\"])\n",
    "print(\"Best DNN scores\\nTrain acc: {:.4f}\\nCV acc: {:.4f}\".format(best_training_accuracy, best_validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 12)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict and one-hot encode\n",
    "dnn_pred_cv_y = dnn.predict(cv_X, batch_size=32)\n",
    "dnn_pred_cv_y = utils.one_hot_encode(dnn_pred_cv_y)\n",
    "dnn_pred_cv_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN accuracy via sklearn (CV): 0.1500\n",
      "DNN f1 score (CV): 0.1133\n"
     ]
    }
   ],
   "source": [
    "# we can also use sklearn directly to get accuracy\n",
    "dnn_cv_accuracy = accuracy_score(cv_y, dnn_pred_cv_y)\n",
    "dnn_cv_f1_score = f1_score(cv_y, dnn_pred_cv_y, average=\"weighted\")\n",
    "print(\"DNN accuracy via sklearn (CV): {:.4f}\".format(dnn_cv_accuracy))\n",
    "print(\"DNN f1 score (CV): {:.4f}\".format(dnn_cv_f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Models\n",
    "Seems we're stuck around 0.15 accuracy. That makes sense because the actual \"no\" and other words may come at any place in the vector, we can't really keep being attached to specific indexes when training (which we currently are). Let's try convolutional layers, which can find certain patterns regardless of whether they appear at the start or end of the file.\n",
    "\n",
    "We will also move towards using our preprocessed data as convolutions work better with data that conveys dimensionality, beginning with mean MFCCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 100, 1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to use convolutions we have to reshape our X -> expand it to 3 dimensions\n",
    "conv_train_X_mfccs_1D = np.expand_dims(train_X_mfccs_1D, axis=2)\n",
    "conv_train_X_mfccs_1D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for cv & test\n",
    "conv_cv_X_mfccs_1D = np.expand_dims(cv_X_mfccs_1D, axis=2)\n",
    "conv_test_X_mfccs_1D = np.expand_dims(test_X_mfccs_1D, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1 = Sequential([\n",
    "        Convolution1D(input_shape=(conv_train_X_mfccs_1D.shape[1], 1), kernel_size=64, filters=64, padding=\"same\", activation=\"relu\"),\n",
    "        Dropout(0.12),\n",
    "        MaxPooling1D(),\n",
    "        Convolution1D(kernel_size=64, filters=64, padding=\"same\", activation=\"relu\"),\n",
    "        Dropout(0.12),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dense(2000, activation=\"relu\"),\n",
    "        Dropout(.7),\n",
    "        Dense(num_categories, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "cnn1.compile(Adam(lr=0.0001),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/80\n",
      "240/240 [==============================] - 2s - loss: 9.0299 - acc: 0.0917 - val_loss: 4.7122 - val_acc: 0.1167\n",
      "Epoch 2/80\n",
      "240/240 [==============================] - 0s - loss: 7.4429 - acc: 0.1208 - val_loss: 2.8284 - val_acc: 0.1167\n",
      "Epoch 3/80\n",
      "240/240 [==============================] - 0s - loss: 5.9821 - acc: 0.0750 - val_loss: 3.1201 - val_acc: 0.1500\n",
      "Epoch 4/80\n",
      "240/240 [==============================] - 0s - loss: 5.2001 - acc: 0.0958 - val_loss: 2.5003 - val_acc: 0.1833\n",
      "Epoch 5/80\n",
      "240/240 [==============================] - 0s - loss: 4.1264 - acc: 0.1000 - val_loss: 2.5581 - val_acc: 0.1167\n",
      "Epoch 6/80\n",
      "240/240 [==============================] - 0s - loss: 3.8282 - acc: 0.0833 - val_loss: 2.4932 - val_acc: 0.1500\n",
      "Epoch 7/80\n",
      "240/240 [==============================] - 0s - loss: 3.1335 - acc: 0.1375 - val_loss: 2.4176 - val_acc: 0.1833\n",
      "Epoch 8/80\n",
      "240/240 [==============================] - 0s - loss: 2.8177 - acc: 0.1375 - val_loss: 2.4147 - val_acc: 0.1500\n",
      "Epoch 9/80\n",
      "240/240 [==============================] - 0s - loss: 2.6024 - acc: 0.1750 - val_loss: 2.4203 - val_acc: 0.1833\n",
      "Epoch 10/80\n",
      "240/240 [==============================] - 0s - loss: 2.6968 - acc: 0.1542 - val_loss: 2.4164 - val_acc: 0.1333\n",
      "Epoch 11/80\n",
      "240/240 [==============================] - 0s - loss: 2.6537 - acc: 0.1208 - val_loss: 2.4124 - val_acc: 0.1000\n",
      "Epoch 12/80\n",
      "240/240 [==============================] - 0s - loss: 2.5441 - acc: 0.1292 - val_loss: 2.4133 - val_acc: 0.1167\n",
      "Epoch 13/80\n",
      "240/240 [==============================] - 0s - loss: 2.5055 - acc: 0.1667 - val_loss: 2.4194 - val_acc: 0.1500\n",
      "Epoch 14/80\n",
      "240/240 [==============================] - 0s - loss: 2.4240 - acc: 0.1333 - val_loss: 2.4230 - val_acc: 0.1333\n",
      "Epoch 15/80\n",
      "240/240 [==============================] - 0s - loss: 2.5024 - acc: 0.1292 - val_loss: 2.4231 - val_acc: 0.1167\n",
      "Epoch 16/80\n",
      "240/240 [==============================] - 0s - loss: 2.4374 - acc: 0.1292 - val_loss: 2.4203 - val_acc: 0.1500\n",
      "Epoch 17/80\n",
      "240/240 [==============================] - 0s - loss: 2.4345 - acc: 0.1250 - val_loss: 2.4158 - val_acc: 0.1833\n",
      "Epoch 18/80\n",
      "240/240 [==============================] - 0s - loss: 2.3647 - acc: 0.1625 - val_loss: 2.4073 - val_acc: 0.1667\n",
      "Epoch 19/80\n",
      "240/240 [==============================] - 0s - loss: 2.3628 - acc: 0.1917 - val_loss: 2.4035 - val_acc: 0.1833\n",
      "Epoch 20/80\n",
      "240/240 [==============================] - 0s - loss: 2.3965 - acc: 0.1333 - val_loss: 2.3932 - val_acc: 0.1500\n",
      "Epoch 21/80\n",
      "240/240 [==============================] - 0s - loss: 2.4011 - acc: 0.1667 - val_loss: 2.3862 - val_acc: 0.1667\n",
      "Epoch 22/80\n",
      "240/240 [==============================] - 0s - loss: 2.3722 - acc: 0.1750 - val_loss: 2.3813 - val_acc: 0.1500\n",
      "Epoch 23/80\n",
      "240/240 [==============================] - 0s - loss: 2.3800 - acc: 0.1750 - val_loss: 2.3693 - val_acc: 0.1833\n",
      "Epoch 24/80\n",
      "240/240 [==============================] - 0s - loss: 2.3764 - acc: 0.1583 - val_loss: 2.3634 - val_acc: 0.2000\n",
      "Epoch 25/80\n",
      "240/240 [==============================] - 0s - loss: 2.3949 - acc: 0.1750 - val_loss: 2.3640 - val_acc: 0.2000\n",
      "Epoch 26/80\n",
      "240/240 [==============================] - 0s - loss: 2.3283 - acc: 0.1792 - val_loss: 2.3643 - val_acc: 0.1833\n",
      "Epoch 27/80\n",
      "240/240 [==============================] - 0s - loss: 2.3960 - acc: 0.1667 - val_loss: 2.3627 - val_acc: 0.2167\n",
      "Epoch 28/80\n",
      "240/240 [==============================] - 0s - loss: 2.3812 - acc: 0.1792 - val_loss: 2.3500 - val_acc: 0.2167\n",
      "Epoch 29/80\n",
      "240/240 [==============================] - 0s - loss: 2.3713 - acc: 0.1833 - val_loss: 2.3450 - val_acc: 0.2167\n",
      "Epoch 30/80\n",
      "240/240 [==============================] - 0s - loss: 2.3721 - acc: 0.1750 - val_loss: 2.3437 - val_acc: 0.1667\n",
      "Epoch 31/80\n",
      "240/240 [==============================] - 0s - loss: 2.3109 - acc: 0.1792 - val_loss: 2.3467 - val_acc: 0.1500\n",
      "Epoch 32/80\n",
      "240/240 [==============================] - 0s - loss: 2.3025 - acc: 0.2167 - val_loss: 2.3400 - val_acc: 0.1167\n",
      "Epoch 33/80\n",
      "240/240 [==============================] - 0s - loss: 2.3430 - acc: 0.1583 - val_loss: 2.3277 - val_acc: 0.0833\n",
      "Epoch 34/80\n",
      "240/240 [==============================] - 0s - loss: 2.3321 - acc: 0.1625 - val_loss: 2.3122 - val_acc: 0.1500\n",
      "Epoch 35/80\n",
      "240/240 [==============================] - 0s - loss: 2.3233 - acc: 0.2208 - val_loss: 2.2990 - val_acc: 0.2167\n",
      "Epoch 36/80\n",
      "240/240 [==============================] - 0s - loss: 2.3479 - acc: 0.1708 - val_loss: 2.2911 - val_acc: 0.2000\n",
      "Epoch 37/80\n",
      "240/240 [==============================] - 0s - loss: 2.3217 - acc: 0.1625 - val_loss: 2.2967 - val_acc: 0.2000\n",
      "Epoch 38/80\n",
      "240/240 [==============================] - 0s - loss: 2.2992 - acc: 0.1833 - val_loss: 2.3089 - val_acc: 0.2000\n",
      "Epoch 39/80\n",
      "240/240 [==============================] - 0s - loss: 2.2897 - acc: 0.2042 - val_loss: 2.3225 - val_acc: 0.2000\n",
      "Epoch 40/80\n",
      "240/240 [==============================] - 0s - loss: 2.2893 - acc: 0.2083 - val_loss: 2.3205 - val_acc: 0.2000\n",
      "Epoch 41/80\n",
      "240/240 [==============================] - 0s - loss: 2.2908 - acc: 0.2000 - val_loss: 2.3127 - val_acc: 0.2000\n",
      "Epoch 42/80\n",
      "240/240 [==============================] - 0s - loss: 2.3441 - acc: 0.1500 - val_loss: 2.3110 - val_acc: 0.1833\n",
      "Epoch 43/80\n",
      "240/240 [==============================] - 0s - loss: 2.2787 - acc: 0.2167 - val_loss: 2.3102 - val_acc: 0.1500\n",
      "Epoch 44/80\n",
      "240/240 [==============================] - 0s - loss: 2.3171 - acc: 0.1958 - val_loss: 2.3090 - val_acc: 0.1833\n",
      "Epoch 45/80\n",
      "240/240 [==============================] - 0s - loss: 2.2361 - acc: 0.2375 - val_loss: 2.3033 - val_acc: 0.2000\n",
      "Epoch 46/80\n",
      "240/240 [==============================] - 0s - loss: 2.3483 - acc: 0.1667 - val_loss: 2.2933 - val_acc: 0.2167\n",
      "Epoch 47/80\n",
      "240/240 [==============================] - 0s - loss: 2.2224 - acc: 0.2167 - val_loss: 2.2827 - val_acc: 0.2000\n",
      "Epoch 48/80\n",
      "240/240 [==============================] - 0s - loss: 2.2371 - acc: 0.1833 - val_loss: 2.2773 - val_acc: 0.2500\n",
      "Epoch 49/80\n",
      "240/240 [==============================] - 0s - loss: 2.2331 - acc: 0.2208 - val_loss: 2.2763 - val_acc: 0.3000\n",
      "Epoch 50/80\n",
      "240/240 [==============================] - 0s - loss: 2.2674 - acc: 0.2542 - val_loss: 2.2832 - val_acc: 0.2333\n",
      "Epoch 51/80\n",
      "240/240 [==============================] - 0s - loss: 2.2463 - acc: 0.2000 - val_loss: 2.2698 - val_acc: 0.2000\n",
      "Epoch 52/80\n",
      "240/240 [==============================] - 0s - loss: 2.2260 - acc: 0.2292 - val_loss: 2.2522 - val_acc: 0.2333\n",
      "Epoch 53/80\n",
      "240/240 [==============================] - 0s - loss: 2.2428 - acc: 0.2833 - val_loss: 2.2446 - val_acc: 0.2167\n",
      "Epoch 54/80\n",
      "240/240 [==============================] - 0s - loss: 2.1467 - acc: 0.2583 - val_loss: 2.2426 - val_acc: 0.1833\n",
      "Epoch 55/80\n",
      "240/240 [==============================] - 0s - loss: 2.2054 - acc: 0.2542 - val_loss: 2.2521 - val_acc: 0.2167\n",
      "Epoch 56/80\n",
      "240/240 [==============================] - 0s - loss: 2.2014 - acc: 0.2667 - val_loss: 2.2558 - val_acc: 0.1667\n",
      "Epoch 57/80\n",
      "240/240 [==============================] - 0s - loss: 2.2168 - acc: 0.2250 - val_loss: 2.2482 - val_acc: 0.2167\n",
      "Epoch 58/80\n",
      "240/240 [==============================] - 0s - loss: 2.1396 - acc: 0.2750 - val_loss: 2.2372 - val_acc: 0.2667\n",
      "Epoch 59/80\n",
      "240/240 [==============================] - 0s - loss: 2.1468 - acc: 0.2458 - val_loss: 2.2271 - val_acc: 0.2333\n",
      "Epoch 60/80\n",
      "240/240 [==============================] - 0s - loss: 2.1570 - acc: 0.2542 - val_loss: 2.2444 - val_acc: 0.2167\n",
      "Epoch 61/80\n",
      "240/240 [==============================] - 0s - loss: 2.1209 - acc: 0.2708 - val_loss: 2.2364 - val_acc: 0.2000\n",
      "Epoch 62/80\n",
      "240/240 [==============================] - 0s - loss: 2.1236 - acc: 0.2208 - val_loss: 2.2220 - val_acc: 0.2000\n",
      "Epoch 63/80\n",
      "240/240 [==============================] - 0s - loss: 2.1445 - acc: 0.2750 - val_loss: 2.2162 - val_acc: 0.2333\n",
      "Epoch 64/80\n",
      "240/240 [==============================] - 0s - loss: 2.1275 - acc: 0.2542 - val_loss: 2.2072 - val_acc: 0.2000\n",
      "Epoch 65/80\n",
      "240/240 [==============================] - 0s - loss: 2.1148 - acc: 0.3125 - val_loss: 2.2010 - val_acc: 0.1667\n",
      "Epoch 66/80\n",
      "240/240 [==============================] - 0s - loss: 2.1534 - acc: 0.2625 - val_loss: 2.1916 - val_acc: 0.2000\n",
      "Epoch 67/80\n",
      "240/240 [==============================] - 0s - loss: 2.1514 - acc: 0.2375 - val_loss: 2.1942 - val_acc: 0.2000\n",
      "Epoch 68/80\n",
      "240/240 [==============================] - 0s - loss: 2.1022 - acc: 0.2542 - val_loss: 2.2061 - val_acc: 0.1500\n",
      "Epoch 69/80\n",
      "240/240 [==============================] - 0s - loss: 2.0887 - acc: 0.3167 - val_loss: 2.2183 - val_acc: 0.1833\n",
      "Epoch 70/80\n",
      "240/240 [==============================] - 0s - loss: 2.0922 - acc: 0.2625 - val_loss: 2.2088 - val_acc: 0.2833\n",
      "Epoch 71/80\n",
      "240/240 [==============================] - 0s - loss: 2.1104 - acc: 0.2750 - val_loss: 2.1778 - val_acc: 0.2500\n",
      "Epoch 72/80\n",
      "240/240 [==============================] - 0s - loss: 2.0773 - acc: 0.2875 - val_loss: 2.1739 - val_acc: 0.2333\n",
      "Epoch 73/80\n",
      "240/240 [==============================] - 0s - loss: 2.0442 - acc: 0.3000 - val_loss: 2.1663 - val_acc: 0.2333\n",
      "Epoch 74/80\n",
      "240/240 [==============================] - 0s - loss: 2.0186 - acc: 0.2958 - val_loss: 2.1616 - val_acc: 0.2333\n",
      "Epoch 75/80\n",
      "240/240 [==============================] - 0s - loss: 2.0527 - acc: 0.2708 - val_loss: 2.1622 - val_acc: 0.2167\n",
      "Epoch 76/80\n",
      "240/240 [==============================] - 0s - loss: 2.0472 - acc: 0.2792 - val_loss: 2.1686 - val_acc: 0.2167\n",
      "Epoch 77/80\n",
      "240/240 [==============================] - 0s - loss: 2.0385 - acc: 0.2833 - val_loss: 2.1529 - val_acc: 0.2000\n",
      "Epoch 78/80\n",
      "240/240 [==============================] - 0s - loss: 2.0519 - acc: 0.2958 - val_loss: 2.1458 - val_acc: 0.1833\n",
      "Epoch 79/80\n",
      "240/240 [==============================] - 0s - loss: 1.9960 - acc: 0.2667 - val_loss: 2.1593 - val_acc: 0.2000\n",
      "Epoch 80/80\n",
      "240/240 [==============================] - 0s - loss: 1.9519 - acc: 0.3500 - val_loss: 2.1585 - val_acc: 0.2167\n"
     ]
    }
   ],
   "source": [
    "cnn1_results = cnn1.fit(conv_train_X_mfccs_1D, train_y, batch_size=64, epochs=80, \n",
    "                        validation_data=(conv_cv_X_mfccs_1D, cv_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CNN 1 scores\n",
      "Train acc: 0.3500\n",
      "CV acc: 0.3000\n"
     ]
    }
   ],
   "source": [
    "# show best results\n",
    "best_training_accuracy = max(cnn1_results.history[\"acc\"])\n",
    "best_validation_accuracy = max(cnn1_results.history[\"val_acc\"])\n",
    "print(\"Best CNN 1 scores\\nTrain acc: {:.4f}\\nCV acc: {:.4f}\".format(best_training_accuracy, best_validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This CNN architecture should get to 0.3 accuracy within 50-70 epochs and then start to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 12)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict and one-hot encode\n",
    "cnn1_pred_cv_y_mfccs_1D = cnn1.predict(conv_cv_X_mfccs_1D, batch_size=32)\n",
    "cnn1_pred_cv_y_mfccs_1D = utils.one_hot_encode(cnn1_pred_cv_y_mfccs_1D)\n",
    "cnn1_pred_cv_y_mfccs_1D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN 1 accuracy via sklearn (CV): 0.2167\n",
      "CNN 1 f1 score (CV): 0.2299\n"
     ]
    }
   ],
   "source": [
    "# we can also use sklearn directly to get accuracy\n",
    "cnn1_cv_accuracy = accuracy_score(cv_y, cnn1_pred_cv_y_mfccs_1D)\n",
    "cnn1_cv_f1_score = f1_score(cv_y, cnn1_pred_cv_y_mfccs_1D, average=\"weighted\")\n",
    "print(\"CNN 1 accuracy via sklearn (CV): {:.4f}\".format(cnn1_cv_accuracy))\n",
    "print(\"CNN 1 f1 score (CV): {:.4f}\".format(cnn1_cv_f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional models (1D) with FFT\n",
    "We have another form of preprocessing that results in a 1D vector - the Fast Fourier Transform. Let's see how our convolutional model might perform in that area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 16000, 1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to use convolutions we have to reshape our X -> expand it to 3 dimensions\n",
    "conv_train_X_fft = np.expand_dims(train_X_fft, axis=2)\n",
    "conv_train_X_fft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the FFT results in a 16K column vector - which will also require a lot more computational resources to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for cv & test\n",
    "conv_cv_X_fft = np.expand_dims(cv_X_fft, axis=2)\n",
    "conv_test_X_fft = np.expand_dims(test_X_fft, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_fft = Sequential([\n",
    "    Convolution1D(input_shape=(conv_train_X_fft.shape[1], 1), kernel_size=64, filters=64, padding=\"same\", activation=\"relu\"),\n",
    "    Dropout(0.12),\n",
    "    MaxPooling1D(),\n",
    "    Convolution1D(kernel_size=64, filters=64, padding=\"same\", activation=\"relu\"),\n",
    "    Dropout(0.12),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(2000, activation=\"relu\"),\n",
    "    Dropout(.7),\n",
    "    Dense(num_categories, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn_fft.compile(Adam(lr=0.001),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/20\n",
      "240/240 [==============================] - 89s - loss: 14.9422 - acc: 0.0667 - val_loss: 13.9690 - val_acc: 0.1333\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 84s - loss: 14.6406 - acc: 0.0917 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 77s - loss: 14.5734 - acc: 0.0958 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 76s - loss: 14.9092 - acc: 0.0750 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 76s - loss: 14.9764 - acc: 0.0708 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 77s - loss: 14.9092 - acc: 0.0750 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 81s - loss: 14.7749 - acc: 0.0833 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 80s - loss: 14.7749 - acc: 0.0833 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 84s - loss: 14.7078 - acc: 0.0875 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 80s - loss: 14.5734 - acc: 0.0958 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 84s - loss: 14.7749 - acc: 0.0833 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 79s - loss: 15.0436 - acc: 0.0667 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 75s - loss: 15.1779 - acc: 0.0583 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 76s - loss: 14.7749 - acc: 0.0833 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 74s - loss: 15.0436 - acc: 0.0667 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 76s - loss: 14.6406 - acc: 0.0917 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 77s - loss: 14.8421 - acc: 0.0792 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 84s - loss: 15.1107 - acc: 0.0625 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 82s - loss: 14.7749 - acc: 0.0833 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 83s - loss: 14.9092 - acc: 0.0750 - val_loss: 14.7749 - val_acc: 0.0833\n"
     ]
    }
   ],
   "source": [
    "cnn_fft_results = cnn_fft.fit(conv_train_X_fft, train_y, batch_size=64, epochs=20, \n",
    "                        validation_data=(conv_cv_X_fft, cv_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see the number of columns in the 1D vector results in a significant increase in the training time per epoch and we don't seem to be converging on better predictions (can't even fit the training set well with a fairly basic setup of the layers - most probably our kernel sizes are too small given the size of the vector). Let's leave this approach for now. Important practical aspect of ML: human time is ultimately the most valuable resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional models withMFCCs (2D)\n",
    "Let's try a similar model on the _2D MFCC data._ Notice that even though we are working with 2-dimensional input data, we are still using the 1D convolutional layers (and corresponding max pooling). That's primarily due to the available computational resources. A 1D convolutional layer will make a single pass horizontally across the 2D input matrix. Depending on the kernel size relative to the input size, this can still allow it to capture important patterns, allowing us to add more filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 100, 32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our data is already 2D, we don't need to expand dimensions\n",
    "train_X_mfccs_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2 = Sequential([\n",
    "        Convolution1D(input_shape=(train_X_mfccs_2D.shape[1], train_X_mfccs_2D.shape[2]), \n",
    "                      kernel_size=12, filters=128, padding=\"same\", activation=\"relu\"),\n",
    "        Dropout(0.11),\n",
    "        MaxPooling1D(),\n",
    "        Convolution1D(kernel_size=12, filters=128, padding=\"same\", activation=\"relu\"),\n",
    "        Dropout(0.13),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dense(2000, activation=\"relu\"),\n",
    "        Dropout(.7),\n",
    "        Dense(num_categories, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "cnn2.compile(Adam(lr=0.0001),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      "240/240 [==============================] - 5s - loss: 13.8843 - acc: 0.0625 - val_loss: 12.1183 - val_acc: 0.1500\n",
      "Epoch 2/100\n",
      "240/240 [==============================] - 0s - loss: 13.3157 - acc: 0.1208 - val_loss: 12.3101 - val_acc: 0.1667\n",
      "Epoch 3/100\n",
      "240/240 [==============================] - 0s - loss: 13.7101 - acc: 0.1000 - val_loss: 13.8039 - val_acc: 0.1333\n",
      "Epoch 4/100\n",
      "240/240 [==============================] - 0s - loss: 13.7622 - acc: 0.0917 - val_loss: 13.9723 - val_acc: 0.1333\n",
      "Epoch 5/100\n",
      "240/240 [==============================] - 0s - loss: 13.8633 - acc: 0.1125 - val_loss: 13.7956 - val_acc: 0.1333\n",
      "Epoch 6/100\n",
      "240/240 [==============================] - 0s - loss: 13.6308 - acc: 0.1250 - val_loss: 12.3735 - val_acc: 0.1667\n",
      "Epoch 7/100\n",
      "240/240 [==============================] - 0s - loss: 13.6375 - acc: 0.1167 - val_loss: 12.7424 - val_acc: 0.1167\n",
      "Epoch 8/100\n",
      "240/240 [==============================] - 0s - loss: 13.4899 - acc: 0.1125 - val_loss: 12.7566 - val_acc: 0.1167\n",
      "Epoch 9/100\n",
      "240/240 [==============================] - 0s - loss: 12.8714 - acc: 0.1542 - val_loss: 12.3217 - val_acc: 0.1167\n",
      "Epoch 10/100\n",
      "240/240 [==============================] - 0s - loss: 12.5884 - acc: 0.1542 - val_loss: 11.3360 - val_acc: 0.1833\n",
      "Epoch 11/100\n",
      "240/240 [==============================] - 0s - loss: 13.5296 - acc: 0.1167 - val_loss: 12.1098 - val_acc: 0.1500\n",
      "Epoch 12/100\n",
      "240/240 [==============================] - 0s - loss: 13.2045 - acc: 0.1167 - val_loss: 12.9681 - val_acc: 0.1500\n",
      "Epoch 13/100\n",
      "240/240 [==============================] - 0s - loss: 12.8995 - acc: 0.1625 - val_loss: 13.2857 - val_acc: 0.1500\n",
      "Epoch 14/100\n",
      "240/240 [==============================] - 0s - loss: 12.8826 - acc: 0.1667 - val_loss: 13.2962 - val_acc: 0.1500\n",
      "Epoch 15/100\n",
      "240/240 [==============================] - 0s - loss: 12.6220 - acc: 0.1792 - val_loss: 13.0474 - val_acc: 0.1500\n",
      "Epoch 16/100\n",
      "240/240 [==============================] - 0s - loss: 12.2717 - acc: 0.1917 - val_loss: 12.4257 - val_acc: 0.1833\n",
      "Epoch 17/100\n",
      "240/240 [==============================] - 0s - loss: 12.4744 - acc: 0.1917 - val_loss: 11.8660 - val_acc: 0.1167\n",
      "Epoch 18/100\n",
      "240/240 [==============================] - 0s - loss: 12.8951 - acc: 0.1542 - val_loss: 12.3967 - val_acc: 0.1167\n",
      "Epoch 19/100\n",
      "240/240 [==============================] - 0s - loss: 12.2048 - acc: 0.1833 - val_loss: 12.3090 - val_acc: 0.1333\n",
      "Epoch 20/100\n",
      "240/240 [==============================] - 0s - loss: 12.3146 - acc: 0.1875 - val_loss: 12.0581 - val_acc: 0.1667\n",
      "Epoch 21/100\n",
      "240/240 [==============================] - 0s - loss: 12.9351 - acc: 0.1500 - val_loss: 12.3656 - val_acc: 0.1500\n",
      "Epoch 22/100\n",
      "240/240 [==============================] - 0s - loss: 12.0926 - acc: 0.1792 - val_loss: 12.1894 - val_acc: 0.1667\n",
      "Epoch 23/100\n",
      "240/240 [==============================] - 0s - loss: 12.4511 - acc: 0.1875 - val_loss: 11.5998 - val_acc: 0.2000\n",
      "Epoch 24/100\n",
      "240/240 [==============================] - 0s - loss: 12.6979 - acc: 0.1708 - val_loss: 11.3153 - val_acc: 0.1667\n",
      "Epoch 25/100\n",
      "240/240 [==============================] - 0s - loss: 12.2806 - acc: 0.1708 - val_loss: 12.5651 - val_acc: 0.1667\n",
      "Epoch 26/100\n",
      "240/240 [==============================] - 0s - loss: 12.5864 - acc: 0.1833 - val_loss: 12.2928 - val_acc: 0.2000\n",
      "Epoch 27/100\n",
      "240/240 [==============================] - 0s - loss: 12.4074 - acc: 0.1833 - val_loss: 12.4509 - val_acc: 0.1500\n",
      "Epoch 28/100\n",
      "240/240 [==============================] - 0s - loss: 11.8533 - acc: 0.2000 - val_loss: 12.4813 - val_acc: 0.1333\n",
      "Epoch 29/100\n",
      "240/240 [==============================] - 0s - loss: 12.5673 - acc: 0.1667 - val_loss: 10.8042 - val_acc: 0.1333\n",
      "Epoch 30/100\n",
      "240/240 [==============================] - 0s - loss: 11.6499 - acc: 0.2042 - val_loss: 10.6129 - val_acc: 0.2000\n",
      "Epoch 31/100\n",
      "240/240 [==============================] - 0s - loss: 11.5741 - acc: 0.2042 - val_loss: 11.6958 - val_acc: 0.2000\n",
      "Epoch 32/100\n",
      "240/240 [==============================] - 0s - loss: 11.6571 - acc: 0.2125 - val_loss: 11.9330 - val_acc: 0.1833\n",
      "Epoch 33/100\n",
      "240/240 [==============================] - 0s - loss: 12.3656 - acc: 0.1833 - val_loss: 12.6795 - val_acc: 0.1833\n",
      "Epoch 34/100\n",
      "240/240 [==============================] - 0s - loss: 12.2452 - acc: 0.1792 - val_loss: 13.2241 - val_acc: 0.1667\n",
      "Epoch 35/100\n",
      "240/240 [==============================] - 0s - loss: 11.5600 - acc: 0.2333 - val_loss: 12.6342 - val_acc: 0.1500\n",
      "Epoch 36/100\n",
      "240/240 [==============================] - 0s - loss: 11.8864 - acc: 0.2000 - val_loss: 10.4108 - val_acc: 0.1500\n",
      "Epoch 37/100\n",
      "240/240 [==============================] - 0s - loss: 11.0030 - acc: 0.2583 - val_loss: 10.8800 - val_acc: 0.1833\n",
      "Epoch 38/100\n",
      "240/240 [==============================] - 0s - loss: 11.6391 - acc: 0.2167 - val_loss: 10.4483 - val_acc: 0.2000\n",
      "Epoch 39/100\n",
      "240/240 [==============================] - 0s - loss: 10.2718 - acc: 0.2917 - val_loss: 10.2877 - val_acc: 0.1833\n",
      "Epoch 40/100\n",
      "240/240 [==============================] - 0s - loss: 10.9473 - acc: 0.2542 - val_loss: 10.0632 - val_acc: 0.1667\n",
      "Epoch 41/100\n",
      "240/240 [==============================] - 0s - loss: 10.8718 - acc: 0.2708 - val_loss: 9.7471 - val_acc: 0.2000\n",
      "Epoch 42/100\n",
      "240/240 [==============================] - 0s - loss: 10.1419 - acc: 0.3000 - val_loss: 9.7513 - val_acc: 0.1833\n",
      "Epoch 43/100\n",
      "240/240 [==============================] - 0s - loss: 10.4198 - acc: 0.2583 - val_loss: 9.9384 - val_acc: 0.2167\n",
      "Epoch 44/100\n",
      "240/240 [==============================] - 0s - loss: 10.0839 - acc: 0.3000 - val_loss: 10.2707 - val_acc: 0.2333\n",
      "Epoch 45/100\n",
      "240/240 [==============================] - 0s - loss: 9.9772 - acc: 0.2875 - val_loss: 11.1794 - val_acc: 0.1500\n",
      "Epoch 46/100\n",
      "240/240 [==============================] - 0s - loss: 9.8849 - acc: 0.2875 - val_loss: 11.0415 - val_acc: 0.1500\n",
      "Epoch 47/100\n",
      "240/240 [==============================] - 0s - loss: 9.6395 - acc: 0.2875 - val_loss: 9.7267 - val_acc: 0.1833\n",
      "Epoch 48/100\n",
      "240/240 [==============================] - 0s - loss: 8.7303 - acc: 0.3542 - val_loss: 10.0210 - val_acc: 0.2000\n",
      "Epoch 49/100\n",
      "240/240 [==============================] - 0s - loss: 9.2594 - acc: 0.3250 - val_loss: 11.1557 - val_acc: 0.1833\n",
      "Epoch 50/100\n",
      "240/240 [==============================] - 0s - loss: 9.2203 - acc: 0.2875 - val_loss: 9.3382 - val_acc: 0.2667\n",
      "Epoch 51/100\n",
      "240/240 [==============================] - 0s - loss: 8.5293 - acc: 0.3458 - val_loss: 8.3143 - val_acc: 0.2500\n",
      "Epoch 52/100\n",
      "240/240 [==============================] - 0s - loss: 8.8413 - acc: 0.3167 - val_loss: 7.7694 - val_acc: 0.2167\n",
      "Epoch 53/100\n",
      "240/240 [==============================] - 0s - loss: 8.5381 - acc: 0.3333 - val_loss: 7.3499 - val_acc: 0.2333\n",
      "Epoch 54/100\n",
      "240/240 [==============================] - 0s - loss: 7.4057 - acc: 0.3875 - val_loss: 6.6551 - val_acc: 0.2167\n",
      "Epoch 55/100\n",
      "240/240 [==============================] - 0s - loss: 7.3161 - acc: 0.3958 - val_loss: 6.0489 - val_acc: 0.2333\n",
      "Epoch 56/100\n",
      "240/240 [==============================] - 0s - loss: 7.1368 - acc: 0.3500 - val_loss: 5.6989 - val_acc: 0.2667\n",
      "Epoch 57/100\n",
      "240/240 [==============================] - 0s - loss: 6.2476 - acc: 0.4000 - val_loss: 5.5383 - val_acc: 0.2500\n",
      "Epoch 58/100\n",
      "240/240 [==============================] - 0s - loss: 5.6294 - acc: 0.4292 - val_loss: 5.0392 - val_acc: 0.2000\n",
      "Epoch 59/100\n",
      "240/240 [==============================] - 0s - loss: 4.9004 - acc: 0.4792 - val_loss: 4.7864 - val_acc: 0.2167\n",
      "Epoch 60/100\n",
      "240/240 [==============================] - 0s - loss: 5.0654 - acc: 0.4417 - val_loss: 4.5202 - val_acc: 0.2667\n",
      "Epoch 61/100\n",
      "240/240 [==============================] - 0s - loss: 4.8065 - acc: 0.4833 - val_loss: 4.0323 - val_acc: 0.2167\n",
      "Epoch 62/100\n",
      "240/240 [==============================] - 0s - loss: 3.6952 - acc: 0.5375 - val_loss: 3.6849 - val_acc: 0.2000\n",
      "Epoch 63/100\n",
      "240/240 [==============================] - 0s - loss: 3.2297 - acc: 0.5458 - val_loss: 3.6648 - val_acc: 0.1833\n",
      "Epoch 64/100\n",
      "240/240 [==============================] - 0s - loss: 3.3110 - acc: 0.5292 - val_loss: 3.4994 - val_acc: 0.1833\n",
      "Epoch 65/100\n",
      "240/240 [==============================] - 0s - loss: 2.6696 - acc: 0.5875 - val_loss: 3.2769 - val_acc: 0.2000\n",
      "Epoch 66/100\n",
      "240/240 [==============================] - 0s - loss: 2.7242 - acc: 0.5583 - val_loss: 3.1359 - val_acc: 0.2333\n",
      "Epoch 67/100\n",
      "240/240 [==============================] - 0s - loss: 2.3156 - acc: 0.5792 - val_loss: 2.8586 - val_acc: 0.2500\n",
      "Epoch 68/100\n",
      "240/240 [==============================] - 0s - loss: 1.9998 - acc: 0.5792 - val_loss: 2.6515 - val_acc: 0.2833\n",
      "Epoch 69/100\n",
      "240/240 [==============================] - 0s - loss: 1.5813 - acc: 0.6375 - val_loss: 2.5454 - val_acc: 0.3000\n",
      "Epoch 70/100\n",
      "240/240 [==============================] - 0s - loss: 1.5449 - acc: 0.6625 - val_loss: 2.4688 - val_acc: 0.3167\n",
      "Epoch 71/100\n",
      "240/240 [==============================] - 0s - loss: 1.4038 - acc: 0.6625 - val_loss: 2.4216 - val_acc: 0.3333\n",
      "Epoch 72/100\n",
      "240/240 [==============================] - 0s - loss: 1.2442 - acc: 0.6750 - val_loss: 2.3688 - val_acc: 0.3500\n",
      "Epoch 73/100\n",
      "240/240 [==============================] - 0s - loss: 0.8931 - acc: 0.7083 - val_loss: 2.3199 - val_acc: 0.3500\n",
      "Epoch 74/100\n",
      "240/240 [==============================] - 0s - loss: 0.9994 - acc: 0.6875 - val_loss: 2.3150 - val_acc: 0.3500\n",
      "Epoch 75/100\n",
      "240/240 [==============================] - 0s - loss: 0.7931 - acc: 0.7792 - val_loss: 2.3201 - val_acc: 0.3667\n",
      "Epoch 76/100\n",
      "240/240 [==============================] - 0s - loss: 1.1013 - acc: 0.7042 - val_loss: 2.3143 - val_acc: 0.3500\n",
      "Epoch 77/100\n",
      "240/240 [==============================] - 0s - loss: 0.7515 - acc: 0.7375 - val_loss: 2.3095 - val_acc: 0.3667\n",
      "Epoch 78/100\n",
      "240/240 [==============================] - 0s - loss: 0.7794 - acc: 0.8083 - val_loss: 2.3081 - val_acc: 0.3667\n",
      "Epoch 79/100\n",
      "240/240 [==============================] - 0s - loss: 0.6406 - acc: 0.8000 - val_loss: 2.2990 - val_acc: 0.3500\n",
      "Epoch 80/100\n",
      "240/240 [==============================] - 0s - loss: 0.5782 - acc: 0.8167 - val_loss: 2.2906 - val_acc: 0.3500\n",
      "Epoch 81/100\n",
      "240/240 [==============================] - 0s - loss: 0.6192 - acc: 0.8083 - val_loss: 2.2948 - val_acc: 0.3167\n",
      "Epoch 82/100\n",
      "240/240 [==============================] - 0s - loss: 0.4767 - acc: 0.8583 - val_loss: 2.3005 - val_acc: 0.3500\n",
      "Epoch 83/100\n",
      "240/240 [==============================] - 0s - loss: 0.5202 - acc: 0.8417 - val_loss: 2.3202 - val_acc: 0.3167\n",
      "Epoch 84/100\n",
      "240/240 [==============================] - 0s - loss: 0.5177 - acc: 0.8292 - val_loss: 2.3436 - val_acc: 0.3000\n",
      "Epoch 85/100\n",
      "240/240 [==============================] - 0s - loss: 0.3719 - acc: 0.8875 - val_loss: 2.3619 - val_acc: 0.3167\n",
      "Epoch 86/100\n",
      "240/240 [==============================] - 0s - loss: 0.3652 - acc: 0.8792 - val_loss: 2.3715 - val_acc: 0.3333\n",
      "Epoch 87/100\n",
      "240/240 [==============================] - 0s - loss: 0.3251 - acc: 0.8958 - val_loss: 2.3881 - val_acc: 0.3333\n",
      "Epoch 88/100\n",
      "240/240 [==============================] - 0s - loss: 0.3631 - acc: 0.8625 - val_loss: 2.3999 - val_acc: 0.3833\n",
      "Epoch 89/100\n",
      "240/240 [==============================] - 0s - loss: 0.3473 - acc: 0.8708 - val_loss: 2.4111 - val_acc: 0.3833\n",
      "Epoch 90/100\n",
      "240/240 [==============================] - 0s - loss: 0.3708 - acc: 0.8708 - val_loss: 2.4294 - val_acc: 0.3333\n",
      "Epoch 91/100\n",
      "240/240 [==============================] - 0s - loss: 0.3701 - acc: 0.8708 - val_loss: 2.4398 - val_acc: 0.3000\n",
      "Epoch 92/100\n",
      "240/240 [==============================] - 0s - loss: 0.2602 - acc: 0.9083 - val_loss: 2.4338 - val_acc: 0.2833\n",
      "Epoch 93/100\n",
      "240/240 [==============================] - 0s - loss: 0.2491 - acc: 0.8958 - val_loss: 2.4188 - val_acc: 0.3667\n",
      "Epoch 94/100\n",
      "240/240 [==============================] - 0s - loss: 0.3462 - acc: 0.9083 - val_loss: 2.4111 - val_acc: 0.3833\n",
      "Epoch 95/100\n",
      "240/240 [==============================] - 0s - loss: 0.2006 - acc: 0.9375 - val_loss: 2.3988 - val_acc: 0.3833\n",
      "Epoch 96/100\n",
      "240/240 [==============================] - 0s - loss: 0.2515 - acc: 0.9042 - val_loss: 2.3900 - val_acc: 0.3667\n",
      "Epoch 97/100\n",
      "240/240 [==============================] - 0s - loss: 0.2246 - acc: 0.9333 - val_loss: 2.3940 - val_acc: 0.3667\n",
      "Epoch 98/100\n",
      "240/240 [==============================] - 0s - loss: 0.1624 - acc: 0.9458 - val_loss: 2.4119 - val_acc: 0.3667\n",
      "Epoch 99/100\n",
      "240/240 [==============================] - 0s - loss: 0.1707 - acc: 0.9333 - val_loss: 2.4460 - val_acc: 0.3500\n",
      "Epoch 100/100\n",
      "240/240 [==============================] - 0s - loss: 0.1978 - acc: 0.9458 - val_loss: 2.4600 - val_acc: 0.3500\n"
     ]
    }
   ],
   "source": [
    "cnn2_results = cnn2.fit(train_X_mfccs_2D, train_y, batch_size=64, \n",
    "                        epochs=100, validation_data=(cv_X_mfccs_2D, cv_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CNN 2 results\n",
      "Train acc: 0.9458\n",
      "CV acc: 0.3833\n"
     ]
    }
   ],
   "source": [
    "# show best results\n",
    "best_training_accuracy = max(cnn2_results.history[\"acc\"])\n",
    "best_validation_accuracy = max(cnn2_results.history[\"val_acc\"])\n",
    "print(\"Best CNN 2 results\\nTrain acc: {:.4f}\\nCV acc: {:.4f}\".format(best_training_accuracy, best_validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our **best convolutional model's accuracy above 0.35**. The model's performance is very brittle though, highly dependent on random weights initialization. It is also already overfitting. Let's calculate the F1 score for our latest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn2' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-f2109c787488>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# predict and one-hot encode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcnn2_pred_cv_y_mfccs_2D\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_X_mfccs_2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcnn2_pred_cv_y_mfccs_2D\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn2_pred_cv_y_mfccs_2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcnn2_pred_cv_y_mfccs_2D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cnn2' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# predict and one-hot encode\n",
    "cnn2_pred_cv_y_mfccs_2D = cnn2.predict(cv_X_mfccs_2D, batch_size=32)\n",
    "cnn2_pred_cv_y_mfccs_2D = utils.one_hot_encode(cnn2_pred_cv_y_mfccs_2D)\n",
    "cnn2_pred_cv_y_mfccs_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN 2 accuracy via sklearn (CV): 0.3500\n",
      "CNN 2 f1 score (CV): 0.3767\n"
     ]
    }
   ],
   "source": [
    "# we can also use sklearn directly to get accuracy\n",
    "cnn2_cv_accuracy = accuracy_score(cv_y, cnn2_pred_cv_y_mfccs_2D)\n",
    "cnn2_cv_f1_score = f1_score(cv_y, cnn2_pred_cv_y_mfccs_2D, average=\"weighted\")\n",
    "print(\"CNN 2 accuracy via sklearn (CV): {:.4f}\".format(cnn2_cv_accuracy))\n",
    "print(\"CNN 2 f1 score (CV): {:.4f}\".format(cnn2_cv_f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional models with Tempogram data (2D)\n",
    "We have 2 other forms of preprocessed data with dimensions that lend themselves to convolutions - MEL Spectrogram and Tempogram. Initial experiments with the MEL Spectrogram data didn't yield promising initial results, let's try Tempogram instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempogram shape:  (240, 384, 32)\n"
     ]
    }
   ],
   "source": [
    "# Our data is already 2D, we don't need to expand dimensions\n",
    "print(\"Tempogram shape: \", train_X_tempogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3 = Sequential([\n",
    "        Convolution1D(input_shape=(train_X_tempogram.shape[1], train_X_tempogram.shape[2]), \n",
    "                      kernel_size=32, filters=128, padding=\"same\", activation=\"relu\"),\n",
    "        Dropout(0.11),\n",
    "        MaxPooling1D(),\n",
    "        Convolution1D(kernel_size=12, filters=128, padding=\"same\", activation=\"relu\"),\n",
    "        Dropout(0.13),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dense(2000, activation=\"relu\"),\n",
    "        Dropout(.7),\n",
    "        Dense(num_categories, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "cnn3.compile(Adam(lr=0.0001),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/50\n",
      "240/240 [==============================] - 4s - loss: 2.4760 - acc: 0.0917 - val_loss: 2.4169 - val_acc: 0.1167\n",
      "Epoch 2/50\n",
      "240/240 [==============================] - 2s - loss: 2.4466 - acc: 0.1042 - val_loss: 2.4006 - val_acc: 0.1500\n",
      "Epoch 3/50\n",
      "240/240 [==============================] - 2s - loss: 2.4076 - acc: 0.1292 - val_loss: 2.4018 - val_acc: 0.1667\n",
      "Epoch 4/50\n",
      "240/240 [==============================] - 2s - loss: 2.4003 - acc: 0.1625 - val_loss: 2.3901 - val_acc: 0.1833\n",
      "Epoch 5/50\n",
      "240/240 [==============================] - 2s - loss: 2.3821 - acc: 0.1417 - val_loss: 2.3701 - val_acc: 0.1833\n",
      "Epoch 6/50\n",
      "240/240 [==============================] - 2s - loss: 2.3500 - acc: 0.1500 - val_loss: 2.3524 - val_acc: 0.2000\n",
      "Epoch 7/50\n",
      "240/240 [==============================] - 2s - loss: 2.3744 - acc: 0.1792 - val_loss: 2.3573 - val_acc: 0.2333\n",
      "Epoch 8/50\n",
      "240/240 [==============================] - 2s - loss: 2.3599 - acc: 0.1708 - val_loss: 2.3358 - val_acc: 0.2000\n",
      "Epoch 9/50\n",
      "240/240 [==============================] - 2s - loss: 2.3464 - acc: 0.1667 - val_loss: 2.3278 - val_acc: 0.1833\n",
      "Epoch 10/50\n",
      "240/240 [==============================] - 2s - loss: 2.3226 - acc: 0.1708 - val_loss: 2.3227 - val_acc: 0.1833\n",
      "Epoch 11/50\n",
      "240/240 [==============================] - 2s - loss: 2.3286 - acc: 0.1750 - val_loss: 2.3141 - val_acc: 0.1833\n",
      "Epoch 12/50\n",
      "240/240 [==============================] - 2s - loss: 2.2943 - acc: 0.1875 - val_loss: 2.2992 - val_acc: 0.2167\n",
      "Epoch 13/50\n",
      "240/240 [==============================] - 2s - loss: 2.2680 - acc: 0.2375 - val_loss: 2.2972 - val_acc: 0.2167\n",
      "Epoch 14/50\n",
      "240/240 [==============================] - 2s - loss: 2.3057 - acc: 0.1875 - val_loss: 2.2927 - val_acc: 0.2000\n",
      "Epoch 15/50\n",
      "240/240 [==============================] - 2s - loss: 2.2658 - acc: 0.1833 - val_loss: 2.2678 - val_acc: 0.2333\n",
      "Epoch 16/50\n",
      "240/240 [==============================] - 2s - loss: 2.2390 - acc: 0.2042 - val_loss: 2.2697 - val_acc: 0.2000\n",
      "Epoch 17/50\n",
      "240/240 [==============================] - 2s - loss: 2.2391 - acc: 0.2417 - val_loss: 2.2593 - val_acc: 0.2333\n",
      "Epoch 18/50\n",
      "240/240 [==============================] - 2s - loss: 2.2434 - acc: 0.2333 - val_loss: 2.2491 - val_acc: 0.2500\n",
      "Epoch 19/50\n",
      "240/240 [==============================] - 2s - loss: 2.2233 - acc: 0.2292 - val_loss: 2.2484 - val_acc: 0.2500\n",
      "Epoch 20/50\n",
      "240/240 [==============================] - 2s - loss: 2.2043 - acc: 0.2333 - val_loss: 2.2348 - val_acc: 0.2500\n",
      "Epoch 21/50\n",
      "240/240 [==============================] - 2s - loss: 2.2209 - acc: 0.2250 - val_loss: 2.2161 - val_acc: 0.2833\n",
      "Epoch 22/50\n",
      "240/240 [==============================] - 2s - loss: 2.2093 - acc: 0.2333 - val_loss: 2.2156 - val_acc: 0.2500\n",
      "Epoch 23/50\n",
      "240/240 [==============================] - 2s - loss: 2.2051 - acc: 0.2292 - val_loss: 2.2160 - val_acc: 0.2500\n",
      "Epoch 24/50\n",
      "240/240 [==============================] - 2s - loss: 2.1959 - acc: 0.2208 - val_loss: 2.1940 - val_acc: 0.2333\n",
      "Epoch 25/50\n",
      "240/240 [==============================] - 2s - loss: 2.1527 - acc: 0.2792 - val_loss: 2.1822 - val_acc: 0.2333\n",
      "Epoch 26/50\n",
      "240/240 [==============================] - 2s - loss: 2.1617 - acc: 0.2625 - val_loss: 2.1726 - val_acc: 0.2833\n",
      "Epoch 27/50\n",
      "240/240 [==============================] - 2s - loss: 2.1363 - acc: 0.2542 - val_loss: 2.1591 - val_acc: 0.2833\n",
      "Epoch 28/50\n",
      "240/240 [==============================] - 2s - loss: 2.1425 - acc: 0.2667 - val_loss: 2.1491 - val_acc: 0.2667\n",
      "Epoch 29/50\n",
      "240/240 [==============================] - 2s - loss: 2.1138 - acc: 0.2875 - val_loss: 2.1776 - val_acc: 0.2667\n",
      "Epoch 30/50\n",
      "240/240 [==============================] - 2s - loss: 2.1096 - acc: 0.3083 - val_loss: 2.1530 - val_acc: 0.2667\n",
      "Epoch 31/50\n",
      "240/240 [==============================] - 2s - loss: 2.1045 - acc: 0.2792 - val_loss: 2.1347 - val_acc: 0.2833\n",
      "Epoch 32/50\n",
      "240/240 [==============================] - 2s - loss: 2.1094 - acc: 0.2958 - val_loss: 2.1373 - val_acc: 0.3000\n",
      "Epoch 33/50\n",
      "240/240 [==============================] - 2s - loss: 2.0524 - acc: 0.3000 - val_loss: 2.1213 - val_acc: 0.2667\n",
      "Epoch 34/50\n",
      "240/240 [==============================] - 2s - loss: 2.0636 - acc: 0.2917 - val_loss: 2.0976 - val_acc: 0.3167\n",
      "Epoch 35/50\n",
      "240/240 [==============================] - 2s - loss: 2.0188 - acc: 0.3125 - val_loss: 2.0915 - val_acc: 0.3000\n",
      "Epoch 36/50\n",
      "240/240 [==============================] - 2s - loss: 2.0609 - acc: 0.3000 - val_loss: 2.1023 - val_acc: 0.3167\n",
      "Epoch 37/50\n",
      "240/240 [==============================] - 2s - loss: 2.0167 - acc: 0.3208 - val_loss: 2.0878 - val_acc: 0.3000\n",
      "Epoch 38/50\n",
      "240/240 [==============================] - 2s - loss: 1.9785 - acc: 0.3708 - val_loss: 2.0711 - val_acc: 0.3333\n",
      "Epoch 39/50\n",
      "240/240 [==============================] - 2s - loss: 1.9760 - acc: 0.3250 - val_loss: 2.0630 - val_acc: 0.2833\n",
      "Epoch 40/50\n",
      "240/240 [==============================] - 2s - loss: 1.9442 - acc: 0.3500 - val_loss: 2.0455 - val_acc: 0.3333\n",
      "Epoch 41/50\n",
      "240/240 [==============================] - 2s - loss: 1.9865 - acc: 0.3000 - val_loss: 2.0397 - val_acc: 0.3500\n",
      "Epoch 42/50\n",
      "240/240 [==============================] - 2s - loss: 1.9434 - acc: 0.3250 - val_loss: 2.0364 - val_acc: 0.3167\n",
      "Epoch 43/50\n",
      "240/240 [==============================] - 3s - loss: 1.9754 - acc: 0.3083 - val_loss: 2.0151 - val_acc: 0.3167\n",
      "Epoch 44/50\n",
      "240/240 [==============================] - 3s - loss: 1.9031 - acc: 0.3833 - val_loss: 2.0037 - val_acc: 0.3333\n",
      "Epoch 45/50\n",
      "240/240 [==============================] - 2s - loss: 1.9431 - acc: 0.3250 - val_loss: 2.0157 - val_acc: 0.3000\n",
      "Epoch 46/50\n",
      "240/240 [==============================] - 3s - loss: 1.9001 - acc: 0.3667 - val_loss: 2.0070 - val_acc: 0.3167\n",
      "Epoch 47/50\n",
      "240/240 [==============================] - 2s - loss: 1.8910 - acc: 0.3333 - val_loss: 1.9949 - val_acc: 0.3167\n",
      "Epoch 48/50\n",
      "240/240 [==============================] - 2s - loss: 1.8815 - acc: 0.3500 - val_loss: 2.0005 - val_acc: 0.3167\n",
      "Epoch 49/50\n",
      "240/240 [==============================] - 2s - loss: 1.9089 - acc: 0.3250 - val_loss: 1.9903 - val_acc: 0.3000\n",
      "Epoch 50/50\n",
      "240/240 [==============================] - 2s - loss: 1.8556 - acc: 0.3542 - val_loss: 1.9861 - val_acc: 0.3333\n"
     ]
    }
   ],
   "source": [
    "cnn3_results = cnn3.fit(train_X_tempogram, train_y, batch_size=64, \n",
    "                        epochs=50, validation_data=(cv_X_tempogram, cv_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CNN 3 results\n",
      "Train acc: 0.3833\n",
      "CV acc: 0.3500\n"
     ]
    }
   ],
   "source": [
    "# show best results\n",
    "best_training_accuracy = max(cnn3_results.history[\"acc\"])\n",
    "best_validation_accuracy = max(cnn3_results.history[\"val_acc\"])\n",
    "print(\"Best CNN 3 results\\nTrain acc: {:.4f}\\nCV acc: {:.4f}\".format(best_training_accuracy, best_validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our **best convolutional model with the tempogram data reaches an accuracy around 0.35**. This model's performance is far less brittle than the 2D MFCCs. After 50 epochs we aren't particularly overfitting. Let's check the F1 score and continue training for a couple more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 12)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict and one-hot encode\n",
    "cnn3_pred_cv_y_tempogram = cnn3.predict(cv_X_tempogram, batch_size=32)\n",
    "cnn3_pred_cv_y_tempogram = utils.one_hot_encode(cnn3_pred_cv_y_tempogram)\n",
    "cnn3_pred_cv_y_tempogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN 3 (tempogram) accuracy via sklearn (CV): 0.3333\n",
      "CNN 3 (tempogram) f1 score (CV): 0.2913\n"
     ]
    }
   ],
   "source": [
    "# we can also use sklearn directly to get accuracy\n",
    "cnn3_cv_accuracy = accuracy_score(cv_y, cnn3_pred_cv_y_tempogram)\n",
    "cnn3_cv_f1_score = f1_score(cv_y, cnn3_pred_cv_y_tempogram, average=\"weighted\")\n",
    "print(\"CNN 3 (tempogram) accuracy via sklearn (CV): {:.4f}\".format(cnn3_cv_accuracy))\n",
    "print(\"CNN 3 (tempogram) f1 score (CV): {:.4f}\".format(cnn3_cv_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/50\n",
      "240/240 [==============================] - 2s - loss: 1.8663 - acc: 0.3333 - val_loss: 1.9622 - val_acc: 0.3500\n",
      "Epoch 2/50\n",
      "240/240 [==============================] - 2s - loss: 1.8919 - acc: 0.3167 - val_loss: 1.9641 - val_acc: 0.3500\n",
      "Epoch 3/50\n",
      "240/240 [==============================] - 2s - loss: 1.8349 - acc: 0.3667 - val_loss: 1.9515 - val_acc: 0.3667\n",
      "Epoch 4/50\n",
      "240/240 [==============================] - 2s - loss: 1.8632 - acc: 0.3333 - val_loss: 1.9513 - val_acc: 0.3667\n",
      "Epoch 5/50\n",
      "240/240 [==============================] - 2s - loss: 1.7914 - acc: 0.4000 - val_loss: 1.9441 - val_acc: 0.3667\n",
      "Epoch 6/50\n",
      "240/240 [==============================] - 2s - loss: 1.8184 - acc: 0.3792 - val_loss: 1.9343 - val_acc: 0.3667\n",
      "Epoch 7/50\n",
      "240/240 [==============================] - 2s - loss: 1.8228 - acc: 0.3792 - val_loss: 1.9309 - val_acc: 0.3500\n",
      "Epoch 8/50\n",
      "240/240 [==============================] - 2s - loss: 1.8108 - acc: 0.3458 - val_loss: 1.9374 - val_acc: 0.3833\n",
      "Epoch 9/50\n",
      "240/240 [==============================] - 2s - loss: 1.7938 - acc: 0.3833 - val_loss: 1.9289 - val_acc: 0.3667\n",
      "Epoch 10/50\n",
      "240/240 [==============================] - 2s - loss: 1.8062 - acc: 0.3833 - val_loss: 1.9286 - val_acc: 0.3833\n",
      "Epoch 11/50\n",
      "240/240 [==============================] - 2s - loss: 1.7849 - acc: 0.3375 - val_loss: 1.9200 - val_acc: 0.3667\n",
      "Epoch 12/50\n",
      "240/240 [==============================] - 2s - loss: 1.7493 - acc: 0.3875 - val_loss: 1.9068 - val_acc: 0.3500\n",
      "Epoch 13/50\n",
      "240/240 [==============================] - 2s - loss: 1.7274 - acc: 0.4375 - val_loss: 1.9044 - val_acc: 0.3500\n",
      "Epoch 14/50\n",
      "240/240 [==============================] - 2s - loss: 1.7345 - acc: 0.3958 - val_loss: 1.9137 - val_acc: 0.3667\n",
      "Epoch 15/50\n",
      "240/240 [==============================] - 2s - loss: 1.7547 - acc: 0.3917 - val_loss: 1.9177 - val_acc: 0.3667\n",
      "Epoch 16/50\n",
      "240/240 [==============================] - 2s - loss: 1.7387 - acc: 0.4125 - val_loss: 1.9047 - val_acc: 0.4000\n",
      "Epoch 17/50\n",
      "240/240 [==============================] - 2s - loss: 1.7286 - acc: 0.3750 - val_loss: 1.9001 - val_acc: 0.4000\n",
      "Epoch 18/50\n",
      "240/240 [==============================] - 2s - loss: 1.7485 - acc: 0.4000 - val_loss: 1.9245 - val_acc: 0.3667\n",
      "Epoch 19/50\n",
      "240/240 [==============================] - 2s - loss: 1.7070 - acc: 0.4083 - val_loss: 1.9221 - val_acc: 0.3833\n",
      "Epoch 20/50\n",
      "240/240 [==============================] - 2s - loss: 1.7264 - acc: 0.3875 - val_loss: 1.9156 - val_acc: 0.3500\n",
      "Epoch 21/50\n",
      "240/240 [==============================] - 2s - loss: 1.7418 - acc: 0.3917 - val_loss: 1.9227 - val_acc: 0.3667\n",
      "Epoch 22/50\n",
      "240/240 [==============================] - 2s - loss: 1.6804 - acc: 0.4250 - val_loss: 1.8997 - val_acc: 0.3333\n",
      "Epoch 23/50\n",
      "240/240 [==============================] - 2s - loss: 1.6447 - acc: 0.4417 - val_loss: 1.9037 - val_acc: 0.3667\n",
      "Epoch 24/50\n",
      "240/240 [==============================] - 2s - loss: 1.6794 - acc: 0.4208 - val_loss: 1.8957 - val_acc: 0.3833\n",
      "Epoch 25/50\n",
      "240/240 [==============================] - 2s - loss: 1.6816 - acc: 0.4042 - val_loss: 1.8880 - val_acc: 0.3500\n",
      "Epoch 26/50\n",
      "240/240 [==============================] - 2s - loss: 1.6686 - acc: 0.4042 - val_loss: 1.9014 - val_acc: 0.3333\n",
      "Epoch 27/50\n",
      "240/240 [==============================] - 2s - loss: 1.6584 - acc: 0.4125 - val_loss: 1.8999 - val_acc: 0.3333\n",
      "Epoch 28/50\n",
      "240/240 [==============================] - 2s - loss: 1.7168 - acc: 0.4125 - val_loss: 1.8923 - val_acc: 0.3333\n",
      "Epoch 29/50\n",
      "240/240 [==============================] - 2s - loss: 1.6537 - acc: 0.4625 - val_loss: 1.8996 - val_acc: 0.3500\n",
      "Epoch 30/50\n",
      "240/240 [==============================] - 2s - loss: 1.6205 - acc: 0.4625 - val_loss: 1.8999 - val_acc: 0.3500\n",
      "Epoch 31/50\n",
      "240/240 [==============================] - 2s - loss: 1.5866 - acc: 0.4792 - val_loss: 1.8975 - val_acc: 0.3833\n",
      "Epoch 32/50\n",
      "240/240 [==============================] - 2s - loss: 1.6386 - acc: 0.4292 - val_loss: 1.8875 - val_acc: 0.3667\n",
      "Epoch 33/50\n",
      "240/240 [==============================] - 2s - loss: 1.5948 - acc: 0.4333 - val_loss: 1.9121 - val_acc: 0.3667\n",
      "Epoch 34/50\n",
      "240/240 [==============================] - 2s - loss: 1.6026 - acc: 0.4333 - val_loss: 1.8950 - val_acc: 0.3500\n",
      "Epoch 35/50\n",
      "240/240 [==============================] - 2s - loss: 1.6066 - acc: 0.4333 - val_loss: 1.8973 - val_acc: 0.3667\n",
      "Epoch 36/50\n",
      "240/240 [==============================] - 2s - loss: 1.6021 - acc: 0.4542 - val_loss: 1.9071 - val_acc: 0.3500\n",
      "Epoch 37/50\n",
      "240/240 [==============================] - 2s - loss: 1.5608 - acc: 0.4708 - val_loss: 1.9079 - val_acc: 0.3333\n",
      "Epoch 38/50\n",
      "240/240 [==============================] - 2s - loss: 1.5606 - acc: 0.4958 - val_loss: 1.9087 - val_acc: 0.3667\n",
      "Epoch 39/50\n",
      "240/240 [==============================] - 2s - loss: 1.5695 - acc: 0.4417 - val_loss: 1.9151 - val_acc: 0.3667\n",
      "Epoch 40/50\n",
      "240/240 [==============================] - 2s - loss: 1.5732 - acc: 0.4583 - val_loss: 1.9063 - val_acc: 0.3333\n",
      "Epoch 41/50\n",
      "240/240 [==============================] - 2s - loss: 1.5532 - acc: 0.4667 - val_loss: 1.9142 - val_acc: 0.3333\n",
      "Epoch 42/50\n",
      "240/240 [==============================] - 2s - loss: 1.5403 - acc: 0.4292 - val_loss: 1.9064 - val_acc: 0.3333\n",
      "Epoch 43/50\n",
      "240/240 [==============================] - 2s - loss: 1.5204 - acc: 0.4958 - val_loss: 1.9090 - val_acc: 0.3500\n",
      "Epoch 44/50\n",
      "240/240 [==============================] - 2s - loss: 1.5224 - acc: 0.4917 - val_loss: 1.9179 - val_acc: 0.3667\n",
      "Epoch 45/50\n",
      "240/240 [==============================] - 2s - loss: 1.5724 - acc: 0.4833 - val_loss: 1.9155 - val_acc: 0.3333\n",
      "Epoch 46/50\n",
      "240/240 [==============================] - 2s - loss: 1.5794 - acc: 0.4250 - val_loss: 1.9097 - val_acc: 0.3333\n",
      "Epoch 47/50\n",
      "240/240 [==============================] - 2s - loss: 1.5236 - acc: 0.4625 - val_loss: 1.9284 - val_acc: 0.3333\n",
      "Epoch 48/50\n",
      "240/240 [==============================] - 2s - loss: 1.5187 - acc: 0.4958 - val_loss: 1.9164 - val_acc: 0.3667\n",
      "Epoch 49/50\n",
      "240/240 [==============================] - 2s - loss: 1.4836 - acc: 0.5000 - val_loss: 1.9084 - val_acc: 0.3500\n",
      "Epoch 50/50\n",
      "240/240 [==============================] - 2s - loss: 1.5036 - acc: 0.5083 - val_loss: 1.9205 - val_acc: 0.3833\n"
     ]
    }
   ],
   "source": [
    "cnn3_results = cnn3.fit(train_X_tempogram, train_y, batch_size=64, \n",
    "                        epochs=50, validation_data=(cv_X_tempogram, cv_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CNN 3 results\n",
      "Train acc: 0.5083\n",
      "CV acc: 0.4000\n"
     ]
    }
   ],
   "source": [
    "# show best results after another 50 epochs\n",
    "best_training_accuracy = max(cnn3_results.history[\"acc\"])\n",
    "best_validation_accuracy = max(cnn3_results.history[\"val_acc\"])\n",
    "print(\"Best CNN 3 results\\nTrain acc: {:.4f}\\nCV acc: {:.4f}\".format(best_training_accuracy, best_validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final CNN 3 (tempogram) accuracy via sklearn (CV): 0.3833\n",
      "Final CNN 3 (tempogram) f1 score (CV): 0.3357\n"
     ]
    }
   ],
   "source": [
    "# predict and one-hot encode\n",
    "cnn3_pred_cv_y_tempogram = cnn3.predict(cv_X_tempogram, batch_size=32)\n",
    "cnn3_pred_cv_y_tempogram = utils.one_hot_encode(cnn3_pred_cv_y_tempogram)\n",
    "\n",
    "# we can also use sklearn directly to get accuracy\n",
    "cnn3_cv_accuracy = accuracy_score(cv_y, cnn3_pred_cv_y_tempogram)\n",
    "cnn3_cv_f1_score = f1_score(cv_y, cnn3_pred_cv_y_tempogram, average=\"weighted\")\n",
    "print(\"Final CNN 3 (tempogram) accuracy via sklearn (CV): {:.4f}\".format(cnn3_cv_accuracy))\n",
    "print(\"Final CNN 3 (tempogram) f1 score (CV): {:.4f}\".format(cnn3_cv_f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reached the **best CV accuracy so far - 0.4**, but we're beginning to overfit. Given that we're working on a relatively small sample, this could be a viable starting point for training models on the entire training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Models\n",
    "We can also try to take advantage of the architectures specifically designed for time sequences: RNNs. We will start with the basic keras implementations of simple RNN. After that we can consider moving on to GRUs & LSTMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_1 = Sequential([\n",
    "        SimpleRNN(input_shape=(conv_train_X_mfccs_1D.shape[1], 1), units=1000, activation='relu'),\n",
    "        Dropout(.4),\n",
    "        Dense(2000, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(.8),\n",
    "        Dense(num_categories, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "rnn_1.compile(Adam(lr=0.001),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/50\n",
      "240/240 [==============================] - 8s - loss: 3.7420 - acc: 0.0917 - val_loss: 2.4786 - val_acc: 0.0833\n",
      "Epoch 2/50\n",
      "240/240 [==============================] - 6s - loss: 3.2680 - acc: 0.1333 - val_loss: 2.4763 - val_acc: 0.0833\n",
      "Epoch 3/50\n",
      "240/240 [==============================] - 6s - loss: 3.1245 - acc: 0.1083 - val_loss: 2.4735 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "240/240 [==============================] - 6s - loss: 3.0108 - acc: 0.1417 - val_loss: 2.4777 - val_acc: 0.0833\n",
      "Epoch 5/50\n",
      "240/240 [==============================] - 6s - loss: 2.8757 - acc: 0.1792 - val_loss: 2.4826 - val_acc: 0.0833\n",
      "Epoch 6/50\n",
      "240/240 [==============================] - 6s - loss: 2.8516 - acc: 0.1333 - val_loss: 2.4814 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "240/240 [==============================] - 6s - loss: 2.6712 - acc: 0.1500 - val_loss: 2.4785 - val_acc: 0.0667\n",
      "Epoch 8/50\n",
      "240/240 [==============================] - 7s - loss: 2.7017 - acc: 0.1417 - val_loss: 2.4772 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "240/240 [==============================] - 7s - loss: 2.7979 - acc: 0.1292 - val_loss: 2.4802 - val_acc: 0.0500\n",
      "Epoch 10/50\n",
      "240/240 [==============================] - 8s - loss: 2.6468 - acc: 0.1667 - val_loss: 2.4824 - val_acc: 0.0667\n",
      "Epoch 11/50\n",
      "240/240 [==============================] - 7s - loss: 2.5629 - acc: 0.2167 - val_loss: 2.4779 - val_acc: 0.0667\n",
      "Epoch 12/50\n",
      "240/240 [==============================] - 7s - loss: 2.4955 - acc: 0.1708 - val_loss: 2.4744 - val_acc: 0.1167\n",
      "Epoch 13/50\n",
      "240/240 [==============================] - 8s - loss: 2.5015 - acc: 0.2125 - val_loss: 2.4713 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "240/240 [==============================] - 8s - loss: 2.4450 - acc: 0.1750 - val_loss: 2.4696 - val_acc: 0.0500\n",
      "Epoch 15/50\n",
      "240/240 [==============================] - 7s - loss: 2.3047 - acc: 0.2542 - val_loss: 2.4758 - val_acc: 0.0833\n",
      "Epoch 16/50\n",
      "240/240 [==============================] - 8s - loss: 2.3290 - acc: 0.2417 - val_loss: 2.4769 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "240/240 [==============================] - 8s - loss: 2.2927 - acc: 0.2292 - val_loss: 2.4729 - val_acc: 0.1167\n",
      "Epoch 18/50\n",
      "240/240 [==============================] - 8s - loss: 2.3143 - acc: 0.2667 - val_loss: 2.4669 - val_acc: 0.0833\n",
      "Epoch 19/50\n",
      "240/240 [==============================] - 8s - loss: 2.1273 - acc: 0.2958 - val_loss: 2.4643 - val_acc: 0.1167\n",
      "Epoch 20/50\n",
      "240/240 [==============================] - 8s - loss: 2.0852 - acc: 0.3083 - val_loss: 2.4597 - val_acc: 0.1667\n",
      "Epoch 21/50\n",
      "240/240 [==============================] - 8s - loss: 2.1143 - acc: 0.3000 - val_loss: 2.4625 - val_acc: 0.1333\n",
      "Epoch 22/50\n",
      "240/240 [==============================] - 8s - loss: 1.9646 - acc: 0.3583 - val_loss: 2.4644 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "240/240 [==============================] - 8s - loss: 2.0197 - acc: 0.3375 - val_loss: 2.4587 - val_acc: 0.1167\n",
      "Epoch 24/50\n",
      "240/240 [==============================] - 8s - loss: 1.8677 - acc: 0.3792 - val_loss: 2.4584 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "240/240 [==============================] - 8s - loss: 1.8667 - acc: 0.3667 - val_loss: 2.4677 - val_acc: 0.0500\n",
      "Epoch 26/50\n",
      "240/240 [==============================] - 8s - loss: 1.7144 - acc: 0.4083 - val_loss: 2.4628 - val_acc: 0.0667\n",
      "Epoch 27/50\n",
      "240/240 [==============================] - 8s - loss: 1.7474 - acc: 0.4000 - val_loss: 2.4594 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "240/240 [==============================] - 7s - loss: 1.5764 - acc: 0.4917 - val_loss: 2.4463 - val_acc: 0.0667\n",
      "Epoch 29/50\n",
      "240/240 [==============================] - 7s - loss: 1.4552 - acc: 0.5167 - val_loss: 2.4443 - val_acc: 0.0833\n",
      "Epoch 30/50\n",
      "240/240 [==============================] - 7s - loss: 1.4246 - acc: 0.5417 - val_loss: 2.4386 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "240/240 [==============================] - 7s - loss: 1.3248 - acc: 0.5708 - val_loss: 2.4586 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "240/240 [==============================] - 7s - loss: 1.2092 - acc: 0.6333 - val_loss: 2.4410 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "240/240 [==============================] - 7s - loss: 1.0812 - acc: 0.6333 - val_loss: 2.4526 - val_acc: 0.1167\n",
      "Epoch 34/50\n",
      "240/240 [==============================] - 7s - loss: 1.0745 - acc: 0.6292 - val_loss: 2.4697 - val_acc: 0.0833\n",
      "Epoch 35/50\n",
      "240/240 [==============================] - 7s - loss: 0.9265 - acc: 0.7083 - val_loss: 2.4871 - val_acc: 0.0667\n",
      "Epoch 36/50\n",
      "240/240 [==============================] - 7s - loss: 0.8562 - acc: 0.7292 - val_loss: 2.5070 - val_acc: 0.0833\n",
      "Epoch 37/50\n",
      "240/240 [==============================] - 7s - loss: 0.7941 - acc: 0.7625 - val_loss: 2.4631 - val_acc: 0.0667\n",
      "Epoch 38/50\n",
      "240/240 [==============================] - 8s - loss: 0.7608 - acc: 0.7708 - val_loss: 2.4724 - val_acc: 0.1167\n",
      "Epoch 39/50\n",
      "240/240 [==============================] - 7s - loss: 0.7329 - acc: 0.7583 - val_loss: 2.4883 - val_acc: 0.0833\n",
      "Epoch 40/50\n",
      "240/240 [==============================] - 7s - loss: 0.6417 - acc: 0.7833 - val_loss: 2.5473 - val_acc: 0.0167\n",
      "Epoch 41/50\n",
      "240/240 [==============================] - 7s - loss: 0.6183 - acc: 0.8167 - val_loss: 2.5189 - val_acc: 0.0833\n",
      "Epoch 42/50\n",
      "240/240 [==============================] - 7s - loss: 0.5644 - acc: 0.8167 - val_loss: 2.5496 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "240/240 [==============================] - 7s - loss: 0.5527 - acc: 0.8250 - val_loss: 2.5372 - val_acc: 0.1500\n",
      "Epoch 44/50\n",
      "240/240 [==============================] - 8s - loss: 0.4331 - acc: 0.8583 - val_loss: 2.5462 - val_acc: 0.0667\n",
      "Epoch 45/50\n",
      "240/240 [==============================] - 7s - loss: 0.3994 - acc: 0.8708 - val_loss: 2.6039 - val_acc: 0.1167\n",
      "Epoch 46/50\n",
      "240/240 [==============================] - 8s - loss: 0.3492 - acc: 0.8875 - val_loss: 2.6308 - val_acc: 0.0667\n",
      "Epoch 47/50\n",
      "240/240 [==============================] - 7s - loss: 0.3296 - acc: 0.8750 - val_loss: 2.6817 - val_acc: 0.0500\n",
      "Epoch 48/50\n",
      "240/240 [==============================] - 8s - loss: 0.2717 - acc: 0.9250 - val_loss: 2.7143 - val_acc: 0.1333\n",
      "Epoch 49/50\n",
      "240/240 [==============================] - 8s - loss: 0.1985 - acc: 0.9458 - val_loss: 2.7824 - val_acc: 0.0667\n",
      "Epoch 50/50\n",
      "240/240 [==============================] - 7s - loss: 0.2515 - acc: 0.9375 - val_loss: 2.8268 - val_acc: 0.0500\n"
     ]
    }
   ],
   "source": [
    "rnn_1_results = rnn_1.fit(conv_train_X_mfccs_1D, train_y, batch_size=32, epochs=50, validation_data=(conv_cv_X_mfccs_1D, cv_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RNN 1 results\n",
      "Train acc: 0.9458\n",
      "CV acc: 0.1667\n"
     ]
    }
   ],
   "source": [
    "# show best results after another 50 epochs\n",
    "best_training_accuracy = max(rnn_1_results.history[\"acc\"])\n",
    "best_validation_accuracy = max(rnn_1_results.history[\"val_acc\"])\n",
    "print(\"Best RNN 1 results\\nTrain acc: {:.4f}\\nCV acc: {:.4f}\".format(best_training_accuracy, best_validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after some experiments to reduce overfitting our SimpleRNN doesn't seem able to get a good CV accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU\n",
    "Let's try the Gated Recurrent Unit network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_2 = Sequential([\n",
    "        GRU(input_shape=(conv_train_X_mfccs_1D.shape[1], 1), units=1000, activation='tanh'),\n",
    "        Dense(1000, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(.7),\n",
    "        Dense(num_categories, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "rnn_2.compile(Adam(lr=0.003),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 26s - loss: 4.2266 - acc: 0.0708 - val_loss: 2.7199 - val_acc: 0.0833\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 21s - loss: 4.3152 - acc: 0.0917 - val_loss: 6.1280 - val_acc: 0.1167\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 19s - loss: 3.6099 - acc: 0.0792 - val_loss: 6.5881 - val_acc: 0.0833\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 21s - loss: 3.8228 - acc: 0.0792 - val_loss: 12.8300 - val_acc: 0.0833\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 20s - loss: 2.9018 - acc: 0.0917 - val_loss: 12.3476 - val_acc: 0.0833\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 20s - loss: 2.5534 - acc: 0.1667 - val_loss: 11.3755 - val_acc: 0.0833\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 20s - loss: 3.9685 - acc: 0.1042 - val_loss: 8.7863 - val_acc: 0.1167\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 20s - loss: 3.3102 - acc: 0.1208 - val_loss: 8.2222 - val_acc: 0.1167\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 20s - loss: 3.6101 - acc: 0.0958 - val_loss: 6.0353 - val_acc: 0.1167\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 19s - loss: 3.3395 - acc: 0.1083 - val_loss: 5.5199 - val_acc: 0.1167\n"
     ]
    }
   ],
   "source": [
    "rnn_2_results = rnn_2.fit(conv_train_X_mfccs_1D, train_y, batch_size=32, epochs=10, validation_data=(conv_cv_X_mfccs_1D, cv_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly the nearly-default GRU architecture doesn't seem promising. Let's try the LSTM for dilligence's sake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_3 = Sequential([\n",
    "        LSTM(input_shape=(conv_train_X_mfccs_1D.shape[1], 1), units=1000, activation='tanh'),\n",
    "        Dense(1000, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(.7),\n",
    "        Dense(num_categories, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "rnn_3.compile(Adam(lr=0.001),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 14s - loss: 3.1245 - acc: 0.1083 - val_loss: 2.4812 - val_acc: 0.1000\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 12s - loss: 2.7994 - acc: 0.0833 - val_loss: 2.4873 - val_acc: 0.0500\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 12s - loss: 2.8856 - acc: 0.0792 - val_loss: 2.4869 - val_acc: 0.1000\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 12s - loss: 2.8621 - acc: 0.0792 - val_loss: 2.4864 - val_acc: 0.0833\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 12s - loss: 2.6422 - acc: 0.1042 - val_loss: 2.4840 - val_acc: 0.0667\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 12s - loss: 2.6223 - acc: 0.0833 - val_loss: 2.4865 - val_acc: 0.0833\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 12s - loss: 2.6100 - acc: 0.1125 - val_loss: 2.4869 - val_acc: 0.0667\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 12s - loss: 2.5333 - acc: 0.0917 - val_loss: 2.4876 - val_acc: 0.0833\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 12s - loss: 2.5045 - acc: 0.1375 - val_loss: 2.4857 - val_acc: 0.1167\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 12s - loss: 2.4933 - acc: 0.0958 - val_loss: 2.4851 - val_acc: 0.0667\n"
     ]
    }
   ],
   "source": [
    "rnn_3_results = rnn_3.fit(conv_train_X_mfccs_1D, train_y, batch_size=32, epochs=10, validation_data=(conv_cv_X_mfccs_1D, cv_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems that we might be running into the same obstacle as we did in our other non-convolutional models, namely the fact that the actual utterance may come at many places within the 1 second sample and the recurrent models can't pick up on that, being very order-dependent. We could consider using convolutional transformations on smaller time-slices and then running that through recurrent models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining data preprocessed in 2 different ways\n",
    "We saw that our models seem to be doing well on the 2D MFCCs and Tempogram data. Perhaps these two forms of preprocessing capture different nuances of our sets - if so, we might be able to benefit from combining them into one input matrix per example.\n",
    "\n",
    "There's a nuance here that we have to take into consideration - since we are effectively concating the 2D MFCCs and Tempogram matrices together we can no longer rely on 1D convolutional layers, as they only do 1 pass (horizontally) over the input data, which (depending on chosen kernel size) might mean our convolutions never actually \"see\" on of the data sources. In consequence our models will take much longer to train, forcing us to limit the number of filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's grab a single example from our tempogram data\n",
    "example_tempogram = train_X_tempogram[0]\n",
    "example_tempogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and from our 2D MFCCs\n",
    "example_mfccs_2D = train_X_mfccs_2D[0]\n",
    "example_mfccs_2D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that they share the same number of dimensions along one of the axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(484, 32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_combined = np.concatenate((example_tempogram, example_mfccs_2D), axis=0)\n",
    "example_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do this with 3D matrices, like the ones that hold our entire preprocessed Xs (adjusting the axes number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 484, 32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_combined = np.concatenate((train_X_tempogram, train_X_mfccs_2D), axis=1)\n",
    "train_X_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 484, 32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeat for CV and Test sets\n",
    "cv_X_combined = np.concatenate((cv_X_tempogram, cv_X_mfccs_2D), axis=1)\n",
    "test_X_combined = np.concatenate((test_X_tempogram, test_X_mfccs_2D), axis=1)\n",
    "cv_X_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in 2D convolutions this time, so let's expand with a single channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 484, 32, 1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_combined = np.expand_dims(train_X_combined, axis=3)\n",
    "train_X_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 484, 32, 1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_X_combined = np.expand_dims(cv_X_combined, axis=3)\n",
    "test_X_combined = np.expand_dims(test_X_combined, axis=3)\n",
    "cv_X_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn4 = Sequential([\n",
    "        Conv2D(input_shape=(train_X_combined.shape[1], train_X_combined.shape[2], 1), \n",
    "                      kernel_size=12, filters=10, padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(.5),\n",
    "        Conv2D(kernel_size=12, filters=12, padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(.5),\n",
    "        Flatten(),\n",
    "        Dense(3000, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(.85),\n",
    "        Dense(2000, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(.7),\n",
    "        Dense(num_categories, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "cnn4.compile(Adam(lr=0.0003),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/50\n",
      "240/240 [==============================] - 14s - loss: 4.8142 - acc: 0.0958 - val_loss: 5.8760 - val_acc: 0.1000\n",
      "Epoch 2/50\n",
      "240/240 [==============================] - 10s - loss: 4.3949 - acc: 0.1250 - val_loss: 4.6691 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "240/240 [==============================] - 10s - loss: 4.5150 - acc: 0.1125 - val_loss: 5.8855 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "240/240 [==============================] - 10s - loss: 4.6312 - acc: 0.1000 - val_loss: 6.3307 - val_acc: 0.0833\n",
      "Epoch 5/50\n",
      "240/240 [==============================] - 9s - loss: 4.3680 - acc: 0.1375 - val_loss: 6.7992 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "240/240 [==============================] - 10s - loss: 4.4208 - acc: 0.1292 - val_loss: 6.9844 - val_acc: 0.0833\n",
      "Epoch 7/50\n",
      "240/240 [==============================] - 10s - loss: 4.1149 - acc: 0.1125 - val_loss: 7.1453 - val_acc: 0.1333\n",
      "Epoch 8/50\n",
      "240/240 [==============================] - 10s - loss: 4.6399 - acc: 0.1167 - val_loss: 7.0449 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "240/240 [==============================] - 10s - loss: 4.0905 - acc: 0.1375 - val_loss: 6.9971 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "240/240 [==============================] - 10s - loss: 4.5596 - acc: 0.1583 - val_loss: 6.8588 - val_acc: 0.0833\n",
      "Epoch 11/50\n",
      "240/240 [==============================] - 10s - loss: 4.4594 - acc: 0.1333 - val_loss: 6.6134 - val_acc: 0.0833\n",
      "Epoch 12/50\n",
      "240/240 [==============================] - 10s - loss: 4.1430 - acc: 0.1292 - val_loss: 5.9921 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "240/240 [==============================] - 10s - loss: 4.1459 - acc: 0.1208 - val_loss: 5.4063 - val_acc: 0.1167\n",
      "Epoch 14/50\n",
      "240/240 [==============================] - 10s - loss: 4.2946 - acc: 0.1417 - val_loss: 4.8227 - val_acc: 0.1333\n",
      "Epoch 15/50\n",
      "240/240 [==============================] - 10s - loss: 4.0024 - acc: 0.1583 - val_loss: 4.1829 - val_acc: 0.1500\n",
      "Epoch 16/50\n",
      "240/240 [==============================] - 10s - loss: 4.1820 - acc: 0.1625 - val_loss: 3.6801 - val_acc: 0.1500\n",
      "Epoch 17/50\n",
      "240/240 [==============================] - 10s - loss: 4.2758 - acc: 0.1250 - val_loss: 3.3911 - val_acc: 0.1500\n",
      "Epoch 18/50\n",
      "240/240 [==============================] - 10s - loss: 4.3461 - acc: 0.1542 - val_loss: 3.2679 - val_acc: 0.1667\n",
      "Epoch 19/50\n",
      "240/240 [==============================] - 10s - loss: 4.3335 - acc: 0.0917 - val_loss: 3.2203 - val_acc: 0.2000\n",
      "Epoch 20/50\n",
      "240/240 [==============================] - 10s - loss: 3.9622 - acc: 0.1333 - val_loss: 3.1888 - val_acc: 0.1667\n",
      "Epoch 21/50\n",
      "240/240 [==============================] - 10s - loss: 4.1834 - acc: 0.1750 - val_loss: 3.1829 - val_acc: 0.1667\n",
      "Epoch 22/50\n",
      "240/240 [==============================] - 10s - loss: 3.9855 - acc: 0.1708 - val_loss: 3.1999 - val_acc: 0.1667\n",
      "Epoch 23/50\n",
      "240/240 [==============================] - 10s - loss: 3.7107 - acc: 0.1792 - val_loss: 3.1944 - val_acc: 0.1500\n",
      "Epoch 24/50\n",
      "240/240 [==============================] - 10s - loss: 4.1047 - acc: 0.1542 - val_loss: 3.2142 - val_acc: 0.1667\n",
      "Epoch 25/50\n",
      "240/240 [==============================] - 10s - loss: 4.0661 - acc: 0.1542 - val_loss: 3.2156 - val_acc: 0.1667\n",
      "Epoch 26/50\n",
      "240/240 [==============================] - 10s - loss: 3.9187 - acc: 0.1458 - val_loss: 3.2066 - val_acc: 0.1667\n",
      "Epoch 27/50\n",
      "240/240 [==============================] - 10s - loss: 3.9436 - acc: 0.1625 - val_loss: 3.2064 - val_acc: 0.2000\n",
      "Epoch 28/50\n",
      "240/240 [==============================] - 10s - loss: 3.9605 - acc: 0.1458 - val_loss: 3.0842 - val_acc: 0.2000\n",
      "Epoch 29/50\n",
      "240/240 [==============================] - 10s - loss: 3.7457 - acc: 0.1875 - val_loss: 2.9559 - val_acc: 0.2333\n",
      "Epoch 30/50\n",
      "240/240 [==============================] - 10s - loss: 3.7994 - acc: 0.1750 - val_loss: 2.7915 - val_acc: 0.1833\n",
      "Epoch 31/50\n",
      "240/240 [==============================] - 10s - loss: 3.8660 - acc: 0.1625 - val_loss: 2.6988 - val_acc: 0.1833\n",
      "Epoch 32/50\n",
      "240/240 [==============================] - 10s - loss: 3.8243 - acc: 0.1708 - val_loss: 2.6926 - val_acc: 0.2000\n",
      "Epoch 33/50\n",
      "240/240 [==============================] - 10s - loss: 3.7331 - acc: 0.1667 - val_loss: 2.6751 - val_acc: 0.2000\n",
      "Epoch 34/50\n",
      "240/240 [==============================] - 11s - loss: 3.6763 - acc: 0.2000 - val_loss: 2.6015 - val_acc: 0.2333\n",
      "Epoch 35/50\n",
      "240/240 [==============================] - 10s - loss: 3.7012 - acc: 0.1750 - val_loss: 2.5429 - val_acc: 0.2167\n",
      "Epoch 36/50\n",
      "240/240 [==============================] - 11s - loss: 3.8196 - acc: 0.1833 - val_loss: 2.4758 - val_acc: 0.2167\n",
      "Epoch 37/50\n",
      "240/240 [==============================] - 10s - loss: 3.9068 - acc: 0.1792 - val_loss: 2.4266 - val_acc: 0.2167\n",
      "Epoch 38/50\n",
      "240/240 [==============================] - 11s - loss: 3.7018 - acc: 0.2000 - val_loss: 2.4123 - val_acc: 0.2333\n",
      "Epoch 39/50\n",
      "240/240 [==============================] - 11s - loss: 3.7243 - acc: 0.1875 - val_loss: 2.4162 - val_acc: 0.2000\n",
      "Epoch 40/50\n",
      "240/240 [==============================] - 12s - loss: 3.3309 - acc: 0.1708 - val_loss: 2.4139 - val_acc: 0.2333\n",
      "Epoch 41/50\n",
      "240/240 [==============================] - 11s - loss: 3.7622 - acc: 0.2000 - val_loss: 2.4165 - val_acc: 0.2333\n",
      "Epoch 42/50\n",
      "240/240 [==============================] - 11s - loss: 3.3182 - acc: 0.2667 - val_loss: 2.4391 - val_acc: 0.2000\n",
      "Epoch 43/50\n",
      "240/240 [==============================] - 11s - loss: 3.7953 - acc: 0.1750 - val_loss: 2.4957 - val_acc: 0.2167\n",
      "Epoch 44/50\n",
      "240/240 [==============================] - 11s - loss: 3.5564 - acc: 0.1917 - val_loss: 2.5607 - val_acc: 0.2167\n",
      "Epoch 45/50\n",
      "240/240 [==============================] - 11s - loss: 3.4664 - acc: 0.2250 - val_loss: 2.6295 - val_acc: 0.1833\n",
      "Epoch 46/50\n",
      "240/240 [==============================] - 11s - loss: 3.2550 - acc: 0.2333 - val_loss: 2.6644 - val_acc: 0.1833\n",
      "Epoch 47/50\n",
      "240/240 [==============================] - 11s - loss: 3.6804 - acc: 0.1958 - val_loss: 2.6788 - val_acc: 0.1833\n",
      "Epoch 48/50\n",
      "240/240 [==============================] - 11s - loss: 3.2768 - acc: 0.2500 - val_loss: 2.6773 - val_acc: 0.1667\n",
      "Epoch 49/50\n",
      "240/240 [==============================] - 11s - loss: 3.6634 - acc: 0.2333 - val_loss: 2.6842 - val_acc: 0.1667\n",
      "Epoch 50/50\n",
      "240/240 [==============================] - 11s - loss: 3.4536 - acc: 0.2042 - val_loss: 2.6958 - val_acc: 0.1167\n"
     ]
    }
   ],
   "source": [
    "cnn4_results = cnn4.fit(train_X_combined, train_y, batch_size=64, \n",
    "                        epochs=50, validation_data=(cv_X_combined, cv_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that with the unchanged kernel size our models perform worse on the combined data. In principle however running a model consisting of 2D convolutional layers might still be a valid approach.\n",
    "\n",
    "Let's try one last experiment before moving on. Let's try to fit a 2D convolutional model, despite the computational costs, on the tempogram data. First we'll have to expand its dimensions to fit the shape required by 2D convolutions (which can also take colors into consideration). We will essentially treat the tempogram as a 2D grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 384, 32, 1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_tempogram_2 = np.expand_dims(train_X_tempogram, axis=3)\n",
    "train_X_tempogram_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_X_tempogram_2 = np.expand_dims(cv_X_tempogram, axis=3)\n",
    "test_X_tempogram_2 = np.expand_dims(test_X_tempogram, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn5 = Sequential([\n",
    "        Conv2D(input_shape=(train_X_tempogram_2.shape[1], train_X_tempogram_2.shape[2], 1), \n",
    "                      kernel_size=32, filters=128, padding=\"same\", activation=\"relu\"),\n",
    "        Dropout(0.11),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(kernel_size=12, filters=128, padding=\"same\", activation=\"relu\"),\n",
    "        Dropout(0.13),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(2000, activation=\"relu\"),\n",
    "        Dropout(.7),\n",
    "        Dense(num_categories, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "cnn5.compile(Adam(lr=0.0001),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-4d600bd9005f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m cnn5_results = cnn5.fit(train_X_tempogram_2, train_y, batch_size=64, \n\u001b[1;32m----> 2\u001b[1;33m                         epochs=20, validation_data=(cv_X_tempogram_2, cv_y))\n\u001b[0m",
      "\u001b[1;32mc:\\users\\mateus\\documents\\mateusz\\coding\\tensorflow_voice\\tensor_venv\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateus\\documents\\mateusz\\coding\\tensorflow_voice\\tensor_venv\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1619\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1620\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1621\u001b[1;33m         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1623\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\mateus\\documents\\mateusz\\coding\\tensorflow_voice\\tensor_venv\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1193\u001b[0m           \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1195\u001b[1;33m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateus\\documents\\mateusz\\coding\\tensorflow_voice\\tensor_venv\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2471\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2472\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2473\u001b[1;33m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2474\u001b[0m     updated = session.run(\n\u001b[0;32m   2475\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateus\\documents\\mateusz\\coding\\tensorflow_voice\\tensor_venv\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m       \u001b[0m_initialize_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateus\\documents\\mateusz\\coding\\tensorflow_voice\\tensor_venv\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[1;34m(session)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateus\\documents\\mateusz\\coding\\tensorflow_voice\\tensor_venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateus\\documents\\mateusz\\coding\\tensorflow_voice\\tensor_venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateus\\documents\\mateusz\\coding\\tensorflow_voice\\tensor_venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateus\\documents\\mateusz\\coding\\tensorflow_voice\\tensor_venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateus\\documents\\mateusz\\coding\\tensorflow_voice\\tensor_venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "cnn5_results = cnn5.fit(train_X_tempogram_2, train_y, batch_size=64, \n",
    "                        epochs=20, validation_data=(cv_X_tempogram_2, cv_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn5_results' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-59b46ee80fd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# show best results after the 20 epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbest_training_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn5_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mbest_validation_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn5_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best CNN 5 results\\nTrain acc: {:.4f}\\nCV acc: {:.4f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_training_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_validation_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cnn5_results' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# show best results after the 20 epochs\n",
    "best_training_accuracy = max(cnn5_results.history[\"acc\"])\n",
    "best_validation_accuracy = max(cnn5_results.history[\"val_acc\"])\n",
    "print(\"Best CNN 5 results\\nTrain acc: {:.4f}\\nCV acc: {:.4f}\".format(best_training_accuracy, best_validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 20 epochs the 2D convolutions model is approaching our previous best results, without overfitting, albeit taking a lot longer to get there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/20\n",
      "240/240 [==============================] - 164s - loss: 2.0675 - acc: 0.2708 - val_loss: 2.1040 - val_acc: 0.3167\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 162s - loss: 2.0496 - acc: 0.2792 - val_loss: 2.0543 - val_acc: 0.3167\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 166s - loss: 1.9616 - acc: 0.2833 - val_loss: 2.0355 - val_acc: 0.3167\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 169s - loss: 1.9800 - acc: 0.3250 - val_loss: 1.9935 - val_acc: 0.3167\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 172s - loss: 1.9760 - acc: 0.3208 - val_loss: 1.9803 - val_acc: 0.3333\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 167s - loss: 1.8824 - acc: 0.3250 - val_loss: 1.9780 - val_acc: 0.3333\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 163s - loss: 1.9024 - acc: 0.3292 - val_loss: 1.9439 - val_acc: 0.3833\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 163s - loss: 1.8479 - acc: 0.3500 - val_loss: 1.9397 - val_acc: 0.3500\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 162s - loss: 1.8363 - acc: 0.3667 - val_loss: 1.9142 - val_acc: 0.3500\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 162s - loss: 1.8364 - acc: 0.3583 - val_loss: 1.9350 - val_acc: 0.3333\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 162s - loss: 1.7748 - acc: 0.4208 - val_loss: 1.9061 - val_acc: 0.3333\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 164s - loss: 1.7964 - acc: 0.3917 - val_loss: 1.8875 - val_acc: 0.3167\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 164s - loss: 1.7521 - acc: 0.3708 - val_loss: 1.8968 - val_acc: 0.3833\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 170s - loss: 1.7115 - acc: 0.3833 - val_loss: 1.8864 - val_acc: 0.3667\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 164s - loss: 1.6913 - acc: 0.3875 - val_loss: 1.8810 - val_acc: 0.3667\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 178s - loss: 1.6314 - acc: 0.4500 - val_loss: 1.8937 - val_acc: 0.3000\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 189s - loss: 1.6924 - acc: 0.4208 - val_loss: 1.8831 - val_acc: 0.3833\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 209s - loss: 1.6527 - acc: 0.4542 - val_loss: 1.8754 - val_acc: 0.4167\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 219s - loss: 1.5760 - acc: 0.4417 - val_loss: 1.8740 - val_acc: 0.3500\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 203s - loss: 1.5554 - acc: 0.4417 - val_loss: 1.8887 - val_acc: 0.3500\n"
     ]
    }
   ],
   "source": [
    "# fit for another 20 epochs\n",
    "cnn5_results = cnn5.fit(train_X_tempogram_2, train_y, batch_size=64, \n",
    "                        epochs=20, validation_data=(cv_X_tempogram_2, cv_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CNN 5 results\n",
      "Train acc: 0.4542\n",
      "CV acc: 0.4167\n"
     ]
    }
   ],
   "source": [
    "# show best results after the 20 epochs\n",
    "best_training_accuracy = max(cnn5_results.history[\"acc\"])\n",
    "best_validation_accuracy = max(cnn5_results.history[\"val_acc\"])\n",
    "print(\"Best CNN 5 results\\nTrain acc: {:.4f}\\nCV acc: {:.4f}\".format(best_training_accuracy, best_validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2D Convolutional model is doing just a little bit better on the 2D Tempogram data than the 1D Convolutional model, with the **best CV accuracy of 0.42**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final CNN 5 (tempogram) accuracy via sklearn (CV): 0.3500\n",
      "Final CNN 5 (tempogram) f1 score (CV): 0.3134\n"
     ]
    }
   ],
   "source": [
    "# predict and one-hot encode\n",
    "cnn5_pred_cv_y_tempogram = cnn5.predict(cv_X_tempogram_2, batch_size=32)\n",
    "cnn5_pred_cv_y_tempogram = utils.one_hot_encode(cnn5_pred_cv_y_tempogram)\n",
    "\n",
    "# we can also use sklearn directly to get accuracy\n",
    "cnn5_cv_accuracy = accuracy_score(cv_y, cnn5_pred_cv_y_tempogram)\n",
    "cnn5_cv_f1_score = f1_score(cv_y, cnn5_pred_cv_y_tempogram, average=\"weighted\")\n",
    "print(\"Final CNN 5 (tempogram) accuracy via sklearn (CV): {:.4f}\".format(cnn5_cv_accuracy))\n",
    "print(\"Final CNN 5 (tempogram) f1 score (CV): {:.4f}\".format(cnn5_cv_f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding augmentation\n",
    "In the previous notebook we also figured out ways of shifting and stretching our voice samples, as well as adding background noise. This methods will effectively enable us to generate additional, slightly different training examples.\n",
    "\n",
    "In many cases we would do this by creating a batch generator function that is called within the model's fitting function, effectively turning the untouched batch of training examples into a larger batch of preprocessed samples. In our case however the shifting, stretching and adding white noise has to be done prior to the other transformations that we've found make our models more effective (extraction of MFCCs and Tempogram).\n",
    "\n",
    "This means that we have to use the shifting, stretching and adding white noise on the raw .wav files and then turn that data into MFCCs and Tempograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paperspace/tensorflow_speech_recognition\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first create a new directory for our preprocessed & augmented data\n",
    "path_to_sample_preprocessed_and_augmented = os.path.join(path_to_sample, \"preprocessed_and_augmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "The syntax of the command is incorrect.\n"
     ]
    }
   ],
   "source": [
    "# create the directory if it's not there already\n",
    "!mkdir $path_to_sample_preprocessed_and_augmented\n",
    "!mkdir $path_to_sample_preprocessed_and_augmented/train\n",
    "!mkdir $path_to_sample_preprocessed_and_augmented/cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data\\\\sample\\\\preprocessed_and_augmented'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_sample_preprocessed_and_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06076b6b_nohash_2.wav  3d53244b_nohash_0.wav  b4bef564_nohash_1.wav\r\n",
      "0819edb0_nohash_2.wav  4ec7d027_nohash_0.wav  b7a0754f_nohash_3.wav\r\n",
      "0cd323ec_nohash_0.wav  742d6431_nohash_4.wav  c5570933_nohash_0.wav\r\n",
      "0e5193e6_nohash_1.wav  778a4a01_nohash_0.wav  ced4e2a1_nohash_0.wav\r\n",
      "35d1b6ee_nohash_3.wav  834f03fe_nohash_1.wav  ced835d3_nohash_1.wav\r\n",
      "38d78313_nohash_1.wav  884ae8e1_nohash_1.wav  dabf67d9_nohash_0.wav\r\n",
      "3bfd30e6_nohash_2.wav  a1cff772_nohash_2.wav\r\n"
     ]
    }
   ],
   "source": [
    "# copy all train and cv subfolders and files (untouched) to the new directory\n",
    "!cp -r data/sample/train/* data/sample/preprocessed_and_augmented/train/\n",
    "!cp -r data/sample/cv/* data/sample/preprocessed_and_augmented/cv/\n",
    "!ls data/sample/preprocessed_and_augmented/train/down/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the train and cv paths\n",
    "sample_train_and_cv_wavs = sample_train_wavs + sample_cv_wavs\n",
    "len(sample_train_and_cv_wavs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run our 3 augmentation functions on all .wav files from our sample train and cv set, saving them in the new folders\n",
    "# seed the random module for repeatable results\n",
    "random.seed(12345678)\n",
    "\n",
    "for wav_file in sample_train_and_cv_wavs:\n",
    "    \n",
    "    # prepare output paths\n",
    "    wav_file = wav_file.replace(\"/sample/train/\", \"/sample/preprocessed_and_augmented/train/\")\n",
    "    # or in the cv case\n",
    "    wav_file = wav_file.replace(\"/sample/cv/\", \"/sample/preprocessed_and_augmented/cv/\")\n",
    "    \n",
    "    output_white_noise = wav_file.replace(\".wav\", \"_whitenoise.wav\")\n",
    "    output_shift = wav_file.replace(\".wav\", \"_shift.wav\")\n",
    "    output_stretch =  wav_file.replace(\".wav\", \"_stretch.wav\")\n",
    "    \n",
    "    # random white noise\n",
    "    # within reasonable bounds and a constant seed\n",
    "    white_noise_factor = random.uniform(10, 40)\n",
    "    utils.augment_with_white_noise(wav_file, output_white_noise, white_noise_factor)\n",
    "    \n",
    "    # shifting (default factor)\n",
    "    utils.augment_with_shift(wav_file, output_shift)\n",
    "    \n",
    "    # stretching\n",
    "    stretch_factor = random.uniform(0.6, 1.4)\n",
    "    utils.augment_with_stretch(wav_file, output_stretch, stretch_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's listen to our augmented samples to confirm they are different in the desired way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "utils.display_audio(\"data/sample/train/down/a1cff772_nohash_2.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with random whitenoise\n",
    "utils.display_audio(\"data/sample/preprocessed_and_augmented/train/down/a1cff772_nohash_2_whitenoise.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with shift\n",
    "utils.display_audio(\"data/sample/preprocessed_and_augmented/train/down/a1cff772_nohash_2_shift.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,UklGRiRgAABXQVZFZm10IBAAAAABAAEAgD4AAAB9AAACABAAZGF0YQBgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA//////7//f/9//z//P/8//z//f/+/////////wAAAAAAAAAAAAACAAIAAgABAAAA/f/7//r/+//+/wIABgAJAAwADgAPAA8ADgAMAAsACgALAA0ADwAPAAwABwABAP///f/8//z/+//7//v/+v/5//j/9f/z//H/8f/0//n///8EAAkADQAOAA8AEgAVABgAGAAXABUAEQAKAAMA/P/2//D/7P/t//D/8//y//D/7f/r/+v/6//u//T//P8FAA0AFgAcAB4AGwAVABIAEwATAA8ACAD///D/3f/I/7X/qP+j/6f/tP/D/9D/1f/W/9j/4f/v/wAADAAUABkAIAAoAC4ALwAkAA4A/P/x//L//f8CAP7/9//0//n/AwAPABkAIAAkACcAKgAtAC0AJQAcABoAJQA1AD8APgAzACUAFAAFAP7/+P/y/+v/4//h/+D/2//Q/8D/t/+6/8v/6P8GACIANQBCAEYARABDAD8ANwAtACIAHwAYAAsA///n/9X/w/+x/7L/u//P/+f/+v8CAAEAAAAAAAcAFgAqAD0ARQBMAE0AQgAtAA8A8f/Y/8r/xv/H/8H/sP+Z/3//cf92/4v/qf/I/+T/AAAbACoALgAmABMA/v/z////HQA/AFIATwAyAAIA0P+i/4j/if+f/8H/6v8OACgANgAxACEAEQAMABUAMQBcAIcAnwCcAIUAYwBEACkAGgAUABUAFwAQAAMA7f/M/5//dP9q/3r/l/+6/9n/8v8AAAIABwAXACwAPABMAGUAgQCSAIwAagAzAPv/0//H/87/3f/u//L/5f/T/8P/tP+s/7f/z//4/yIAPABHAEYAOwAxADMAPABGAEwASgBGAEAANwAiAP7/xf+J/2D/Tf9b/4L/sf/Y/+v/7v/s/+j/5//x/wcAJwA6AD0APQA+AD0AOQAoAAgA5f/F/6z/oP+Z/47/hP+B/5H/uv/p/xEAMgBMAF0AYwBjAF4AYABqAHsAlwCyALYAmABhACIA8f/Q/7v/r/+o/6b/qv+1/8j/0v/I/6r/lv+e/8f/BAA+AGsAgwCHAH8AcwBdADwAHwARABQAJAAuABoA7f+z/4D/Zv9p/3//of/E/9v/5f/p/+n/4f/h//L/GABJAHEAiwCQAHwAWAAxABAA/v/0//z/FQApAB8A7f+i/1r/NP89/3L/w/8PAEgAXgBVAEAAJAADAO//9v8aAFgAlwC2AKwAdwAaALP/a/9V/2H/gv+s/9b/+f8EAPX/1/+8/7X/y/8AAEsAkwDBAMYArACBAE4AIQABAPv/DwAqADkALwANAOL/q/97/27/h/+///v/IgAyAC0AFQDy/+L/9v8gAFAAfACjALgAqQBxACoA5f+0/5v/mf+3/+f/DwAZAAQA2v+g/2v/R/9K/4X/5f9FAI0ApwCSAFoAFwDl/9b/6/8MADEAVwBuAGsARAD//7P/dv9P/0//cP+n/+D/DQAiABYABgD9//r/CQAuAF4AggCAAFYAJQACAPT/BwA9AGMAVQAaAMH/c/9F/zv/Vv98/6L/yP/u/wwAHwAaAAAA8P/5/xgAWACmAOkAEAH8AKgAPgDY/4r/dP+O/8H/8P/4/97/r/93/0r/N/9M/4//7v9RALAA6wD0ANgAoABnAEgASgBmAIgAhwBiAC0A1/90/xT/1/7Z/gz/df/7/2YAewBOABYA4f/U//3/SwClAOAA2gCnAE8A1P9V//P+2P4C/1//zP8QADAAKgD//8T/f/9Z/2H/b/+r/yEAqgAaAUMBHQG7AD4Asv9J/x//DP8m/3T/0/84AIwAoABsAOr/Uv/s/r/+2v46/8z/VgCqALEAdgAeAK7/cv+P/9j/OQCOAMUA+wARAfUAxgCDAD4AEQDm/9T/8//2/7T/N/+//qP+zP4Z/4n/AwBhAIgAfQBlAG0AhgCiAM0AEgFWAWgBMgHIAGAAAwCc/yz/z/6m/sX+DP9d/6v/vf+Y/2v/fv8bABMB+QGFApsCKwJgAXsAuv9Q/x7/Bv8m/1X/V/8O/3z+5v2t/dX9W/5M/zQA7ABbAU0BGAH5ANkAwgD2AG4B8wFAAvgBMwEhANX+pP33/PH8jf2H/nv/FwBMABAARv94/kX+xP6+/8gAowE+AmgCDgJgAX0Ajv/P/oP+v/56/20ANwGPAVwBzwAFADr/pP58/vn+0f+HAN4A1ABTAIr/3P6X/sP+Ev9x/+b/awDbADEBZwE6AeEAgwAcAPD/9v8ZAG8AtQCgAEkAtv/R/vr9j/3S/bv+cf+y//D/KAB5ABoB1gFYApgCcQIzAisC9gFzAcgA2/+//uH9Lf2M/Eb8LPxk/Br97f2c/iT/m/8lAPkABwIFA4MDZgP/An8CUAKBAqwCbAKHAToAtP4f/cP78fri+ob7jvy+/Qb/6f8AALf/uf9hAIQBjQJOA9oD3gNLA2sCOAHV/7X+Bv4P/rj+kv8xAAYAGv8f/r39t/0s/lb/4AB1AlcDXQO9ApwBQwAb/2D+IP6X/mb/PADmAEABUwHLAHf/Af5Q/VX9xf23/jkAtwGHAn4C5QEaARwAFv8w/sf9Wv57/1MA6AB8AdQBlgGhAMH/wf9mAP8ApQGBAgcDswJ0Ae//g/4l/dX7OvvB+8789v0d/yUAmgBnALT/5v6w/ir/lQChAqsEMgZ8Bm4FQAORAF/+b/2S/UP+kv++AK0Abf9b/R37rPmD+c76g/2rADMD+gSEBbYEGQMmAaD/4v4u/2YAGQJlA4oDlAKRACj+Pfx1+1T8Y/5YAL8BewJNAlgBLwB7/1r/pf80AOMAgQFoAbAAQAAjAOH/Vf+2/g3+Qf3K/En9rP7z/3IAjAB/ABkAk/+X/wkAggDHAOcA/ADbAPYAQAE1AaEA4v9F/9H+//6N/6AASwJHAyoDlQKDAcf/8/2V/DT81fyY/VX+Kv+Y/7b/4f8FAOr/jv9B/43/4gB4AnkDswMMA+YBoQCw/6b/cQBGAaABWgFWAKD+MPzN+YH4P/kW/F3/7AE1AxIDCgLnAIIA6QCYAaoBQgEsAU4BYgEoAZYArf+r/rz99fy1/OH8zP1u/0wB/wIhBFIEUQP8Ad8AKgDk/9X/YADHAO8A2AC2/+P9nfv3+Sn5VvlM+yj+vADMAdcBOQHG/2X+d/1r/pQAmAKRBFUGgge5Bs4Dtf9l/Hn6wfnU+gT9qf//AVMDkwPjAlIB9/7u/Lj8VP7EAL8ChAPcA1QD2wHS/9r9Vf2e/Zv+XAAwAjsDogKcAJ7+tP2Y/bz++wD1Ah8EhQSZA5YBJf9J/dz8bP0d/6QBjQP7ArIADf4B/PP7Ef0A/7cATAHeACIA3v9t/wz/nf74/Qj+hv7M/ur+2f49/2kATgK3BKMGWweiBvIE4gKTAHH+JP0D/Zv9sv7q/10AZP9L/YP6Rfj896z5gfzf/qgAmwGZAb8AQP8Z/qT9rv5zAEYCAgSnBGkEdwMJArMAi//8/VL8PvsQ+1f8gv6PAKEBHAEaACf/cf4V/3sAWgHEAXcCkwIJAlYBkQDaACgBKgFoAUwBFgERAVsBEgEVAOn+lP3u/NH8bv0A/8YApwJsBHoFpAX7BNgDCwPHAnoCaAK3Aj8CTAFEADD/X/4T/aL7ZvpE+X35L/sV/QT+Yv2v+lv3u/Ur9o75v/+XB2EP8RLXEIQKlQKs/AH7Ff7jAxIK2gxDCoADEvqO8e/ryekE7HjyYPqV/64BGQFG/yP9dPoY+uT8egIoCFgL0wzgC38I4wKU/ez6QPuu/oIBhwJFAkUA2/td9WzxcPFw8+32MPzMAr0HqwkeCfwGowR9AnkBagF7AhgFPwjTCVIImwUeAjz9t/eD87HztPd2+6r9tgDjA3AE7QFr/8//HQOfB7ALJxB6ErIRSA5wCQMGygNyAUP+9/up+YT3pvba9YP1sPbI93f35fV09K31vPjJ/DoC5wgBDi0PVAt0BH//VPxW/JQAegcKDqIQmw6WBzP+e/R57qntLvAx9i/9uAHFAEn8/PYO85vxhPMY+wcF2Az0DpYL2QTq/IL25fRg+W0AGQhCDUQOnAplAj34lO8o7HHuMPezAskJ4gocBiz+EPer8cTxx/dzAUMMSRICEzoOhQVJ+230mPUH+5AClwcwCrEJ+QN6/PvzAu+/7n70+f7DB6kNYQ1tCXoE8v7E/ukDuwx4FW8bnR7aGy4UiQgK/xL5J/N58YrzxPia/PT6n/eg89fv8evc6TPr8O4c9T38CAXOC0ENoQtHCGUGGgeeCtMO3RD8EMYMeQXP/FH01u987jbw5vTj+Ev4YvMj70HuDvOE+wcBLwI7/tT5kPdl+B8A7AqOFq4ddxwdEh//H+ud3Qff+ura+W8IzQxYCeH+xu8y4/HbcOXb+YMOSBs+HkAd0hLsBJP2FfCe+WYHXBXvHScgZhg8AYHkMc/SzAjWxeS/+/gU/yR8IKEP0f/19U7wPPPwBsMjHD5xRjw7zCjxEoAAgvMH6Q/mGetd8cT3tvzx/OH3cO1Y423det/86bX2eAOIDscY9B3eHGcYPA+XBusCkARBCawMnwlPAVL1sOW53dnf1uSD7IL1RP9zCbML4AcqBEoBgwBN/dX8dwGRBcEH/gaJCIIIZwP8+dHtquSu27nV6dJt19DmivWaAOsEbQagBwQFfQLoAuAJjxNQHxIoaiNhFlYGavde7ifpUukP7/X1FwGBB+IGYQZi/o3vnuDe3lPrXv16FAgqsD9WTWJGAjMIHHwGcfgL+OkEfRK2Gwsdkg9l997ZdcOxuyvAbtCL6lkJ+R8OKfclWRkPCtv9/vi7/VoMgh4dLB8v8SRXFIwDNvIj4LbR1ctv0Jbdiuzc9tL4BPaW8+v1Jf6bBkMO1xXUHUQkOSYxIicVIALd8PHnc+hj6lTndeAv13rPc8tQy1zQeNjx4J/m2eo77/70Hv+dC3oYeiR3KycsxCYfG2sMH/2i8Azq7+fn5Nfd1dnp3Vnmtu6O84fzy/J09/QD8Rg8MPE9zj3mNZEvpC6xM0c9WUWKRZM5oyaIFTEIKPxr707lRd+k26TZ6NZs0nnMy8VHxFfNVN9b9YYJeBnxJGErvS67MfQ0KTRMLb8lbCEUH7caAxK4Bzn8p+7d4ZXYGdMXz8vM5M2j08Pd5ulK9Nn5SPyj/UgAwgUPDq8X+h0SHcEVtQ1SCBcBUPMd4zrY29OM0ZfSG9oc4snjvOHF5B/vj/gx/egCeQrDDgAOAgzDCzUK0gOv95rp99sz0BjLGM8l2yHqVveyAt8L+RBiE3caRSoUPKZIB0/dTyJLZEB6MVYm4iIKIcocIhe4EJkHsftY7i/gLNLNxEW95cLj0i7iq+tC77ftXuo06gTx9f66Eb8kUzZmRJtIJEJZNoMoNBzFFl0XORc+ElAJevxR7cLe6tNSzxfOv84h0s3Vedfn1yTb+OQX8qj/ug/zH0Aq6CwJKp0ipBcvDJ8DAf459qfp/t1Y1tjOW8fDxEbIxM701s7gluz9+tYIWREyFasXTRkIGaAWzhPXEJkLfgPR9zjmnM/ZuRGtlq8xwAPZe/SKDYsgZS6jN7w5MTsEQQhFtEZCSMNHoEX6Pl8w/h/DEM//vPJh7rnvJ/Vd+bv1oey34OLRNMVRwgLMCt+i8HH69QI1C5ANtgxzD14WjB5mJ6wwojfdNsotESI3Fm4MoAb4AykC6/vl8FXoE+d/65juhOkS3/jVWtBr0CbXU+FZ7N33ZAK1DbgbQCjjL2QvVSaiHEAVtglQ+VHpjdt+0OLFL7rgsomxf7XowjPXauxl/ngI8Q3XFHsbcyHAKeYvzi/HKhYg4hPnCGn3qtz6vy2oiJtnnxqx+8hI4TD4cw5aI1w0nz8DRwZONlMYVOFT7VNcTjU/OymbE4AF0f7z+oz2x+8K6W7lfeRs5rXpcuhA4YHbct1C597yt/fv+HH8CAHbBxsPtxPvGPAfiSWHKBcpyiUFH44Vuws3CrIPsxE8EXoN0QLt9tnq8OFf37Ddnd+A5R3mad4V1JbNaNCC3hH08Q4JKNo3zUDlP0Y0ZyesGX0H0PEn2czEDLpos0evHa5DraCw8bwO0b/qQQNYE+EdNijCMgk9t0GiO4MwGSaGHs0YlA07+d3bl7WGkqGAAYCVj0Ssa83z8YAXezPUROxOeVCYTztSHla0We9ZolOKSD43lB8+CJX0neY74YPhvONk5SnkLOMA5T/ob+uo6y/tefa+/sv+ZvyL+138QP6UANYGpxLwHMsgaCA2HbgXKxGtDEAP/BVqGC8XBBUJEPcLDwvkBzIAh/Qc5pPartYj2JnZStiS1S3VQdn74xT3ZQ5NJSU470NmSf1EqzGOFFH30t/3zf289Kx6o1KhYaQpr8fBY9Ul5S/wc/rkCIIY7ygAPvRRWlrkVOlGSDTxHKQAluAxwmSrSZ1ame6dI6QiqpK0LspF620Pai9tRwRXr2DfYwlgxlmjU3dM8kOLO7g0BCtlGKD/++cE2JrTTtaF2JTb1OPk7VH29f4YBlgGuf1v8c/qh+tS8f/7YAhvFWoh9iPkHWUWEQxl/4D2F/Wt/tgTOyshPFdD5TkoIC0Eg/Db5hTn1e5X9iL0Reee2AnNn8N6wMHI2dnV7bQB/xWpK3Y/6EsATcVAkCmhDWrxYtfFwwq5a7O9rCOnE6sbuT/Jt9Ya5Jrx8PoSA0MQoyDRMMlAfVDjXMZdaEsQJxX3tcKpmliO65grrvPEW9RM3YnjWeSM5t7zgAewG0ky00qWYdVv427FYvZSKEClK7samxGID6sLmv2A6n7dR9iX1/Pa7+P18mIAQwbWCN4IBAO2+NPum+zq88j8SQJUCGQQqxSkEukMowKG9QTuRvIuAE4V6DGbSh9Tp01jO1IcXPvR5EbdVeLE7KP0lvJi43jNZLtWspa0GcTV32sCAyI6OkhLSk/NROMy0RupAXnr/do1z/bIycS+wZzCasMJwhzBwsCGxLTRUeUn+90RaCGAJwguVTePQaJKDUXXKbgCtdjhs/eeS6DBtCrS4etz9qXzZe/z7H/oAuWw7j8LSS7xTLZoM300fx1sUEm8IYYFvPlF+SED8g+JE0sL9vhz5Bbaitkp2+jewukL+osGcAyuEekWVxVdCuD5Detc5gHvQgAQECsWCRQaDugFyv+UAEML3B1hLos3IT28PZ8y8R1KBoHtitkb1Dbac+I66mLtJeed2zTTt9IF3D3u7wSuG14tyjQjMPUhjRDk/0Lvu+AX11zRyM9S0xXbu+J25BrdUM8nxODCLs6A4JXwWAGnFKAgiSJ6Ir0mEScJFmj6CuIO0V7Kcs5226nthfytAnMAGvgr7r7np+YQ7Bn9MBoKORBSwmIdaNFgi0t5LVcRbfuz8Rb7Ew/dHYgdgg4U+ETe3soIydbT9uQs/KcSrCHJKe0pjB4LC9b1d+Ii23Xlfve2CcoYrx/pGSMJjPlz8lHysPqeC3AhNjbuQfhABjNTHEgFjPH64s3cAuCF6ub3BQPZBcj8zewa3rDUPdHN1qjppgIfFAMcHx16FHIEcfTG5zTiRuSB5zPp+uuc8dP3VfXq5P7Ps8EkvYDBnsz92pfpb/fRAi0K6g+GEqEMhwMB/9P+/AGcBOYDUQUKCQkJVgO/+TDx9Oz67Av0LAY+HjIxJzs6Png94DmRMXAluReYChsESAbRCvEMOwyGBz38sO7z50TpwvC7/b8MzRk2IRog/hROBGn23Ooz4hPlRfRWB2IVuhynHa4TYgO69XHtsO/7/QcQYh9YK40zzzNAKrQb3QvC/J/wvepc7HXyKf1xB1kFCfhg54bU9cNXvrfGntlv8RUIPxadGGATSQufAXX4K/OM81L3wfmE+oz6w/Ti5k3VYMJtsjOtwbO8w3/Yg+fZ7T3zbfsbBgsT7B2dJFUpeSocJvYeqBVQCJj6QO8H5uvjOesK9kYAcgrLEQ0VNRn3HZYhpygzMOkx/y/4KV4fCxVoCwIAYfOL6Yfpy/aPBosL4AlyCEQFaAOeB8UPPhafEqkFGfxM+iL7dP4fBCgFHwEl/6oAHQOkA44ABvzS+bD9Tgf0E7kihy03L8srzCVgHBsSqgn4/+fysujU5WjlQeJW3brX088/xyrFR84X35vyFQZEFfYcYB0oGGwREwtiA6H7FPTR65/lRuGN2hvQDcXQvFq3J7SEtozBwdFz42L2iAeZFbQiUisnLFYtlDKSMiEqeBv1BUfwMOKF2j7ateOx8VT+AAqgFAobbx7XIPkgAyF1JJ8rsjKsNGIwVSUSFAcBgvMY743teO329Kr+9gHEAmYGpAlYCjALXQxxDGsKvAdjCd0NWw7aCgQINgd+BHf9lvYz88vy7/W//H0GERLJHBYkkicvJ+8hwRmGEm4MPQYGASX86POj6YnijN782j3YkNfD1gLWtNr0467tPfnYBLULbw7nDwMPHQncAIH4HO7h4wncsta/1B/SmswTx/7C38LdxxXR4N0/67n3NgS9Ds8W7R99KLwsNy14KAkeyxBZA7r5gPSc8DLw7vYVAW0JkhDUFZoWKBXKEtMQeBPfGRYhhiXIJDokViSMH0UVTgcD+2Tz6+7S8S39IQeWCDwGjwXfAjf/qgCtAysF3AefC1MQRhb+GOgTTgmj/ZfzoO/B8Y/2GgCNDPQVEBy+H+AeSRmXE0kPogmQBPsC9AKqAD37oPSp7J/kEuDN3gTgbeQ66QvrXuw27lXsRuiy5+7qEvHG+ccAFAO4AEX69fHx6YzjWd0x1CDLusjyzDnUe9315XrpIOqH6+TtqvUCBM4QzBiNHVMe1BsqGYcYsxhBF8ETWQ8/DUMNDAyrCuAIkAQgAWgBXgMtBS0IJg1VEX4WNx/8JX4nbCVQIDEXYgseAyMAC/8y/lX90P7U/xj8tvla+x384vy3AfEIsA+WF1McRBgKEfgITv6O9wb5i/4WBF4Jjg4nFMoZ6RtIGt0WLhCmB9cAXPxu+tv5zPcq9aX0UPQz8c/t5OwM7D/q2+mq6ubppebJ4qngLOHE5Crrk/FL9mL6jv1O/m37UfSv6Ova9s/+yALGRcgnz9zYGOMM7Inz/PpoAgAH1wlVDksRzBAwEG4QjBJJF34dbSOGJ9koHCV1HOsRzwXD+ejxZO8S8WP1OPyYBEkNnxeFIt0qfy7OLJwnKyBXGDATQg76BkMAk/pV8xnrmuYB6J3rYfAw+LEBGwzVF3sg6CGaH5QczBXsC0EGsgWyAz4BYgJbAzcDHAZNCrMNfRJrFqgVYRA6CKn+gfP16F/kbeZv6qbvuvh8/9/+B/2p+u/y1egI4MfWN9Cu0VrYsOCI6hv0XvxgA9gH0ggmBdr5Deiy1tLJSsFAvjrAGsaQ0i7ku/R4AlUOvhWTFkoToQ04B3oEvQWmCGcOdBd8IBInHyv9KxwoNB4kEAEC8/UY7qHrx+xs8kT9agnpFL8gsCruLrEuNytrIwEb5BM9DOsFqQFI/Tn2fezI5inoieub78L3QQNPDk0XBB3rH9shKSAgGaYRJA1PCRIEsv4w/HP++QICBygLYBBIFk4adRpUF64RIAn9+4/smuDi2ZTYkNyw5IzvWfj6/LP+3/st9RzsDeFo143Sb9Mo2S7iY+3i+D0DGAw0EMsLM//b7RLc0cuGvom2qLOGtlTCN9VW6sEBlBihJ9YsNCqJIl8Wggg7/5z6a/rEAFwLrBeJJJou/C+KJ70cpxKFBQT4re/J6wbskvNQAMENvxv3JxgvLzFRLkgnUR5LFYsLbAEY+7f25PAW7Xrs1u679Dj7RAE+CDAPlRM6FQYXrhhOFywUqRGTD3oMVAemAKv6yvic+wgB4wjgE9oftygALO0pUyTCGXYHYfFw3YbO7sZCxwLNSNbz4knv6Pet/W7+mfj97+jmO94b2XPZvd5B5ybxjPwkBgIKngjgAFHzC+S91UXIvryctsO1wrp8yM3cB/PKCFUckCmhLqQs5iOSGGcOoQVdAaMC7AfpEfwelykCLaAqXCWtHF8QlgHA9LDsJ+nC7P710wEWEAweJylBL1ow7i52KlUiIha2BqP4ke1Q5cfhxeMC6k3zCf7MB24P9xMLFXYVehbYFTYUNBPOEXwQhw/QDJcHqAGA/Yr7YfwWA1sOPxkaITYmGSmGJnMdphBd/9jp19Z7y3bGhMZ6yzvT4ty16In0H/0zAK/92Pas7eHkVN4V3Afe7uKZ65317P4YB+AJ4gWU/G/uS90JzKC9N7PMrmW0yMO52cLygwktGwMnoCsUK00m5hzzE5sN0AjjCWESiB2aJi4q0ihmJcMf3xW0B7P4sOxk5sPn6O98/OgKShhDI1wq9C2KMIUvZyccGigLo/yn737mWuNE5WHqnfIi/ocK8BOzGFcZehjQFwwW0xNLEjERKxDcDi4NigkHBB7/7ftD/BgBgAgfERUaJCJwJxIoziQyHVAPi/wn6GLW4cnNwrfBrcV+zWrZoedw9Bf9dAH6ADT6yu+u5SzeE9xS323kYOoN8sb6igFjA7D/ePY16ZvaTcvfvIy0RrWBvlDOAOFc810DeBAZG38iGCUIJF0h+xsIFsAVURtZIYUlQCjqKGonSSTqHbgSfwXp+arwk+yX8BT4sf/1CfoUSx0AJM8o6CgOJM4b+BBwBBD4GO+f60/rHeyy8Cn66gSMDhYV4Be/Gm4dzxz6GiQZ4xV5EacM7Qc4AzT+Kfqb+Lv5m/3EBHoOUxh1IKsldSeWJvoh/xZPBpfyQN4KzSbCy73kviPFqtAK3zHtLPoeA5IFqAEA+OHrJ+JX3X7b0dq23UjkQeyj9KT6vftl+GvxG+eP2t7OYcYCwonDOMuh1lHjcPAM/eQHoxEXGkUfKyGkIW8ivSS5KO4syC9wMboxOi9TKSIhNhdBC4/+UfTK7vPsOe7l8ov6RwVEEc4bCySJKJYoBSVfHZkSMgfL/Er16/Da7vjwy/dTAMQINhByFbYYEhvrGzMa2hdxFU4RPw2aCTkF9QFC/7/8fPw+/hMDzQuSFOAZaRx/HaAbnBbWDlsCHPIP4dHRF8hUxaTHtc3y1unhcu1e+S0DQgfHBHr7Ee+f5Qbf0dnW1l/W4tic3u3lCOy57kDun+ua5j/gUtqv1eXT29XF2sDhQum+8Br44f1cAyQKHxDwFNIZRB7ZIpwo/S5eNHY31jeONBUuhiazHdkRHwVd+7/07/CO8H/zUPkTAtkMVxbRHNggYyKqICgbDBPpCoQENABD/YL7Bv0NA/gKEhFvFB4WORdiGMsX5BPIDt4KsQiLB4MGuQXNBWIGhQaPBsMHYgqxDSQQ0w8nDRwKAAeKApb8rfV67cTkf92b2AXWn9bV2szfDeQC6mfySvp7/mL9L/h98T7q0uF72I/QF8yfyyHOCdLC1rTbluBI5cToC+sc7dLuVvBo8kv0lPW+9vr2z/YG9wP3FPlU/r8EXwx5FEUbAyJSKikySjadNj408C63JxcfMBXWC7wDW/2G+S/4XfqCACsI5Q9nFpEZkBqUGkkYCRSzDwIMtwmnCVMLTA13DxcSWhMsE/MRyA6HC+QJ4wiDB2oGRAdlCiMO+xArErQR9RCBD5EMqQmFB28G5wXuAwsBFf6U+sz3/fRY8BHrBea64QLfJN1/3FDe2eHT5rzsnvJY+Lf7W/vh9yzxnOh13+3U2sp3xB3CpcNTyDzOu9Q43Lnkdu1k9bD7v//IAjYGIwinBhUCXvxa99vyJu/d7TLwXfaE/nMGTw4fF6cgXygSLEEshiqzJ9QjMx6eFpsPGQuyCAYIXwgqCn4OUBQJGiYeYR+zHlQdWhoQFisSeQ5FC+4JGArWCi0M2Q0eD8wPMw/VDJwKLArXCYIIzwcjCS4MhA/kEcgSjxKjEYAPRgwcCVYGygNMAdD+gfyM+Tn2pfO68MLsbehL5Frhq99m3nreeeGx5nLsufFB9oP6Mf2e+7z15OwX4pbWb8s2wj+837r5vnfGqM+/2ojm0fF4/NMEewmWC54Mbgw9CukFPgBv+hz12PAk7sbsze0T8jf3xPsGAW8Hvg7MFYAa4BxOHjYfhB8uH08e/RwLG3EZNhm3GfYakB2kINUisSMHI2IgfxyBGGcUPRAxDPQI2gfUCMcKrwyRDgQRKROXExASJw8EDLIJQgdcBOgCrAPlBQEJRwxsDhkPfw/HDwkPTg2EC9cJkAfUA0/+GvhA8k7s1+VK4Ajd9Nu23Lzem+H15bjrBPCb8aryhfJ472XqMOMT2unR+stwx+HEjcXDyazQ5thw4TXpqe909QX7PP/QAGwAiACaAeUACf4A+0b46/Vx9LHzPfPf83D2t/n7/I8A2QMqB+UKlg37DpUQTROyF7ccNSGLJRMpyCslLq0v8i+0LrosSCrJJr8i1B4kGyAYTxbvFEMT5xEwERcR2RBPD64M8wkvB6QD+f8I/er6SPoz+wL9LQDRBAIKVw/2E0gXhRmbGhEamBfjE3kPIgoPBIX9w/bb7+boHOPS3uDbptoP29zcK9/24ILiHOSd5KLjqOIP4tLgA9+53A3aTtj71zDYNtkg3Avgj+NC5q3odesi7jnwAPEV8bzxfvLX89327/k9/ND+TQEIAzYEnQX8BikH8QXYAzQBAP9J/c77UPxB/+UDogpfE3scfSVTLj81hDkzO0s6VDcpM8kudypYJr4jbiItIPwcExvGGrIZ6RYXE0oO6QhuA5r9wvcO85/v1u1j7kvwgfMG+Q4AsQeND00WChsOHhofSR0hGdkTrg0HB+QAlft89iHyOu887dDre+p36UvpE+nT50rlGeLu3jfcvdoG2mzZo9mU2xTfs+Kq5Xrnj+i/6dTpoOh058fmeeZs5nfmseak51LpVOtv7a7vL/Oi91f7y/5DAowFswgKC18MZQzACw8LdAioA77+p/oj+Ef3W/cS+bv9SgUIDgIX/B9LKKAvpTRPNhI2KjVCM20wEC1dKWImWyWZJb0kKSKoH8IdvRpvFUIOlgZu/yP4XPAS6rLm9eXH6G3uwfRL/CcFSA6+Fp0cvh7DHZgaRhXYDcgFU/7Y9zrz//By8PzwEfML9oj4mvkH+Dr0eu/R6ZHj792v2RnX2dZZ2AzaC9yl3jLhpuO55SLmMeVZ5ALkOeQn5VTniuod7WzuH+/S74PxRvNk8/vynvM49jH6Ev6hAhEIjQxwD4oQGQ+uCz0HRAJc/VD4LPR689j15flO/8cF6Q0eFzkfGyUxKZUrjCw/LO8p8SZsJe4kLCWQJgQoLSl0KuUqcyniJRwg0Rj0ELoI7f8494vwfewV68fsqfDF9Tb8FAPYCAQNIg8lD9kNPAveBloBJPxc+K31M/OT8c7xRPQ7+E/7xvyQ/Zn9Svyw+ZT1ffA07CDpI+aW4uLfxt5y3ozel96Q3gbf09844GvgruDk4Fvi+uQF54bpZe0p8S/0l/aQ+PD5q/pA+4b7WPs5/Lj+WwHXAzwGnQhqCisKcAhFBhIDJP9k/Bj7sfpp/AMBngdsDkYUqRkaH4IjeyV3JSkkzyFQH1wd8xujGwIdjB8JI4wmiii6KMwnmCXeIL4ZJBEcCKX/rvgq9I3yoPMn9sD59/0fASYDjgRbBAQCTv5f+vT2UvSN8q7xw/GM8j/0dfaO+Nv6t/xh/tf/Yf9Q/V77k/lg9870SvKa8FHvCe6G7Dfq1+f65fTjyOHq3/fdJ93h3mXhtePF5rzpUeyc727ySPR49lb4H/kE+uT6Qvv5+0z9Gf+uAA8CEATQBZoGPwbmA7AAAv4V+7H5dfs+/tgBDQd8DFARhxXeGBUbCBy+GyIbxBpZGiga0xomHJYdWh+dIRYk0iW/JbIjZSBAHBMXMhEOC7wFqgH2/hL+xP1//bb9Vv43/+r/+P+H/4P+qfx8+vT4r/e+9fnzePKT8Vjyq/M69Vj3KvlY+gP7Hvv6+q/6XvpE+hD6JPqP+pr6A/p2+Lf1hPIz78zqnub+48nhw+DQ4YbjWOWm59vpuOt37bvugu8M8P3vou+L8K3yb/X3+BX9YwHhBFIHrAg4CG4GLwTUAX//Cf1j+5j7Hv2q/8UDowg8DX4RrhTyFr4YeRmQGcoZPxneF7sXihgdGe4anh3rHk0f0B+fHyQeOBsNF4MSzQ3kCFgEwQA0/nL8vvsl/NP8l/2F/rP+3/1i/dP8gfur+tj5QPi39oT16fQl9ZL1l/VM9Tj1X/WE9d31X/ay9vf2vPeG+Wb8XP+QAWIDDwTgAmcBvf/x/Cv5qfR58Jjti+s96izqaepw6j3rY+yT7FXswewV7dvsP+2f7pbwivNU9xL7+P66AkEFGwd2CGgIIwd7BQ4D6f/w/VL90f0CADwDowZDCioOLRGPEzwW+BdmGHYYSxjSF44XsRfmFxoYaRiiGNgYEBmVGE4XvxVcE3QPnAp3BV0AUPwb+lb5dfm2+rb8Vf7u/zAByACf/1X+D/yq+WP4nfcQ93D3HPhB+GX4PvhH9zX2AfW18mbwaO/X7lzv4fF+9Zf5nv2kAKsCIwSFBOgDZQLB/1788Phb9pP0qfNh8xHzfvK/8f7wAfDF7gjtIeuh6fjofOkb6zbu8/GY9YL5gf1XAZYEugYfCKYIIAiHB/0GiQZDBksG9gZGCEoKpwwfD1ERJRNYFGMU6hPqEsMRQhGIENgPDBApEJcQ6BH/EpoTxxNwE+ERSg86DEgIdQTdAOf9xfx0/Pn8Dv9gAfsCzQPiA0EDCgG1/YD6tPeq9aH00vS19Xf2APfC95T45PcW9jn01/HK7yfvxu9T8ZvzX/ZL+T38//4iAeoCMQQFBLUCUQG//+79+vyg/IL7Tfpx+ev3avZp9QL0V/Kn8Dzvde5H7s3uge9/8ILxZfIA9Iv2XPn9+9j+0gDjAWkDrwS/BRgH/QelCJsJkAp2C5QMoA3xDQ8ODw5DDY8MLwynC2ALkQv3C2wMKg3hDT4ObA5EDlYNOAzaCqIItAa1BSMF9gTOBQAH3QctCUkKVAraCXIIkgWiAgUAT/22+z37rPpH+kn6bflJ+MT3SPYR9D7yTPC87l7uve7a79rxJfRq9sr4V/uH/Yr/jAFcAnsCZAJtAZYAEQBp/4P+PP3x+5j6Efl39/X1oPQz89/x+PB58Ffws/Bn8Sry9fKn88j0dPZC+EH63fs5/dj+agAAAsYD7gUFCLgJbQu1DJgNpg48D1wPDg/gDY8MiAuQCs0JzglbCg8LZwyPDRYOuQ7QDmcOAA6zDOkKAQl1B40GLwY/B0wIFAkmCn8KogpzCggJvgZSBE8Bbf7y/AT8Jfun+jr6QPke+Ej37fUC9CDyG/Ag7irtRe3Q7Qvv0fCG8hv04vXp9/j5P/zS/Y3+Ov9Z/1z/pP8gAG8ALAAAAHv/b/6Z/YX8OPuT+bX37vVk9OTz0fNT9LX1q/at90H5cvpm+3H8Dv0q/Tj9lP0b/h//ywCLAn4ElQaqCIkKEgyIDUAOOw7ADWcMDwsJCvoIsQgSCboJyQrvC+MMcQ3ODa4NNw2SDGYLRQptCawIhQgyCe4JoQorC0ILDAtVClsJmQceBc4CDgDW/RH9hvwS/O/7vPvo+sX5J/kH+DH23PQ181rxBvHp8N3wFvLa8k3ztvRS9pH36fgQ+i/6FPpe+qj67fp9+xb8O/xg/BH9q/24/Qn+/v0W/XH8e/sX+jT5ovj/9xL4/PiX+Zr6+PsE/Yb+sP87AHoAIADF/2r/bv85ANgAfgGKAowDtwTjBSMHJghACE8IDAiTB5wHbgerByAISAgMCdAJhQpgCwQMdAxfDOILUgu9CjQKJgppCmkK3QpaCx0LLwvyCoAJRwjKBoUELANCAgoBZAAkAI3/3f7D/kL+xvzm+8L68Pgl+CT3CPb09a/1g/Wj9cX1WPZY9pD2XPdM93H3t/dI99722vb89hj3nPfM96b3J/hq+Jb4bfmz+U35OPnR+HD4mfjr+HH51fm4+rz7e/ym/Zj+B/9F/0P/5/6h/pr+5f6f/xkAtgCYAUEC0AI2A7wDDQQeBDwESwRdBJAEdgWeBsoH+wjbCbEK/AryCgsL1AqCCqoKnAo9CnkKugouC9ALPgyYDMQMvgzpCwcLAgotCIQGGwWlA7YCZgIMAsMB2AHBAUYBFAGWABT/1P3T/Iv7yfq1+kL6v/km+in61vkf+j36z/lr+Rn5MfgY92L2bvWM9MX03fSv9HL11/WY9Qn2mfYJ9nz1pvUj9SX1EvbZ9iv4g/mG+pX7ffxN/SP+sv6v/nX+MP4h/mT+sf40/9f/TgCwADoBoAG3AdkB0QGVAV8BeAHkAW0CbgPNBD8GnAedCDgJoAm4CWsJcQkqCa8IwghrCHkIFglyCRMK9wpqCzgLKwvGCs4J1giJBzUG5wS/AzoDDQPiAuUCwgJpAkYC7gFNAX8Ak/9y/vH9Pv5N/tH+D//G/gr/Mf8S/wb/2f7x/bn8jPv1+av4APhc99r23Pa09ob21fbq9uf24/ZD9p/1hPVi9Wf1Avay9jj3GfhV+Wb6hPu+/IX9Jv6A/in+1/25/Vv9Ev1E/QT+1/5+/3cAzACMAHUA1/9i/57/AQCNAIwBQgI9A7oEogWxBl0HeQf1Bz0Ibwj/CDEJ9Qi+CFwIXgi2CPIIQQlwCUsJ1ghPCLEHqAZ1BUwENwNGAroBsAG+AeIBswE3AcIALQCs/wT/k/50/on++/5k/zoAkwCDAM0AnQDqAIIB6QEPAp0BtABA//z91Pzl+177+/qs+mj6fPpk+hv6J/qw+Rv5Cfk2+Jb3rPeF98f3hvhJ+eb5tPqB+9L7aPzn/J38tfwX/cn8H/22/XP9o/3q/UX+0v7L/qP+V/7f/cf9Ov5J/n7+UP9//yMAKwG7AQIDTQQjBSUGkgaYBgAHPwcdB04HTwcaB40HwQedB8oHSwdKBsMFCQWTBLQEdAQGBGsDgwLbAWUB8wDRAGYA5f+S/xn/L/9b/03/qf/b/wQAWQAyAE0ASQDL/+v/NwA6ABQA8f+I/7z+l/4f/mL9U/2k/Nj7+fsS/Ab8ZfyU/Fj8P/xj/BP8CPt4+lD6FfrH+of7vvt+/Pf82/wZ/VD9ev34/TX+X/6j/sT+Gf9c/3H/e/94/3P/c/9V/wf/xP7A/iL/q/8+ALwA1wBDAfgBoQKGA80DCwShBJgEywQnBScFEQX8BFMFdAVfBZUFKQXDBPgElQT/Ax8EwgO+AnIC+gH9ANgAAAHPAOQAPgHjAEcAOgCG/9D+2P6D/m3+0P4w/0n/Jv8R/+f+0/7N/tL+bP7//d39nv25/Rf+Vf7//eP9BP5+/Yb9k/3z/PP8kf3X/Qf+VP46/iX+0/1M/Qf9Mf3d/UX+av6F/nz+I/4b/mj+Mv5g/sv+3P7h/vf+I//z/hL/EP/j/sr/gAAAAZEB0wFRAuQCSAOKA6oDUAM7A1MDQgMMBNsEAQUjBTwF/gS/BHcEKgQTBOwDDQT9A8MDxQOsA40D1gIuAtwBNgEIAbMA+//s/5j/DP/9/qv+Wv5Y/j7+Gf4y/kD+Uv6N/gP+Hf2L/Nn7b/uL+6r7ZPud+9f7LfuA+8b7tPue/Bb9XP17/Z/9If4Y/jf+wv4Q/7n/YgA/AD4AKQCE/x3/Bf/3/qb+Sf4d/sT9rP3q/TH+pv4e/37/bv8p/zb/Df/7/lH/Nf8k/5P/zf85AAcBjgHZASQCfAKlArAC5wIIAzEDiAMwBPIEogUlBiUGIgZIBlgGFgbPBVgFhAREBEwEGwQIBAkE0gOUA7cDowMRA54CQwI0AmACNwLjAYEBKwHFAHQAfwCAAHEAPgCX/+f+Dv4m/aL8CPw8+4r69vk7+f74//jX+HH5AfqP+kL7Kvvw+s36g/q1+mb7M/we/RL+v/4C/w//3f6l/p/+cv5Y/nP+gv6a/n7+WP4b/sz97P3T/RP+pf6t/tX+5P6o/tz+Yf+d/wgAugC0AOwArwHIAZ8BbgEiARIBrAFkAqcCJQOGA9UDfQTbBDkFaAWBBesFtwXlBUUGrAVKBekEdgQaBGYDJwPYAi0CTwKVArsCRAN9Az4DPQNVAwkD/QJKAxwDvwJlAqkBDQF+ANj/Kv+x/ib+Mv3Z/GT8yvtV+5f6G/qC+cP5bfpY+rv6Vftd+1L7a/tM+/T6yvrw+hH7vPuf/L/82vwR/Uv9sP1H/r/+t/7o/iD/E/9G/1D/Lv9S/2L/Tf9U/2b/HP/+/gX/v/7Z/s/+xP5X/77/0P8HADQAYgC+AB0BzgF9AukCmwPUA3YDPwPDAmIClgKIAmsCwAIiA1MDpAMbBO0DkAOKAxQD6QJOA3ID2ANTBEAEeASVBPoDVwN7AtkBowGaAdEB2wHdAa0BfQGLAY0BZAEYASkBXgEuAccAUACU/8n+W/6y/ez8Gf0//Zf8hvxm/Iv7Q/sz++76+/p4+9j7VPxF/Y39of3u/RX+MP4r/l/+u/7p/tr+yP5b/sv9yP2y/aL9+f1i/qj+8P47/2H/gP+K/6T/ff9F/1n/BP/s/i7/4f7R/kv/kv+p/w8AfgC+AP4AEgHOAKwA5QCrAKYAFQFwAfMBIQIEAgwC+AGAAVQBcwFDAXkB5AFJAp4C3gLjApUCpQJ4AmICgwIPAt0ByAFlAWUBoAGdAdsBNQJLAmYCLQKzAVIB+ADDADEApP+8/8L/y/8gAB4A0/+A/xT/k/4J/rn9OP3m/Bz9Ov1I/Uv9jP2r/bP9Qv6i/rX+1v4S/yH/Ov+x/2H/Dv+V/4b/bP+g/zL//f4W/8f+b/4//v79qP2f/er9fP4F/13/qf+j/1P/7v7S/sr+4P5f/+T/eADaAMcAiAAYAOX/2v/7/4MA5ABcAdgBCAKEAtACkQJ2AkQCIgKjAp8C+AHHAV4B/ABJAVABeAGoAWQBgwF2AVABOQGxAI8AuwAAAW4BdQFuAVgBCAHcAIUAp//m/pX+gv71/oH/+/9UAI4AwAB9ADEA9f9i/9r+lv5p/mD+b/5+/nH+Vv5v/jT+/v0M/t395P0J/m7+3v4O/4X/3f/y/08ATQDb//T/3/+R/5n/Sf/8/gH/JP9N/yr/B/8k/1H/mv+P/yD/8/7s/ib/rv8RAFQAhQDAAPYA3wDHAMAAlgBmAGYAawD7/6n/df8i/1P/mP/e/1oAvQDqAOoA6QAjAWEBfwHlARQC/QHiAVMBzQCHAEgANwBOAIMAnwDKACcBMAHfAJYAeQBmAD8AOAATAOv/LQA0AOj//f/5/8j/7v/j/2f/Iv/2/sH+8f4f/zr/b/+0//j/+P/Z/8f/lv9O/xb/yv63/gL/bP+4/7//1f/d/5n/bP9Z/0r/c/+t/+P/GwBiAHQASwBqAGgAIAAiACsAHQAhAOn/qf+O/2j/Pf8O/w7/DP8j/5v/+f9XAKQAmQCXAIsATQAjAPz/8v///+v/4v+4/3z/f/+U/5H/o//b//z/OQB8AI0AsQCuAKYAyAC/AKcAnQCRAKwAuQCIAGoARQDX/6f/5f85AJ4A7AAHARwBPwEpAd4ApgCBAF8AYwBuAJUA7QD1AO4A7QDTAM4AgAD9/6D/hP+G/4//jP9O/yX/KP8u/1v/f/9r/2X/b/9x/73/4f/W//D/3v/9/yMAHgAHAOP/2v/O/+z/JgAhAAAABQDb/47/Zf8n/wL/Kf9I/2n/o//Y/8n/kP9e/wb/x/67/sn+/P5V/6D/xf/m//f/3v/I/6P/Pf8G//v++/40/27/xf8KAE4AhQBdAFAAKQD3//r/DwA2AFwAoADiABYBPgF0AZwBoAG6AYgBIAHkAM0A4AAHAQYB6ADsAPkA4wC7AHwARgBAAEgANAAPAMr/m/+Z/57/sf+v/73/2//U/9b/vv+c/5n/lP+w/9T/8P8uAHwAzAAVAUMBHQHgAI0ALgAWAPr/3P8AABUAOgBtAEsAPwAaAMP/mv+I/6D/pf+a/5j/hf+a/6P/bf8t//H+xP7R/iD/Tf9z/8j/4v/b/+L/tP+O/5v/ov+b/77/9v8nAHEAkgCAAGIAOAAMANP/sf+l/5D/rf/E/+P/EAARAA8A5P+i/4P/av9P/0//bv/A/xwARABjAHcAbABOADAAGwAJAP7/AAARADAARQBBAEkASQAvACQANQA8AEIAUgBdAH0ApwDRAPAACAEEAeEA2AC/AIAAUQAlABgAJwAWABEAEwAAAAIADAAeACgALAA4ACgAGADz/8f/q/93/1P/Qf9N/2b/av+B/6n/0//v//z/EwAhACAAIQAWABEAAADi/7//lP+Z/53/j/+P/27/WP9c/2X/ef+A/4D/lP+a/6n/vv/D/7n/m/+M/4P/dv9l/1v/bv+q//v/OQBtAIcAggCLAI0AZQBLAC8AJABSAGsAgQCIAGEAWABNACQACADu/9P/6f8UACwASABNAEIAPQAvABUA9v/1//b/7f8AABIAJAAyAEAAWABZAGEAVgAoABMAAQDr/9z/1f/Q/9D/0P+8/67/q/+n/6z/x//e//j/IwAwAEMAZABEABwAAQDW/8D/q/+b/6//wf/H/8T/xP/P/8f/vv/f//r/EAA/AF8AewCPAIUAeQBcAD8AHwD4/+r/4f/j//P/DwAgACMAUAB0AHoAgQB1AGkAaQBSADQAKwAjACsAPgBGAFQAcAB5AIQAgABaADoAJQAHAO//6v/o/+j/9f/+/wQABADq/+D/5//l//3/HgAxAEMATABBACcA/f/K/7f/qP+e/6H/nP+f/43/ev98/3//gv+B/43/n/+5/8z/3f/r/+j/8//y/+b/3f/F/8T/y/+6/8H/0v/X/+z//v8IAA8AAADy/93/v//D/7//w//m//b/BQAaAB4AIAAPAP7//////w0AFgAeADsAPQA6AEIANQAZAP//4//C/7H/sf+5/9j/6//z/w4AHgAkACUAFAAHAPv/+v8PABEAAwAHAAYADAAXABUAFgAlACwAMwA+AEEATABOAEEAMQAcABwAGQALABAAAQADABoAGwArADkALwAqABYACAAMAAgAEQAlADgARwBXAGIAbABtAGYAYQBYAE4APAA8ADQAHgAXAAkA+v/r/+T/8//4//X/8v/u//j/8v/v//X/8v/u/+z/4v/V/8r/yP/K/8P/zP/O/9D/5//1/wsAJgA0ADYAMgAZAPj/4v/L/7X/pv+h/6H/pP+l/6D/mP+H/4T/ev90/4T/jv+Y/5v/pv++/8b/0//S/8X/xf/Q/9z/2//Z/9L/3//t/97/1f/e/+H/6v/6//z//P8EAA8AIQA0AC4ANgBPAFUAXwBvAGkAbwB+AHIAYQBcAE4APQAuAB0AEAABAAUAFwAWABsAJAAsADgAMQAlACMAGQAVAA4ABQAIAAYAAwD9//v/+v/3//L/5P/e/+H/6v/6/xMAHAAgACoALwA9AEcAUgBdAGUAaABjAFUARAAwAB8ADAAAAAAA/f/1/+b/1v/H/7X/qf+m/6T/ov+y/8j/z//d/+b/5//y//j/CgAYAB4AJAAjABcAAQDp/9j/wv+1/7j/t//H/9j/6f/7/wYAJQA4AEMATwBSAFkAVwBOAEYARwBNAEIAQgBDADkAPwBHAEkASABJAEMAOgA0ACkAHAARAP7/7//x/+f/2//W/9P/0f/M/8z/x//E/8H/wf/K/8b/yv/U/87/2v/n/+L/3f/h/9v/2P/Y/8j/wP+6/7T/s/+z/7D/t//E/8T/y//R/9n/4v/r////CQAXACQAJQAhAB0ADwD8/+3/5P/l//H//P8GABoAKAA0AEAAQgBCAEIAQAA2ADEALwAnACgAIwAkACYAHgAfABwAFQAWABMADwAOAAMA+//1/+7/4P/O/8D/uv+z/63/rP+o/6//s/+u/7L/tv+8/8T/xf/G/8//4//q/+z/+f8AAAoAIQAvADEAPQBFAEwAVgBYAFYAUgBQAEUAQwA8ADYAPQA2AC8AJQAcABMABAD2/+//8P/v//r/AAAIABQAIQAsAC0ANAA1ADwANwArAC4AIgAWABUACgAAAP3//P/8//X/9v/5//f/7//q//D/+P8AAAgACgARABUADwAOAAUA+v8AAP///v8IABAAHQAmACsALgArACIAEwAJAPP/2//X/83/xP/F/7//yP/P/8r/yP/G/8H/wv/G/8T/zf/X/+P/6v/x//j/8//1//T/8f/t/+z/8f/7/wMACQAZACEAIAAiACcAIAAZABgAGwAcABYAFwATAAsACQAKABAADwALABQAGQAUABQABgD4//P/7P/m/+P/4f/c/+L/6//t//b/+v/2//X////3//D///////v/BAAGAAQACAD/////AgD1//H/7//t//H/6P/o/+z/6v/p//H//v/5//n/AwAEAAUADwARABIAFgAbACIAHAAiACUAHQAeABwAHAAZABMAEwAKAAEAAwAGAAwADgATABgACQAJAAEA8v/y/+f/4f/l/+T/4//o/+L/4P/l/93/3P/Z/9P/0v/W/9r/4P/s//v/DQAeACcALgAzADcALQArACwAJAAmACoAKQAkAB8AHQAYABAACwAIAAMACAALAA4AGAAcABsAGgAYABUACAAAAPv/7P/n/+b/4P/e/93/0P/K/8r/uf+2/7j/uP/J/9b/4v/w//v///8DAP7/9f/0/+z/6P/o/+f/6//t//X//f8FAAsAEgAfACQAJAApAC0ANAAwACwAKQAeABUADAADAPz/+v/6//3/+//5//j/+v/4/+//7P/r/+r/8P/z/+//+f/7//f/AAD3/+//7f/q/+X/4//o/+b/6v/v/+X/7//z/+3/9P/y//P/+v/6//7/BQAFAAQABwAFAAAAAQAAAP//+//+/wcABwATABwAHQApADAAMQA8AD8AOgBDAEMAQgBJAEAANQA2AC0AHAATABEAAgD6//v//v8CAAAABQANAA0ADwANAAkABAD9//n/9P/r/+D/1//V/8f/wP+4/67/sv+t/7D/u/+9/8n/0//e/+z/8v/4//v/AAACAAcAEQAUABcAGwAbABwAGwAaABwAHwAjACUAJgApACsAKgAqACgALAAwACoALAAwACUAJwAhABUAFAALAAEA/v/1/+f/3//V/8v/zv/L/8z/2f/h/+3/9P/9/wYABQACAAIAAQABAAAA/P/7//b/9P/5//L/8f/q/+f/6v/i/+H/5P/g/+H/4P/g/+b/5v/p/+7/8//2//v/AAADAAMA/v/8//H/5v/m/93/3//i/9v/3v/p/+7/8//5/wAACgAPABEAGQAaABIAEAASAA8ACwAIAAwADwAPABUAIAAqAC0ALQAyADEALgAtACgAKwAnACUAKAAlACAAHAAbABUAEgANAA4AEgAQABcAGQAcACMAHQAaAB8AGgAXABcAFgAWABcAEwAVABMADQALAAgABAD///f/8v/z//L/7f/r/+3/6f/k/+X/3v/Y/9D/yP/B/7r/t/+z/7P/tf+3/7r/wP/I/8z/0//b/+L/6P/r//D/+f/9//r//f/8//7/AAD//wEABQAJAAwAEAAUABMAFgAZABkAFwAYABsAHgAiACEAIgAnACoAKQAoACMAJgAfABQAFgANAAYAAwD///7////+//r//f/7//f//P/6//z//v8BAAYABQAEAAwACgALABAACwAMAAgABwAJAAUACwANAA0AEgATABIAFAATABIAFAAXABUAFgAUABAADAAIAAUAAQD//wAA/P/4//r/+P/4//n//v8CAAYACwARABQAFgAYABcAFwAXABUAEgAOAA0ADAAHAAYAAwAAAP7/9v/t/+X/3P/U/9H/0P/S/9f/2v/j/+n/6f/p/+v/6//p/+v/7f/v//H/8//z//L/8f/y//L/7v/r/+7/7P/p/+r/5v/n/+f/5P/j/+T/4//i/+T/5//s//b//v8AAAYADwARABMAEwASABEAFQAXABgAGQAYABkAGQAUAA8ACgAHAAIAAgAFAAcACAAIAA0ADwAQABEAEgAXABcAGAAZABkAGQAbABwAGwAaABgAFAARAA8ADQANAA4ADwAUABUAFwAaABcAFAATABEADQAOAAwADAALAAcABwAHAAQA//8AAAUABAAHAAgABgADAAIAAAD9//z/+//4//f/9v/y/+z/6//p/+b/5v/p/+b/5f/k/+D/3P/a/9r/2v/c/97/4v/j/+j/7v/x//P/+v8AAAAABgAIAAoACQAJAAsACgAKAAsADQAOAAsADAAMAAoABwAEAAUABwAFAAoADAANAA0AEQASABAAFAASABMAFQAUABIADgAHAAMAAAD7//n/+P/4//f/+P/5//f/+//8//r/+//4//b/9f/z/+//7v/t/+3/7//x//P/9v/2//b/9f/y//H/8f/y/+7/8P/y//H/9P/1//P/9//4//r//f///wAAAQACAAMABQAGAAUABAAGAAQAAwAEAAQABAAIAAgACQAJAAoACwAKAAgACQALAAcABAAGAAYABQAEAAQABAAFAAQAAAAAAAAA/////////f/9//3//f////7///8BAAQABQAHAAoACwAKAAwACgAIAAkACgAKAAoADAAPAA8AEgATABQAFAAWABgAFQAVABUAFAATABIAFQAXABUAFAAVABQAEwASAA8ADAALAAcABAABAPz/+v/6//b/8f/y/+//7v/u/+v/7P/q/+3/7//x//P/8P/w//D/7//v/+7/8P/y//P/9v/2//f//f/9//3/AAABAAIAAgAEAAMAAwABAAEABAACAAEABQACAAIABQABAAIAAAAAAAAA//8AAP7//P/7//v/+f/6//r//P/+//3//P/8//z/+///////AQAEAAQACAAIAAcACAAHAAgACAAHAAUABgAEAAMAAwABAAAAAAABAAIAAQAEAAQABgAGAAcABwAHAAcACQAJAAkADAAJAAoACgAIAAkACAAGAAcABwAGAAcABwAJAAkACAAHAAUAAwAEAAEAAAD+//7/AAAAAAEAAQADAAIAAQACAAEAAAAAAAAAAAD+/wAAAQAAAAIAAQAAAAAAAAD///3/+//3//f/9//2//b/9P/y//L/7v/u/+//7//u/+//7//w//P/8f/x//T/8//0//b/9v/5//n//f/9//z//f/+////AAD//wAA///+//z/+v/8//r/+v/7//n/+v/7//3//f/7//z//P/7//z/+//8//3//f/7//z//P/+/wAA//8AAAAAAQACAAIABAAEAAUABwAFAAcACQAHAAcABgAGAAkACgAKAAwADQALAAwADAALAAwACgAIAAcACAAGAAUABAABAAAAAAD///3//f/7//n/+f/3//b/9v/1//X/9f/4//j/+v/8//3///8BAAMABAAHAAkACgALAAsADQAMAAsACQAJAAkACgAKAAkACAAGAAcABwAHAAQABAAGAAUABQAEAAMAAwADAAIAAwAEAAQABAAFAAUABQAGAAcABQAHAAkABQADAAIAAgADAAEAAQABAAAAAAABAAAAAAD+//7//f/8//3//f/+//////8AAAIAAwAEAAYABwAFAAUABQAFAAYABwAGAAkACQAKAAsADQAKAAgACgAKAAoACQAJAAkACQALAAsACgALAAsACgALAAkACgAKAAgACAAJAAgACQAKAAsACwAMAAsACwALAAwACwALAAsADAALAA0ADQAOAA4ADgAOAA0ACgAIAAcAAwACAAIAAgACAAEAAAD///7//P/7//r/+P/4//j/9//2//b/9f/1//T/8//0//X/9f/1//f/9//4//j/9//4//j/9v/2//X/9//2//X/9v/y//P/8f/x//P/7//u/+7/7v/s/+r/6v/o/+j/5//l/+j/6P/p/+r/6P/q/+v/6//q/+v/7P/s/+3/7v/w//L/8f/y//P/8f/y//P/8v/y//L/8v/0//X/+P/5//r//f/+////AAACAAMABQAGAAcACgAMAAwADQAOAA4ADAANAA0ADAAOAA4ADgARAA8ADwANAA0ADQALAAsACQAKAAsACwAMAA0ADAANAA0ADAAMAA0ADgAPAA8ADwARABEAEwAUABIAEAAOAA0ADQALAA0ADQAOABEAEwASABMAFAATABMAFAAUABUAFAAVABcAFwAWABUAEgAQAA8ACwAJAAcABgADAAIAAQAAAP///f/6//j/8//x/+z/6v/r/+j/6P/n/+b/5f/k/+L/3f/c/9r/2f/Z/9r/2P/a/9z/3P/e/97/3//h/+H/4v/j/+T/5//r/+z/7v/z//b/+P/4//z//f/+//////8CAAQABwAKAA0ADwAPABEAEQAVABMAEAARABEAEQAQAA4ADwAPABAADwAQAA8ADgAKAAoABgAEAAQAAwADAAMAAwAEAAIAAwADAAEAAQAAAP///v/9//3//P/9//v/+v/6//f/9v/0//D/7//t/+r/6f/q/+j/5//o/+r/6P/p/+n/6f/q/+3/7//x//X/9v/4//r/+//7//v/+v/8//r/+//8//3//v/+//7//f8AAP3/+//7//r/+P/4//j/+P/4//v/+v/8//////8AAAEAAQAAAAIABgAHAAgADQAMAA4AEQAPABEAFQATABQAFwAXABkAGwAcAB0AHQAcABoAGQAYABcAFwAaABsAHQAfAB8AIgAlACcAKAAnACkAKAAoACcAJgAnACYAJgAjACEAHgAaABUAFAAQAA0AEAANAA4AEAAMAAsACgAJAAcABwAGAAYABgAEAAMAAAD9//r/9v/0//D/7v/t/+r/6f/q/+j/6P/l/+L/4v/f/93/2f/X/9f/1f/Y/9j/1//Z/9r/2P/T/9L/0P/O/8v/z//S/9T/1//a/9r/3P/c/97/3f/a/9r/2//X/9f/2P/Z/97/3v/c/9z/3P/Y/9b/1f/S/9H/1P/W/9b/2f/d/97/4P/h/+H/5P/m/+j/8P/0//r/BQAMABUAHgAmACoALwA3ADcAOgA8AEEARABEAEcASgBIAEkARwBJAEgARQBDAEEAQgBAAEAAQQBAAD8APwA/AD4APAA5ADoAOgA6ADoAOwA9AD4AQwBFAEUARQBDAEAAPwA9ADgAOQA4ADMAMgAyAC8ALwAtACkAKQAmACQAIwAiACEAJAAkACQAIwAhAB8AGQAWABQAEAAOAA4ADgATABQAGAAXABUAFQAUABIAEAAMAAsACQAIAAkACAAHAAcABQACAAAA/f/7//n/8//u/+3/5//m/+j/5P/g/9z/1v/O/8b/wf+6/7X/r/+r/6v/qP+l/6L/oP+d/5z/m/+Y/5j/mf+d/53/oP+l/6X/qP+n/6f/p/+l/6b/o/+l/6T/o/+m/6n/p/+l/6n/qf+s/7D/s/+1/7j/vP/F/8z/zv/Z/+H/5f/s//X//f/+/wEABQAFAAgABgAHAAkACgAJAAkACQAKAAsADQAPABEAEwATABQAGQAbABsAHQAdACAAIwAlACgAKwAuAC8AMgA1ADgAPQBBAEMARQBIAEkASQBLAEsASgBMAFAATgBQAFIAUABUAFUAVQBWAFYAVwBWAFUAVABVAFUAVgBaAFwAWQBaAFsAWABVAFAATQBGAEAAPAA5ADUALwAoACYAHwAXABEACwAAAPf/8v/q/+P/4f/i/+P/5P/n/+z/6v/s/+z/6//r/+j/6P/s/+3/7f/v/+7/7P/n/+H/3P/W/87/yP/E/8D/vP+8/7n/tf+0/63/p/+k/57/mf+W/5X/lP+X/57/o/+r/7P/t/+9/8P/w//K/9D/1P/b/9//4//o/+z/7//x//T/9f/2//n/+f/9/wAAAwAHAA0ADAAMAAsACQAGAP///P/7//n//P///wEABwANAA8ADwAPAA4ACwALAAcAAwAFAAUABQAGAAUACQAJAAoACgAMAA8AEQAWABoAHAAgACIAIgAiACAAGgAWABMACwAHAAUABAACAAMABgAGAAkACwANAA0ADAAOAA4ADwASABIADwASABAADgAPAA0ADgAMAA0ADwAOABIAEwARABMAEAAJAAcABgAAAP7//f/9//v//v/8//r/+P/0//X/9v/0//b/+////wIABgAIAAoACgAKAAwADAALAAoACwAKAAYABQD+//f/8f/p/+T/3P/U/9P/zv/L/87/zv/R/9P/0v/R/9H/1P/V/9T/1//c/+T/7P/y//v/AAAAAAAAAwAFAAMAAwADAAIAAwABAAIAAgABAAUABwAGAAgADwARABUAHgAkAC4ANQA8AEMARgBJAEYAQwA+ADcAMQAsACYAHQAXABEADQAIAAIAAAD5//T/9P/v/+3/6v/n/+X/4v/k/+f/6v/t//D/9f/5////AgADAAQACQAJAAoACgALAAwACgAHAAYABgAGAAQABgAHAAcACwAOAA8AEgAQABAACwAGAAAA/f/5//P/8v/z//P/9//7/wAABgAIAAoACgALAAkADAAPAAoADQAOAA8AEQAOAA0ACQAJAAUAAgABAAAABQAHAAkADQALAAgAAgD8/+7/4P/W/83/wf+3/7T/rv+o/6X/ov+f/5v/l/+S/5H/kP+P/4//kf+T/5T/mf+f/6b/rP+0/73/x//U/97/6v/v//T/+f/6//n/9//2//X/8f/v//L/9v/9/wQADgAXAB8AKAAvADMAOAA9AEEASQBQAFAAVQBcAF0AXwBhAFwAWwBZAFIATABGAEEAOQAxACoAHwAVAAgA/v/3/+//6f/o/+r/6//u//L/9v/6/wAABQAIAAwAEwAWABkAIAAhACEAJAAiACIAIgAjACUAKAAuADAANAA5AD4AQQBCAEMAQgBCAEAAPwA/AEEAQQBEAEcASABGAEQAQAA5ADMAKAAdABkADAADAP3/8v/o/+b/5P/h/+X/6v/w//j//f8BAAYABwAGAAcABwAFAAAA/f/8//r/9v/2//T/8//w//H/8P/q/+X/3f/a/9T/zv/I/8T/v/+3/7f/sv+s/6z/pf+l/6P/oP+h/6H/of+l/6j/sP+2/7f/u/++/7//wf/B/8D/wv+//8H/x//I/8r/zv/M/9H/0f/S/9j/2f/e/+b/7f/z//3/AgAKABIAGAAaACAAIgAhACIAHgAcABQADAAFAP7/9f/w/+3/6f/n/+n/8P/x//b//v8CAAoAEgAbACQAKwAwADkAQABEAEgATABQAE8ATQBHAEIAOwA0ACoAIgAbABUAEAAOAA0ADwAUABUAGAAgACUAJwAsADAAMgAxADQANwA6ADsAOQA4ADQAMAArACMAGwAUAAwACQAIAAUACQAMAA0AEAAQABIAEwATABQAGAAaABoAHgAgAB0AGgAUAA0ABQD9//P/6//m/+D/4f/j/9//4v/h/9z/2v/U/8//zf/N/9L/1//c/+H/5f/r/+3/7v/v/+3/6v/q/+z/7P/v//X//P///wMABQAEAAIA/f/0/+r/4v/a/9b/0//S/9T/1v/Y/9//4//p//H/9//+/wUACgARAB0AJAApAC8ANAA4ADgANwA0AC8AKQAlACEAHAAZABkAFgATABIAEAANAAcACAAGAAEAAgACAAEABQAFAAUABQAEAP7/9v/v/+T/2v/V/9H/zP/K/8j/xv/F/8T/w//C/8T/y//V/+D/8P8AAAwAGgAiACUAJQAhABwAFgAPAAkABQABAP///P/7//j/8f/t/+f/3//b/9j/2v/c/+D/5P/r//P/9/8AAAMABAAKAA8AEgAUABgAGwAdAB4AIAAXABMADQAAAPn/7v/m/+D/2v/Y/9j/3P/d/93/4v/h/+D/5P/n/+n/7P/u//L/+P/+//3//v/9//f/9P/t/+b/4f/d/9//4v/h/+z/9f/9/wcADQAUABkAGwAiACMAJgAoAC4ANQA7AEAARwBNAFIAWgBcAF4AYgBlAGIAYQBfAFwAWABQAEsARAA8ADMALwApACIAGwAYABQAEAANAAcAAgACAAMAAAD///z/+//6//r/+P/1//X/9f/3//f/9v/6//z/AAD/////AAD+/////f/6//j/9v/2//X/8//z//D/7f/u/+3/7v/x//P/+f/8/////f/5//L/6f/f/9P/xP+7/7j/tf8=\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with stretching\n",
    "utils.display_audio(\"data/sample/preprocessed_and_augmented/train/down/a1cff772_nohash_2_stretch.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cleanup\n",
    "# rm -r $path_to_sample_preprocessed_and_augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can preprocess the .wav files into a tempogram and then run the same model on it (with an increased number of training samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/sample/preprocessed_and_augmented/train/yes/d5356b9a_nohash_0_stretch.wav',\n",
       " 'data/sample/preprocessed_and_augmented/train/yes/d3f22f0e_nohash_0_shift.wav',\n",
       " 'data/sample/preprocessed_and_augmented/train/yes/0f3f64d5_nohash_0.wav',\n",
       " 'data/sample/preprocessed_and_augmented/train/yes/66a412a7_nohash_0_shift.wav',\n",
       " 'data/sample/preprocessed_and_augmented/train/yes/8a28231e_nohash_3.wav',\n",
       " 'data/sample/preprocessed_and_augmented/train/yes/6c9223bd_nohash_0_stretch.wav',\n",
       " 'data/sample/preprocessed_and_augmented/train/yes/8a28231e_nohash_3_shift.wav',\n",
       " 'data/sample/preprocessed_and_augmented/train/yes/61d3e51e_nohash_0_stretch.wav',\n",
       " 'data/sample/preprocessed_and_augmented/train/yes/712e4d58_nohash_2_stretch.wav',\n",
       " 'data/sample/preprocessed_and_augmented/train/yes/d3f22f0e_nohash_0.wav']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we need a new list of all our preprocessed & augmented train files\n",
    "path_to_augmented_train = os.path.join(path_to_sample_preprocessed_and_augmented, \"train\")\n",
    "augmented_sample_train_wavs = []\n",
    "\n",
    "for category in categories_to_predict:\n",
    "    path_to_category = os.path.join(path_to_augmented_train, category)\n",
    "    category_files = utils.grab_wavs(path_to_category)\n",
    "    \n",
    "    # we use extend instead of append to add all elements from the iterable\n",
    "    augmented_sample_train_wavs.extend(category_files)\n",
    "    \n",
    "augmented_sample_train_wavs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/sample/preprocessed_and_augmented/cv/yes/5fadb538_nohash_2_stretch.wav',\n",
       " 'data/sample/preprocessed_and_augmented/cv/yes/5fadb538_nohash_2_shift.wav',\n",
       " 'data/sample/preprocessed_and_augmented/cv/yes/90804775_nohash_0_stretch.wav',\n",
       " 'data/sample/preprocessed_and_augmented/cv/yes/dc2222d7_nohash_1_shift.wav',\n",
       " 'data/sample/preprocessed_and_augmented/cv/yes/dc2222d7_nohash_1_stretch.wav',\n",
       " 'data/sample/preprocessed_and_augmented/cv/yes/e8e960fd_nohash_0.wav',\n",
       " 'data/sample/preprocessed_and_augmented/cv/yes/90804775_nohash_0_whitenoise.wav',\n",
       " 'data/sample/preprocessed_and_augmented/cv/yes/5fadb538_nohash_2.wav',\n",
       " 'data/sample/preprocessed_and_augmented/cv/yes/e8e960fd_nohash_0_stretch.wav',\n",
       " 'data/sample/preprocessed_and_augmented/cv/yes/099d52ad_nohash_1_whitenoise.wav']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeat for cv\n",
    "# first we need a new list of all our preprocessed & augmented train files\n",
    "path_to_augmented_cv = os.path.join(path_to_sample_preprocessed_and_augmented, \"cv\")\n",
    "augmented_sample_cv_wavs = []\n",
    "\n",
    "for category in categories_to_predict:\n",
    "    path_to_category = os.path.join(path_to_augmented_cv, category)\n",
    "    category_files = utils.grab_wavs(path_to_category)\n",
    "    \n",
    "    # we use extend instead of append to add all elements from the iterable\n",
    "    augmented_sample_cv_wavs.extend(category_files)\n",
    "    \n",
    "augmented_sample_cv_wavs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we expect 4 x 240 files for the train set\n",
    "len(augmented_sample_train_wavs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (960, 384, 32)\n",
      "CV shape:  (240, 384, 32)\n"
     ]
    }
   ],
   "source": [
    "# preprocess into a tempogram\n",
    "augmented_train_X_tempogram = utils.get_X_tempogram(augmented_sample_train_wavs)\n",
    "print(\"Train shape: \", augmented_train_X_tempogram.shape)\n",
    "\n",
    "augmented_cv_X_tempogram = utils.get_X_tempogram(augmented_sample_cv_wavs)\n",
    "print(\"CV shape: \", augmented_cv_X_tempogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (960, 384, 32, 1)\n",
      "CV:  (240, 384, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# extend dimensions for 2D convolutions (may take a couple of minutes)\n",
    "augmented_train_X_tempogram_2 = np.expand_dims(augmented_train_X_tempogram, axis=3)\n",
    "augmented_cv_X_tempogram_2 = np.expand_dims(augmented_cv_X_tempogram, axis=3)\n",
    "\n",
    "print(\"Train: \", augmented_train_X_tempogram_2.shape)\n",
    "print(\"CV: \", augmented_cv_X_tempogram_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target dimensions: (960, 12)\n",
      "Received shape: (960, 12)\n"
     ]
    }
   ],
   "source": [
    "# since we've increased the number of .wav files, our y has also changed shape\n",
    "rows = len(augmented_sample_train_wavs)\n",
    "columns = len(categories_to_predict)\n",
    "dimensions = (rows, columns)\n",
    "print(\"Target dimensions: {}\".format(dimensions))\n",
    "\n",
    "# get the y (notice that the character offset changes due to the name of the folder)\n",
    "augmented_train_y = utils.get_y(augmented_sample_train_wavs, 45, categories_to_predict)\n",
    "print(\"Received shape: {}\".format(augmented_train_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target dimensions: (240, 12)\n",
      "Received shape: (240, 12)\n"
     ]
    }
   ],
   "source": [
    "# repeat for cv\n",
    "# since we've increased the number of .wav files, our y has also changed shape\n",
    "rows = len(augmented_sample_cv_wavs)\n",
    "columns = len(categories_to_predict)\n",
    "dimensions = (rows, columns)\n",
    "print(\"Target dimensions: {}\".format(dimensions))\n",
    "\n",
    "# get the y (notice that the character offset changes due to the name of the folder)\n",
    "augmented_cv_y = utils.get_y(augmented_sample_cv_wavs, 42, categories_to_predict)\n",
    "print(\"Received shape: {}\".format(augmented_cv_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persist the obtained matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist\n",
    "bcolz_save(path_to_sample_preprocessed_and_augmented + os.path.sep + \"augmented_train_tempogram_X\" + \".bc\", augmented_train_X_tempogram_2)\n",
    "bcolz_save(path_to_sample_preprocessed_and_augmented + os.path.sep + \"augmented_train_y\" + \".bc\", augmented_train_y)\n",
    "\n",
    "bcolz_save(path_to_sample_preprocessed_and_augmented + os.path.sep + \"augmented_cv_tempogram_X\" + \".bc\", augmented_cv_X_tempogram_2)\n",
    "bcolz_save(path_to_sample_preprocessed_and_augmented + os.path.sep + \"augmented_cv_y\" + \".bc\", augmented_cv_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload\n",
    "augmented_train_X_tempogram_2 = bcolz_load(path_to_sample_preprocessed_and_augmented + os.path.sep + \"augmented_train_tempogram_X\" + \".bc\")\n",
    "augmented_cv_X_tempogram_2 = bcolz_load(path_to_sample_preprocessed_and_augmented + os.path.sep + \"augmented_cv_tempogram_X\" + \".bc\")\n",
    "\n",
    "augmented_train_y = bcolz_load(path_to_sample_preprocessed_and_augmented + os.path.sep + \"augmented_train_y\" + \".bc\")\n",
    "augmented_cv_y = bcolz_load(path_to_sample_preprocessed_and_augmented + os.path.sep + \"augmented_cv_y\" + \".bc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreate the model and train (20 epochs may take a couple hours on a machine with a single GPU). I'm including the code for training for fewer epochs, saving model weights and reloading the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn6 = Sequential([\n",
    "        Conv2D(input_shape=(augmented_train_X_tempogram_2.shape[1], augmented_train_X_tempogram_2.shape[2], 1), \n",
    "                      kernel_size=32, filters=128, padding=\"same\", activation=\"relu\"),\n",
    "        Dropout(0.11),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(kernel_size=12, filters=128, padding=\"same\", activation=\"relu\"),\n",
    "        Dropout(0.13),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(2000, activation=\"relu\"),\n",
    "        Dropout(.7),\n",
    "        Dense(num_categories, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "cnn6.compile(Adam(lr=0.0001),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 960 samples, validate on 240 samples\n",
      "Epoch 1/5\n",
      "960/960 [==============================] - 780s - loss: 2.4507 - acc: 0.0969 - val_loss: 2.4326 - val_acc: 0.1583\n",
      "Epoch 2/5\n",
      "960/960 [==============================] - 627s - loss: 2.4053 - acc: 0.1437 - val_loss: 2.3399 - val_acc: 0.1750\n",
      "Epoch 3/5\n",
      "960/960 [==============================] - 586s - loss: 2.3707 - acc: 0.1562 - val_loss: 2.3790 - val_acc: 0.1750\n",
      "Epoch 4/5\n",
      "960/960 [==============================] - 568s - loss: 2.3512 - acc: 0.1677 - val_loss: 2.3198 - val_acc: 0.1875\n",
      "Epoch 5/5\n",
      "960/960 [==============================] - 569s - loss: 2.2780 - acc: 0.2031 - val_loss: 2.2378 - val_acc: 0.1833\n"
     ]
    }
   ],
   "source": [
    "cnn6_results = cnn6.fit(augmented_train_X_tempogram_2, augmented_train_y, batch_size=64, \n",
    "                        epochs=5, validation_data=(augmented_cv_X_tempogram_2, augmented_cv_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory for storing model weights\n",
    "!mkdir $path_to_sample/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store path to weights\n",
    "path_to_weights = os.path.join(path_to_sample, \"models\", \"cnn6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model weights\n",
    "cnn6.save_weights(path_to_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 960 samples, validate on 240 samples\n",
      "Epoch 1/5\n",
      "960/960 [==============================] - 573s - loss: 2.2401 - acc: 0.2208 - val_loss: 2.2404 - val_acc: 0.2375\n",
      "Epoch 2/5\n",
      "960/960 [==============================] - 565s - loss: 2.1814 - acc: 0.2271 - val_loss: 2.1267 - val_acc: 0.2625\n",
      "Epoch 3/5\n",
      "960/960 [==============================] - 580s - loss: 2.1390 - acc: 0.2469 - val_loss: 2.1015 - val_acc: 0.2792\n",
      "Epoch 4/5\n",
      "960/960 [==============================] - 588s - loss: 2.0946 - acc: 0.2698 - val_loss: 2.1019 - val_acc: 0.2750\n",
      "Epoch 5/5\n",
      "960/960 [==============================] - 563s - loss: 2.0532 - acc: 0.2698 - val_loss: 2.0792 - val_acc: 0.2833\n"
     ]
    }
   ],
   "source": [
    "# 5 more epochs & save weights again\n",
    "cnn6_results = cnn6.fit(augmented_train_X_tempogram_2, augmented_train_y, batch_size=64, \n",
    "                        epochs=5, validation_data=(augmented_cv_X_tempogram_2, augmented_cv_y))\n",
    "cnn6.save_weights(path_to_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 960 samples, validate on 240 samples\n",
      "Epoch 1/5\n",
      "960/960 [==============================] - 677s - loss: 2.0442 - acc: 0.2833 - val_loss: 2.0479 - val_acc: 0.2958\n",
      "Epoch 2/5\n",
      "960/960 [==============================] - 701s - loss: 1.9625 - acc: 0.3281 - val_loss: 2.0089 - val_acc: 0.3208\n",
      "Epoch 3/5\n",
      "960/960 [==============================] - 721s - loss: 1.9416 - acc: 0.3094 - val_loss: 2.0519 - val_acc: 0.3208\n",
      "Epoch 4/5\n",
      "960/960 [==============================] - 712s - loss: 1.9399 - acc: 0.3073 - val_loss: 2.0248 - val_acc: 0.3083\n",
      "Epoch 5/5\n",
      "960/960 [==============================] - 678s - loss: 1.8895 - acc: 0.3302 - val_loss: 2.0065 - val_acc: 0.3042\n"
     ]
    }
   ],
   "source": [
    "# 5 more epochs & save weights again\n",
    "cnn6_results = cnn6.fit(augmented_train_X_tempogram_2, augmented_train_y, batch_size=64, \n",
    "                        epochs=5, validation_data=(augmented_cv_X_tempogram_2, augmented_cv_y))\n",
    "cnn6.save_weights(path_to_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 960 samples, validate on 240 samples\n",
      "Epoch 1/5\n",
      "960/960 [==============================] - 671s - loss: 1.8432 - acc: 0.3542 - val_loss: 2.0178 - val_acc: 0.3125\n",
      "Epoch 2/5\n",
      "960/960 [==============================] - 637s - loss: 1.8191 - acc: 0.3542 - val_loss: 2.0394 - val_acc: 0.3083\n",
      "Epoch 3/5\n",
      "960/960 [==============================] - 607s - loss: 1.8099 - acc: 0.3469 - val_loss: 2.0200 - val_acc: 0.3083\n",
      "Epoch 4/5\n",
      "960/960 [==============================] - 605s - loss: 1.7687 - acc: 0.3615 - val_loss: 2.0439 - val_acc: 0.3292\n",
      "Epoch 5/5\n",
      "960/960 [==============================] - 602s - loss: 1.7536 - acc: 0.3625 - val_loss: 2.0583 - val_acc: 0.3042\n"
     ]
    }
   ],
   "source": [
    "# 5 more epochs & save weights again\n",
    "cnn6_results = cnn6.fit(augmented_train_X_tempogram_2, augmented_train_y, batch_size=64, \n",
    "                        epochs=5, validation_data=(augmented_cv_X_tempogram_2, augmented_cv_y))\n",
    "cnn6.save_weights(path_to_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our model is starting to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 960 samples, validate on 240 samples\n",
      "Epoch 1/5\n",
      "960/960 [==============================] - 639s - loss: 1.7057 - acc: 0.3969 - val_loss: 2.0529 - val_acc: 0.3458\n",
      "Epoch 2/5\n",
      "960/960 [==============================] - 724s - loss: 1.6907 - acc: 0.4010 - val_loss: 2.0136 - val_acc: 0.3333\n",
      "Epoch 3/5\n",
      "960/960 [==============================] - 701s - loss: 1.6661 - acc: 0.3969 - val_loss: 2.1088 - val_acc: 0.3083\n",
      "Epoch 4/5\n",
      "960/960 [==============================] - 673s - loss: 1.6570 - acc: 0.4125 - val_loss: 2.0728 - val_acc: 0.3125\n",
      "Epoch 5/5\n",
      "960/960 [==============================] - 692s - loss: 1.5766 - acc: 0.4542 - val_loss: 2.0852 - val_acc: 0.3208\n"
     ]
    }
   ],
   "source": [
    "# 5 more epochs & save weights again\n",
    "cnn6_results = cnn6.fit(augmented_train_X_tempogram_2, augmented_train_y, batch_size=64, \n",
    "                        epochs=5, validation_data=(augmented_cv_X_tempogram_2, augmented_cv_y))\n",
    "cnn6.save_weights(path_to_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our model with data augmentation does not reach the same accuracy as a pure tempogram model. There are many potential reasons: the shifting might be segmenting utterances so that they become unrecogizable, the white-noise addition may be too generic, pushing the model in the direction of overfitting to that feature. Since the benefits of these 3 types of augmentation are not clear, we could consider the direciton of creating custom keras generators and experimenting with preprocessing there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weights\n",
    "# cnn6.load_weights(path_to_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community Solutions\n",
    "One of the best aspects of Kaggle challenges is the ability to cooperate and discuss your ideas with other participants. In general I believe seeking feedback from other ML Engineers and Data Scientists is very often hugely helpful. Additionally, discussions with other experts can be some of the most constructive experiences of our problem-solving adventures.\n",
    "\n",
    "There's one particularly interesting approach to this challenge that gained popularity while it was still ongoing - promoted by, among others, 은주니 and Sukjae Cho. I'd like to showcase it here because of its unorthodox character.\n",
    "\n",
    "The idea is to skip all preprocessing and use 1D convolutions on the raw 16000-dimensional .wav data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 16000, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to expand the dimensions for 1D convolutions\n",
    "commmunity_train_X = np.expand_dims(train_X, axis=2)\n",
    "commmunity_train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 16000, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same for CV\n",
    "community_cv_X = np.expand_dims(cv_X, axis=2)\n",
    "community_cv_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional model\n",
    "\n",
    "# input layer & batch normalization\n",
    "inputs = Input(shape = (16000,1))\n",
    "x_1d = BatchNormalization(name = 'batchnormal_1d_in')(inputs)\n",
    "\n",
    "# iteratively create 9 blocks of 2 convolutional layers with batchnorm and max-pooling\n",
    "for i in range(9):\n",
    "    \n",
    "    name = 'step'+str(i)\n",
    "    \n",
    "    # first 1D convolutional block\n",
    "    x_1d = Conv1D(8*(2 ** i), (3),padding = 'same', name = 'conv'+name+'_1')(x_1d)\n",
    "    x_1d = BatchNormalization(name = 'batch'+name+'_1')(x_1d)\n",
    "    x_1d = Activation('relu')(x_1d)\n",
    "    \n",
    "    # second 1D convolutional block\n",
    "    x_1d = Conv1D(8*(2 ** i), (3),padding = 'same', name = 'conv'+name+'_2')(x_1d)\n",
    "    x_1d = BatchNormalization(name = 'batch'+name+'_2')(x_1d)\n",
    "    x_1d = Activation('relu')(x_1d)\n",
    "    \n",
    "    # max pooling\n",
    "    x_1d = MaxPooling1D((2), padding='same')(x_1d)\n",
    "\n",
    "# final convolution and dense layer\n",
    "x_1d = Conv1D(1024, (1),name='last1024')(x_1d)\n",
    "x_1d = GlobalMaxPool1D()(x_1d)\n",
    "x_1d = Dense(1024, activation = 'relu', name= 'dense1024_onlygmax')(x_1d)\n",
    "x_1d = Dropout(0.2)(x_1d)\n",
    "\n",
    "# soft-maxed prediction layer\n",
    "predictions = Dense(num_categories, activation = 'softmax',name='cls_1d')(x_1d)\n",
    "\n",
    "\n",
    "community_model = Model(inputs=inputs, outputs=predictions)\n",
    "community_model.compile(Adam(lr=0.0001),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/5\n",
      "240/240 [==============================] - 48s - loss: 3.8549 - acc: 0.0792 - val_loss: 2.4850 - val_acc: 0.0833\n",
      "Epoch 2/5\n",
      "240/240 [==============================] - 46s - loss: 3.3894 - acc: 0.1208 - val_loss: 2.4854 - val_acc: 0.0833\n",
      "Epoch 3/5\n",
      "240/240 [==============================] - 47s - loss: 2.8088 - acc: 0.1917 - val_loss: 2.4862 - val_acc: 0.0833\n",
      "Epoch 4/5\n",
      "240/240 [==============================] - 46s - loss: 2.3386 - acc: 0.2833 - val_loss: 2.4876 - val_acc: 0.0833\n",
      "Epoch 5/5\n",
      "240/240 [==============================] - 46s - loss: 2.0296 - acc: 0.3417 - val_loss: 2.4909 - val_acc: 0.0833\n"
     ]
    }
   ],
   "source": [
    "community_model_results= community_model.fit(commmunity_train_X, train_y, batch_size=64, \n",
    "                        epochs=5, validation_data=(community_cv_X, cv_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model quickly overfits our tiny sample set without reaching a good validation accuracy. This can be due to the fact that the regularization was tuned to a much larger training set. We can experiment by adding dropout to the 9 blocks and trying to make the overall architecture a bit less complex and therefore less prone to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer & batch normalization\n",
    "inputs = Input(shape = (16000,1))\n",
    "x_1d = BatchNormalization(name = 'batchnormal_1d_in')(inputs)\n",
    "\n",
    "# iteratively create 4 blocks of 2 convolutional layers with batchnorm and max-pooling\n",
    "for i in range(5):\n",
    "    \n",
    "    name = 'step'+str(i)\n",
    "    \n",
    "    # first 1D convolutional block\n",
    "    x_1d = Conv1D(8*(2 ** i), (2),padding = 'same', name = 'conv'+name+'_1')(x_1d)\n",
    "    x_1d = BatchNormalization(name = 'batch'+name+'_1')(x_1d)\n",
    "    x_1d = Activation('relu')(x_1d)\n",
    "    \n",
    "    # second 1D convolutional block\n",
    "    x_1d = Conv1D(8*(2 ** i), (3),padding = 'same', name = 'conv'+name+'_2')(x_1d)\n",
    "    x_1d = BatchNormalization(name = 'batch'+name+'_2')(x_1d)\n",
    "    x_1d = Activation('relu')(x_1d)\n",
    "    \n",
    "    # max pooling\n",
    "    x_1d = MaxPooling1D((2), padding='same')(x_1d)\n",
    "\n",
    "# final convolution and dense layer\n",
    "x_1d = Conv1D(1024, (1),name='last1024')(x_1d)\n",
    "x_1d = GlobalMaxPool1D()(x_1d)\n",
    "x_1d = Dense(1024, activation = 'relu', name= 'dense1024_onlygmax')(x_1d)\n",
    "x_1d = Dropout(0.2)(x_1d)\n",
    "\n",
    "# soft-maxed prediction layer\n",
    "predictions = Dense(num_categories, activation = 'softmax',name='cls_1d')(x_1d)\n",
    "\n",
    "\n",
    "community_model_2 = Model(inputs=inputs, outputs=predictions)\n",
    "community_model_2.compile(Adam(lr=0.001),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/30\n",
      "240/240 [==============================] - 19s - loss: 4.6181 - acc: 0.1042 - val_loss: 2.4986 - val_acc: 0.0833\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 16s - loss: 5.3352 - acc: 0.1000 - val_loss: 2.4803 - val_acc: 0.0667\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 16s - loss: 4.2115 - acc: 0.1333 - val_loss: 2.4563 - val_acc: 0.1333\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 16s - loss: 3.2941 - acc: 0.2208 - val_loss: 2.4399 - val_acc: 0.1167\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 16s - loss: 2.9829 - acc: 0.1750 - val_loss: 2.4240 - val_acc: 0.1000\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 16s - loss: 2.7526 - acc: 0.1792 - val_loss: 2.4203 - val_acc: 0.1333\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 16s - loss: 2.4915 - acc: 0.1625 - val_loss: 2.4310 - val_acc: 0.1333\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 16s - loss: 2.3198 - acc: 0.1667 - val_loss: 2.4448 - val_acc: 0.1333\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 16s - loss: 2.2501 - acc: 0.2250 - val_loss: 2.4722 - val_acc: 0.1167\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 16s - loss: 2.2181 - acc: 0.2083 - val_loss: 2.5172 - val_acc: 0.1333\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 16s - loss: 2.1509 - acc: 0.2458 - val_loss: 2.5642 - val_acc: 0.1333\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 16s - loss: 2.0779 - acc: 0.2500 - val_loss: 2.5840 - val_acc: 0.1167\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 16s - loss: 2.0517 - acc: 0.2958 - val_loss: 2.6442 - val_acc: 0.1167\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 16s - loss: 2.0209 - acc: 0.2958 - val_loss: 2.7075 - val_acc: 0.1167\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 16s - loss: 1.9995 - acc: 0.3000 - val_loss: 2.7479 - val_acc: 0.1167\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 16s - loss: 1.9569 - acc: 0.3083 - val_loss: 2.7910 - val_acc: 0.0833\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 16s - loss: 1.9285 - acc: 0.3375 - val_loss: 2.7926 - val_acc: 0.1167\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 16s - loss: 1.8407 - acc: 0.3625 - val_loss: 2.8526 - val_acc: 0.1500\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 16s - loss: 1.8417 - acc: 0.3500 - val_loss: 2.8647 - val_acc: 0.1333\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 16s - loss: 1.8506 - acc: 0.3208 - val_loss: 2.9275 - val_acc: 0.1333\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 16s - loss: 1.8006 - acc: 0.3875 - val_loss: 2.9993 - val_acc: 0.1667\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 16s - loss: 1.6915 - acc: 0.3625 - val_loss: 3.0589 - val_acc: 0.1667\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 16s - loss: 1.6458 - acc: 0.4333 - val_loss: 3.1094 - val_acc: 0.1500\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 16s - loss: 1.7385 - acc: 0.3667 - val_loss: 3.2128 - val_acc: 0.1500\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 16s - loss: 1.6428 - acc: 0.3667 - val_loss: 3.3223 - val_acc: 0.1500\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 16s - loss: 1.6249 - acc: 0.3708 - val_loss: 3.3386 - val_acc: 0.1667\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 16s - loss: 1.5752 - acc: 0.4417 - val_loss: 3.3935 - val_acc: 0.1667\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 15s - loss: 1.5695 - acc: 0.4042 - val_loss: 3.5099 - val_acc: 0.1167\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 15s - loss: 1.5296 - acc: 0.4167 - val_loss: 3.3665 - val_acc: 0.1333\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 14s - loss: 1.5400 - acc: 0.4375 - val_loss: 3.3580 - val_acc: 0.1500\n"
     ]
    }
   ],
   "source": [
    "community_model_2_results = community_model_2.fit(commmunity_train_X, train_y, batch_size=64, \n",
    "                        epochs=30, validation_data=(community_cv_X, cv_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some progress but nothing that would make us treat simple 1D convolutions as a particularly promising direction. A difficult lesson but a lesson nonetheless - testing on the sample can only get you so far.\n",
    "\n",
    "We'll put this architecture to the test on the main set in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final thoughts\n",
    "As you can see doing experiments on the sample sets lets you build intuitions about the types of models that might do well on the larger set. It's good to prototype quickly too narrow down the solution space but we shouldn't get too hung-up on this stage either. Things that might work great with more data might not perform well on a small sample set. We do have strong grounds to believe that the convolutional models are the most promising.\n",
    "\n",
    "There are also pitfalls that we might fall into without knowing our actual, final test set. In particular I mean the fact that the Kaggle test set that determines our leaderboard scores might be quite different from the test set we've been provided with. It might contain lots of utterances of words that would technically fall under our \"unknown\" category, but that nonetheless are very different from the \"unknown\" samples we've trained and locally tested our model on. The leaderboard test sample might also be skewed in different, real-world ways. \n",
    "\n",
    "I do not intend to devote a lot of space to tuning your predictions through ensembling techniques or ways of specifically learning things about the final Kaggle test set, but that is an interesting challenge in and of itself. Instead we'll focus on learning which techniques (and why) are likely to work on the data provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 12)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 12)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
