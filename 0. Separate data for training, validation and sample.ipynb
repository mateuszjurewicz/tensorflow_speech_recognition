{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate data for training, validation and sample\n",
    "\n",
    "Before we get to preprocessing we should split our available data into a *training, cross-validation and testing sets*. It is also really helpful to create a small subset of the data (called **sample**) which we'll use for early experimentations and making sure the code works. \n",
    "\n",
    "The idea is to work on a small sample dataset (itself separated into train, cv and test) so that we get feedback quickly - and the same code can then be run for more epochs on the larger dataset.\n",
    "\n",
    "This is a good exercise in basic python **file manipulation** and can also be done directly in the terminal (deeply recommend *tmux*), but I prefer to have a notebook for this because I can then retrace my steps and easily repeat the process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Plan\n",
    "What do we plan to achieve with this notebook and what steps need to be taken?\n",
    "\n",
    "   -  **Split into main/test and main/cv**\n",
    "   <br><font color=gray> use the provided testing_list.txt and validation_list.txt lists to split the original train set into main/test, main/cv (by moving files). This has the benefit of putting files recorded by the same person in only one subset, so the model can't latch onto a person's voice characteristics. We'll make sure there's not data leakage this way.</font><br><br>\n",
    "   -  **Prepare main/train**\n",
    "   <br><font color=gray>treat the remaining files as main/train.</font><br><br>\n",
    "   -  **Prepare main/-subset-/unknown**\n",
    "   <br><font color=gray>use the categories we won't be predicting as *unknown*, but maintain the files' uniqueness by appending their original category name to the end of the filename and then put them all into main/*subset*/unknown/. </font><br><br>\n",
    "   -  **Split background noise files**\n",
    "   <br><font color=gray>all the background noise files (which we'll treat as *silence* category members) need to be cut into approximately 1 second long files (the other files are also slightly irregular in this way).</font><br><br>\n",
    "   -  **Prepare main/-subset-/silence**\n",
    "   <br><font color=gray>all the 1-sec silence files need to be split into train, test and cv subsets (60 x 20 x 20). </font><br><br>\n",
    "   -  **Copy subsets into sample/-subset-/category**\n",
    "   <br><font color=gray>create sample folder (as opposed to /main) & copy small, random subset of each category into sample/train, sample/cv and sample/test.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "We'll need a couple of additional libraries so let's import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import os\n",
    "\n",
    "from shutil import copyfile\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into main/test and main/cv\n",
    "What Google Brain & Kaggle give us is a folder called \"train\" with 3 important element - the testing_list.txt, validation_list.txt and a subfolder \"audio\" with further subfolders whose names are referring to what the .wav files within them represent - e.g. \"yes\", \"no\", \"happy\" & \"dog\". \n",
    "\n",
    "Google's idea is for us to use the .txt files to grab the right .wav files and move them from the primary train folder into validation and test folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/mateusz/Documents/Mateusz/Career/Machine Learning & AI/tensorflow_speech_recognition/tensorflow_speech_recognition\n"
     ]
    }
   ],
   "source": [
    "# make sure we're in the right folder (the one with Google's test and train folder in it), and if not cd into it.\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're aiming for the following directory tree:\n",
    "    -  data\\\n",
    "        - main\\\n",
    "            - train\\\n",
    "                - all subfolders named after categories (e.g. \"yes\", \"one\", \"cat\", \"silence\", \"unknown\")\n",
    "            - test\\\n",
    "                - (...)\n",
    "            - cv\\\n",
    "                - (...)\n",
    "        - sample\\\n",
    "            - train\\\n",
    "            - test\\\n",
    "            - cv\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our own data folder with main\\train, main\\test and main\\cv subfolders in it\n",
    "!mkdir data\\main\\train\n",
    "!mkdir data\\main\\test\n",
    "!mkdir data\\main\\cv\n",
    "\n",
    "# depending on the operating system the slashes might be backward of forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store relative paths (we need to escape the slash)\n",
    "path_main_train = \"data\\\\main\\\\train\"\n",
    "path_main_test = \"data\\\\main\\\\test\"\n",
    "path_main_cv = \"data\\\\main\\\\cv\"\n",
    "\n",
    "paths_main = [path_main_train, path_main_test, path_main_cv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store relative paths to provided data\n",
    "path_provided = \"train\\\\audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yes', 'right', 'silence', 'three', 'eight', 'dog', 'tree']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the categories (which are also names of subfolders, all lowercase)\n",
    "categories_to_predict = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\",\n",
    "             \"silence\", \"unknown\"]\n",
    "\n",
    "categories_unknown = [\"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \n",
    "                      \"Six\", \"Seven\", \"Eight\", \"Nine\", \"Bed\", \"Bird\",\n",
    "                      \"Cat\", \"Dog\", \"Happy\", \"House\", \"Marvin\", \"Sheila\",\n",
    "                      \"Tree\", \"Wow\"]\n",
    "\n",
    "categories_all = categories_to_predict + categories_unknown\n",
    "\n",
    "# we need to make them all lowercase because that's how they're written in testing_list.txt and validation_list.txt\n",
    "categories_all = [category.lower() for category in categories_all]\n",
    "\n",
    "categories_all[::5]  # every 5th element will be shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all subfolders in main\n",
    "for path in paths_main:\n",
    "    for subfolder_name in categories_all:\n",
    "        subfolder_path = os.path.join(path, subfolder_name)\n",
    "        !mkdir $subfolder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Separate data for training, validation and sample.ipynb\n",
      "LICENSE\n",
      "README.md\n",
      "data\n",
      "req.txt\n",
      "sample_submission.csv\n",
      "test\n",
      "train\n",
      "train_backup\n"
     ]
    }
   ],
   "source": [
    "# we should now see our newly made data folder and the original train folder provided by Google \n",
    "# I've also made a backup of the train folder, just in case.\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bed/0c40e715_nohash_0.wav\\n', 'bed/0ea0e2f4_nohash_0.wav\\n', 'bed/0ea0e2f4_nohash_1.wav\\n', 'bed/105a0eea_nohash_0.wav\\n', 'bed/1528225c_nohash_0.wav\\n']\n"
     ]
    }
   ],
   "source": [
    "# take a look at the format\n",
    "with open(\"train\\\\testing_list.txt\", \"r\", encoding=\"UTF-8\") as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "    # show first 5 entries\n",
    "    print(content[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the .txt files provided by Google to move files from original \\train\\ directory\n",
    "# this won't be a problem for linux/mac users but on windows we'll have to fix the slash\n",
    "def move_per_list(text_list, path_origin, path_destination):\n",
    "    \"\"\"\n",
    "    Take a list of paths to .wav files and move them from origin path to destination\n",
    "    \"\"\"\n",
    "    with open(text_list, \"r\", encoding=\"UTF-8\") as f:\n",
    "        content = f.readlines()\n",
    "        for line in content:\n",
    "            # strip newline (\"\\n\")\n",
    "            line = line.strip()\n",
    "\n",
    "            # replace \"/\" with \"\\\\\"\n",
    "            line = line.replace(\"/\", \"\\\\\")\n",
    "\n",
    "            # construct current path to .wav file\n",
    "            cur_path = os.path.join(path_origin, line)\n",
    "\n",
    "            # move the listed .wav files\n",
    "            os.rename(cur_path, os.path.join(path_destination, line))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\\test\\...\n",
    "move_per_list(\"train\\\\testing_list.txt\", path_provided, path_main_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\\cv\\...\n",
    "move_per_list(\"train\\\\validation_list.txt\", path_provided, path_main_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that our train\\audio directory no longer contains the files from testing_list.txt and validation_list.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare main/train\n",
    "All the .wav files remaining in the path_provided (the original contents of \\train\\audio provided by Google) are meant to be treated as the training set, so let's move them to the appropriate data\\main\\train folder.\n",
    "\n",
    "This step deals with the largest chunk of data so it can take a couple of minutes, depending on the hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use glob module to grab all .wav files in the subfolders\n",
    "for category in categories_all:\n",
    "    # create regex path for glob\n",
    "    glob_regex = os.path.join(path_provided, category)\n",
    "    glob_regex = os.path.join(glob_regex, \"*.wav\")\n",
    "    \n",
    "    # use glob to grab all .wav files in that category's subdirectory\n",
    "    train_wav_files = glob.glob(glob_regex)\n",
    "\n",
    "    # move them to our data\\main\\train folder\n",
    "    for wav_file in train_wav_files:\n",
    "        \n",
    "        # grab the actual unique name of each .wav file (e.q. yes\\004ae712_nohash_0.wav, without the parent dirs)\n",
    "        wav_unique_name = wav_file[12:]\n",
    "        \n",
    "        # move them\n",
    "        os.rename(wav_file, os.path.join(path_main_train, wav_unique_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The origina path_provided (\\train\\audio\\(...)) should now contain empty category subfolders, with the exception of _background_noise_, which we'll use for creating our \"silence\" examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare main/-subset-/unknown\n",
    "Some of the folders contain .wav files that we should consider to belong to one common category - \"unknown\", representing the fact that the user may have said something, but it was not a known command. For example categories such as \"happy\", \"wow\" and \"tree\". We can see how we'd like out voice-recognition applications to distinguish between an unknown word and silence/background noise.\n",
    "\n",
    "We'll want to move all the files from those folders into one folder named \"uknown\". The tricky part is that some of the files within \"happy\" and \"wow\" may have the same name. They're only uniquely named if we take into consideration the name of their folder.\n",
    "\n",
    "My solution is to rename all files within these categories by appending the name of the folder to the end of the filename and then move all of the renamed files to \"unknown\" and then remove the remaining empty folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zero', 'three', 'six', 'nine', 'cat', 'house', 'tree']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure yout unknown categories are lowercase\n",
    "categories_unknown = [category.lower() for category in categories_unknown]\n",
    "categories_unknown[::3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The step below is moving a lot of files, so again it may take a couple minutes to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename for every subset (train, test, cv) and subcategory (e.g. 'house', 'tree' etc.)\n",
    "for path_to_subset in paths_main:\n",
    "    for unknown_cat in categories_unknown:\n",
    "        \n",
    "        # create regex for glob\n",
    "        path_to_cat = os.path.join(path_to_subset, unknown_cat)\n",
    "        glob_regex = os.path.join(path_to_cat, \"*.wav\")\n",
    "        \n",
    "        # grab all \"unknown\" files\n",
    "        unknown_wavs = glob.glob(glob_regex)\n",
    "        \n",
    "        # create destination path\n",
    "        path_to_destination = os.path.join(path_to_subset, \"unknown\")\n",
    "        \n",
    "        # move & rename files\n",
    "        for wav_file in unknown_wavs:\n",
    "            \n",
    "            # construct new full name (with path) - first replace the category with \"unknown\"\n",
    "            new_full_path = wav_file.replace(unknown_cat, \"unknown\")\n",
    "            \n",
    "            # then add the category name - e.g. \"_tree\" before \".wav\")\n",
    "            new_full_path = new_full_path[:-4] + \"_\" + unknown_cat + new_full_path[-4:]\n",
    "            \n",
    "            # move files\n",
    "            os.rename(wav_file, new_full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can safely remove the folders of the categories that became \"unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the unused category folders from all subsets\n",
    "for path_to_subset in paths_main:\n",
    "    for unknown_cat in categories_unknown:\n",
    "        full_unused_path = os.path.join(path_to_subset, unknown_cat)\n",
    "        !rm -r $full_unused_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down\n",
      "go\n",
      "left\n",
      "no\n",
      "off\n",
      "on\n",
      "right\n",
      "silence\n",
      "stop\n",
      "unknown\n",
      "up\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "# main/train, main/test and main/cv should now only contain folders named after categories that we'll be predicting\n",
    "!ls $path_to_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">It is important to notice that in main/test we now have 250 examples per category but in the case of unknown we have over 4000 examples. In main/train we have 1850 examples per category and 32K in unknown . This makes our dataset very unbalanced.</div>\n",
    "\n",
    "However at this stage we don't want to lose any data and we may be able to use data augmentation later on to reduce this imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split background noise files\n",
    "In the train / audio / background_noise folder provided by Google Brain & Kaggle we have 6 .wav files of differing length (between 1:00 and 1:35 minutes). We can use them in a couple of different ways - e.g. mix them with our categorised .wav samples so that our model might better learn how to distinguish voice commands from environments with background noise or treat them separately as members of the \"silence\" category.\n",
    "\n",
    "In this notebook we'll take the latter approach and leave mixing .wav files to the next notebook, which will put more focus on preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_1sec(input_source, output_destination, fragment_length=1000):\n",
    "    \"\"\" \n",
    "    Simple function for grabbing .wav files and splitting them into 1 sec\n",
    "    fragments, also handling differing input length.\n",
    "    \"\"\"\n",
    "    \n",
    "    # open the input source\n",
    "    source = AudioSegment.from_wav(input_source)\n",
    "    \n",
    "    # store length (in milliseconds)\n",
    "    length = len(source)\n",
    "    \n",
    "    # split until there's not enough length to create a full fragment\n",
    "    for i in range(math.floor(length / fragment_length)):\n",
    "        \n",
    "        # grab the right slice\n",
    "        current_fragment = source[i * fragment_length : (i + 1) * fragment_length + 1]\n",
    "        \n",
    "        # construct output fragment's name\n",
    "        fragment_name = output_destination + \"_{}.wav\".format(i+1)\n",
    "        \n",
    "        # save the fragment\n",
    "        current_fragment.export(fragment_name, format=\"wav\")\n",
    "        \n",
    "        # close current fragment\n",
    "        del current_fragment\n",
    "    \n",
    "    # close the input source\n",
    "    del source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this function to populate train/audio/\\_background\\_noise\\_ with 1 second fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_types = [\"doing_the_dishes\", \"dude_miaowing\", \n",
    "                    \"exercise_bike\", \"pink_noise\",\n",
    "                    \"running_tap\", \"white_noise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new directory for the fragments\n",
    "path_to_fragments = os.path.join(path_provided, \"_background_noise_fragments_\")\n",
    "!mkdir $path_to_fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split all 6 background noise files\n",
    "for background in background_types:\n",
    "    # grab the full-length background file\n",
    "    path_to_background = os.path.join(path_provided, \"_background_noise_\", background + \".wav\")\n",
    "    \n",
    "    # create destination path\n",
    "    path_to_destination = os.path.join(path_to_fragments, background)\n",
    "    \n",
    "    # split\n",
    "    split_into_1sec(path_to_background, path_to_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we listen to the files we will notice that some of them are louder than others, which may be good for the background noise \"silence\" category, but not necessarily so for other categories. We may wish to look at that in the preprocessing notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\\audio\\_background_noise_fragments_\n"
     ]
    }
   ],
   "source": [
    "print(path_to_fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    398     398    8167\n"
     ]
    }
   ],
   "source": [
    "# let's see how many \"silence\" examples we have\n",
    "!ls $path_to_fragments | wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we've got almost 400 examples of 1-second background noises that we can now move to the main/ _subset_ /silence folders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare main/-subset-/silence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy subsets into sample/-subset-/category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
